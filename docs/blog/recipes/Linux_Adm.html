<table>
<colgroup>
<col style="width: 100%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">#CLI shortcut keystrokes(linux&amp;MAC)
Ctrl+L: Clear the screen. This is similar to running the “clear”
command. Ctrl+C: Interrupt (kill) the current foreground process running
in in the terminal. This sends the SIGINT signal to the process Ctrl+Z:
Suspend the current foreground process running in bash. This sends the
SIGTSTP signal to the process. To return the process to the foreground
later, use the fg process_name command. Ctrl+D: Close the bash
shell.This is similar to running the exit command Ctrl+L: Clear the
screen. This is similar to running the “clear” command.</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">/etc #configuration files on the system
/etc/hosts #maps hostnames to IP addresses /etc/skel #files copied to
each user’s home /usr #user by user and supersuser accounts.Stores
application programs /usr/bin #executables used by users, in user’s PATH
statement /usr/sbin #executables used by superusers /usr/local
#applications which are not part of linux #applications installed after
initial linux installation,in user’s PATH statement #administrative
applications installed after initial linux installation /usr/local/bin
/usr/doc #the default location for application documentation is in a
directory named for the application /var #stores log files, mails and
other data /var/spool #mail &amp; printing files /var/tmp #data that
should persist across reboot</td>
</tr>
<tr class="even">
<td style="text-align: left;">/var/log #log files /var/log/anaconda.log
- While installing Linux, all installation related messages are stored
in this log file /var/log/audit/ - This subdirectory contains logs
information stored by the Linux audit daemon (auditd) /var/log/auth.log
- user logins,such as password prompts /var/log/boot.log - Contains
information that are logged when the system boots /var/log/cron -
Whenever cron daemon (or anacron) starts a cron job, it logs the
information about the cron job in this file /var/log/debug #debugging
information from the Ubuntu system and applications /var/log/daemon.log
- display server, SSH sessions, printing services, bluetooth
/var/log/dmesg - Contains kernel ring buffer. This file is overwritten
when the system is rebooted. /var/log/faillog -failed user login
attempts. ssh(used for remote login), su(to switch users), at, cron
(both used for scheduling tasks) use PAM modules for authentication
/var/log/kern.log - Contains information logged by the kernel. Helpful
to troubleshoot a custom-built kernel. /var/log/lastlog #last logins
/var/log/messages #the main system log,the messages that are logged
during system startup /var/log/sa/ - Contains the daily sar files that
are collected by the sysstat package. /var/log/samba/ - Contains log
information stored by samba, which is used to connect Windows to Linux.
/var/log/setroubleshoot/ - SELinux uses setroubleshootd (SE Trouble
Shoot Daemon) to notify about issues in the security context of files
and logs those information in this log file. /var/log/secure #failed
login attempts, failed SSH login attempts, successful SSH logins
/var/log/syslog /var/log/user.log - Contains information about all user
level logs.</td>
</tr>
<tr class="odd">
<td style="text-align: left;">/var/log/Xorg.x.log - Log messages from
the X server to this file. /var/log/Xorg.0.log /var/log/yum.log -
Contains information that are logged when a package is installed using
yum</td>
</tr>
<tr class="even">
<td style="text-align: left;">#binary log files,cannot be read with a
normal text editor,special command-line tools are used to display the
relevant information in human-readable format /var/log/btmp - This file
contains information about failed login attempts /var/log/utmp - The
utmp file allows one to discover information about who is currently
using the system. /var/log/wtmp - The wtmp file records all logins and
logouts.</td>
</tr>
<tr class="odd">
<td style="text-align: left;">#This subdirectory contains additional
logs from the mail server. #For example, sendmail stores the collected
mail statistics in /var/log/mail/statistics file /var/log/mail/
/var/log/maillog - Logs information from the mail server that is running
on the system. /var/log/mail.log - Logs information from the mail server
that is running on the system.</td>
</tr>
<tr class="even">
<td style="text-align: left;">#- Contains the apache web server
access_log and error_log and related virtual hosts logs if set up to log
here. /var/log/httpd/ /var/log/apache2 /var/log/apache2/error.log
/var/log/mysql.log</td>
</tr>
<tr class="odd">
<td style="text-align: left;">#All printer and printing related log
messages /var/log/cups /var/log/spooler</td>
</tr>
<tr class="even">
<td style="text-align: left;">/bin #binaries run during system startup
/sbin #administrative binaries run by superusers /root #home for
superuser /home #user home dirs /boot #files run by boot loader and
kernel /dev #peripheral access files /proc #virtual dir contains system
info /tmp #stores temporary files /etc/grub.conf or /boot/grub/grub.conf
#customize the behavior and appearance of the boot menu
/dev/shm,/dev/shmfs #also known as tmpfs,df -h,file system which keeps
all files in virtual memory,no files created on hard drive /etc/passwd
#UID/GID stored, UID/GUID zero(0) for root, all UID/GID &lt;1000
privileged access, all other users UID/GID&gt;1000</td>
</tr>
<tr class="odd">
<td style="text-align: left;">#list group members /etc/group #secondary
group memberships, awk -F’:’ ‘/sudo/{print $4}’ /etc/group grep ‘^sudo’
/etc/group grep -w sudo /etc/group</td>
</tr>
</tbody>
</table>
<p>#Bard</p>
<p>The command [ -f /var/run/reboot-required ] &amp;&amp; sudo reboot -f
first checks if the file /var/run/reboot-required exists. If it does,
the command then runs the sudo reboot -f command, which forcefully
reboots the system.</p>
<p>The file /var/run/reboot-required is created by some Linux
distributions when a system update requires a reboot. This is to ensure
that the system is properly updated before it is restarted.</p>
<p>The sudo reboot -f command forcefully reboots the system, even if
there are unsaved changes in open files. This is useful if the system is
unresponsive or if you need to reboot it immediately.</p>
<p>Some of the best uses cases for the command [ -f
/var/run/reboot-required ] &amp;&amp; sudo reboot -f are:</p>
<pre><code>After a system update that requires a reboot.
If the system is unresponsive.
If you need to reboot the system immediately.</code></pre>
<h2
id="it-is-important-to-note-that-forcefully-rebooting-the-system-can-sometimes-cause-data-loss.-therefore-you-should-only-use-this-command-if-you-are-sure-that-there-are-no-unsaved-changes-in-open-files.">It
is important to note that forcefully rebooting the system can sometimes
cause data loss. Therefore, you should only use this command if you are
sure that there are no unsaved changes in open files.</h2>
<p>#ChatGPT</p>
<p>This command is used in a Linux shell environment and is composed of
two parts connected by the &amp;&amp; operator. The overall purpose of
this command is to check if a specific file exists and, if it does,
initiate a system reboot with administrative privileges. Let’s break
down each part of the command:</p>
<pre><code>[ -f /var/run/reboot-required ]: This is a conditional test using the [ (test) command. The -f flag checks if the specified file (/var/run/reboot-required) exists. This file is often used on Ubuntu-based systems to indicate that a system reboot is required due to software updates or configuration changes.

&amp;&amp;: This is the logical &quot;AND&quot; operator. It&#39;s used to execute the command on the right only if the command on the left (the test in this case) evaluates as true or successful.

sudo reboot -f: If the previous test [ -f /var/run/reboot-required ] is successful (meaning the file exists), this command is executed. The sudo command is used to execute the subsequent command with superuser (root) privileges. reboot is a command used to restart the system, and the -f flag forces an immediate reboot without further confirmation.</code></pre>
<p>Best Use Cases:</p>
<pre><code>Automated Reboot after Updates: This command is commonly used in automated scripts or scheduled tasks, particularly after software updates have been applied to a Linux system. If the file /var/run/reboot-required exists, it suggests that important updates have been installed that require a system restart for them to take effect. By using this command, you can ensure that the system automatically reboots when necessary after updates.

Post-Configuration Reboot: In situations where configuration changes are applied that necessitate a reboot, this command can be used to automatically restart the system. For example, if you&#39;ve made changes that affect kernel modules or critical system services, an automated reboot might be necessary to apply those changes.

Server Maintenance and Deployment Scripts: When performing maintenance tasks on servers or during deployment procedures, administrators might use this command to ensure that a system is properly restarted after specific actions are taken.

Scripted System Checks: This command can be incorporated into system health-check scripts that are run periodically to ensure the system is in a proper state. If the script detects that a reboot is required, it can automatically initiate one.</code></pre>
<p>It’s important to exercise caution when using commands that trigger a
system reboot, especially in automated scenarios. Rebooting a system
without proper planning can lead to unexpected downtime and disruption
of services. Always thoroughly test any scripts or commands in a
controlled environment before deploying them in production systems.</p>
<table>
<colgroup>
<col style="width: 100%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">“&amp;&amp;” #where the second command is
executed only if the exit status of the preceding command is 0 (zero
exit code) #The right side of &amp;&amp; is evaluated if the exit status
of the left side is zero (i.e. true)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">#Syntax for Command Substitution #The
old-style uses backticks (also called backquotes) to wrap the command
being substituted #The new style begins with a dollar sign and wraps the
rest of the command in parenthesis $ rpm -ql $(rpm -qa | grep
httpd)</td>
</tr>
<tr class="even">
<td style="text-align: left;">$(command) #Command Substitution (list)
#Group commands in a subshell: ( ) { list; } #Group commands in the
current shell: { } [[ expression ]] #Test - return the binary result of
an expression: [[ ]]</td>
</tr>
<tr class="odd">
<td style="text-align: left;">command substitution; output from pwd
works as the argument for echo command $ echo <code>pwd</code></td>
</tr>
<tr class="even">
<td style="text-align: left;">Command Substitution #
<code>backquotes</code> also known as <code>backticks</code>
KERNEL_VERSION=<code>uname -r</code> #(parentheses) KERNEL_VERSION=<span
class="math inline">(<em>u</em><em>n</em><em>a</em><em>m</em><em>e</em> − <em>r</em>)</span>
echo $KERNEL_VERSION 4.15.0-29-generic</td>
</tr>
<tr class="odd">
<td style="text-align: left;">#Command substitution in Bash #execute a
command and substitute it with its standard output,command executes
within a subshell</td>
</tr>
<tr class="even">
<td style="text-align: left;">$ var_date=$(date) &amp;&amp; echo <span
class="math inline"><em>v</em><em>a</em><em>r</em><sub><em>d</em></sub><em>a</em><em>t</em><em>e</em></span>
due_date=“01-01” $ echo “Status as of $(date +%m-%d-%Y) : The delivery
is due on ${due_date}-2022”</td>
</tr>
<tr class="odd">
<td style="text-align: left;">echo “${myvar:-bash}” #check the variable,
$myvar is set or unset. If <span class="math inline">$myvar is unset,
then the string ‘bash’ will print
echo "$</span>{myvar:=bash}” #set the value, ‘bash’ to $myvar and print
‘bash’ to the terminal if <span class="math inline">$myvar is unset
echo "$</span>{myvar:+python}” #print, ‘python’ to the terminal if
$myvar is set before</td>
</tr>
<tr class="even">
<td style="text-align: left;">$ mystr=“Bangladesh” $ echo “${mystr:0:6}”
#six characters from <span
class="math inline"><em>m</em><em>y</em><em>s</em><em>t</em><em>r</em><em>s</em><em>t</em><em>a</em><em>r</em><em>t</em><em>i</em><em>n</em><em>g</em><em>f</em><em>r</em><em>o</em><em>m</em><em>p</em><em>o</em><em>s</em><em>i</em><em>t</em><em>i</em><em>o</em><em>n</em>0<em>t</em><em>o</em>6</span>
echo “${mystr:6}” #all characters from <span
class="math inline"><em>m</em><em>y</em><em>s</em><em>t</em><em>r</em>, <em>s</em><em>t</em><em>a</em><em>r</em><em>t</em><em>i</em><em>n</em><em>g</em><em>f</em><em>r</em><em>o</em><em>m</em><em>p</em><em>o</em><em>s</em><em>i</em><em>t</em><em>i</em><em>o</em><em>n</em>6<em>t</em><em>o</em><em>t</em><em>h</em><em>e</em><em>e</em><em>n</em><em>d</em></span>
echo “${#mystr}” #count and print the total number of characters of
$mystr</td>
</tr>
<tr class="odd">
<td style="text-align: left;">The process substitution &gt;(command)
will be replaced by a file name.</td>
</tr>
</tbody>
</table>
<p>{ Commands; } : Commands execute in current shell ( Commands ) :
Commands will execute in a subshell</p>
<p>$ VAR=“1”; { VAR=“2”; echo “Inside group: VAR=<span
class="math inline">$VAR"; }; echo "Outside: VAR=$</span>VAR” Inside
group: VAR=2 Outside: VAR=2</p>
<p>#the variable is changed in a subshell. Therefore, the changes will
not affect the outer shell $ VAR=“1”; ( VAR=“2”; echo “Inside group:
VAR=<span class="math inline">$VAR" ); echo "Outside: VAR=$</span>VAR”
Inside group: VAR=2 Outside: VAR=1</p>
<p>$ pwd; { cd /etc; pwd; }; pwd #current shell $ pwd; ( cd /etc; pwd );
pwd #subshell</p>
<table>
<colgroup>
<col style="width: 100%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">#Placing a list of commands between curly
braces causes the list to be executed in the current shell context. #No
subshell is created.</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">#Parameter Expansion #specify a variable
within {} to protect it against expansion. #useful when the characters
immediately following it can be interpreted as part of the variable
name. $ price=5 $ echo “${price}USD”</td>
</tr>
</tbody>
</table>
<h1
id="avoid-dot-slash-.-when-running-executable-scripts-binary-file">avoid
dot slash “./” when running executable scripts, binary file</h1>
<p>#OPTION 1 export PATH=$PATH:/path/to/directory</p>
<p>#OPTION 2 ln -s /path_to_script/myscript /usr/bin/myscript</p>
<p>#OPTION 3 bash -c /Users/you/myscript.sh</p>
<p>#OPTION 4 , add the line below into “~/.bashrc.” export
PATH=/path_to_folder_containing_executable/:$PATH
—————————————————————————————— #Hosts File Windows 10 - “C:” Linux -
“/etc/hosts” Mac OS X - “/private/etc/hosts”
——————————————————————————————————————– #Reading file content from
command line $ while read line; do echo $line; done &lt; company.txt
——————————————————————————————————————– mount -t tmpfs tmpfs /mnt/tmp
#in-memory filesystem,tmpfs is a temporary filesystem that only exists
in RAM ——————————————————————————————————————– #which is an external
binary, located at /usr/bin/which which steps through the $PATH
environment variable and checks for the existence of a file which
modprobe #command is built in to shell, with the -v option how shell
invokes the command specified as its option command -v modprobe
——————————————————————————————————————– #ls -ai command</p>
<p>$ ls .. # double dot(..) represents the parent directory $ sudo rm ..
rm: cannot remove ‘..’: Is a directory $ sudo rm -rf .. rm: refusing to
remove ‘.’ or ‘..’ directory: skipping ‘..’</p>
<p>$ ls . #single dot(.) represents the current directory $ sudo rm .
rm: cannot remove ‘.’: Is a directory $ sudo rm -rf . rm: refusing to
remove ‘.’ or ‘..’ directory: skipping ‘.’
——————————————————————————————————————– #list all failed SSH logins grep
“Failed password” /var/log/auth.log egrep “Failed|Failure”
/var/log/auth.log cat /var/log/auth.log | grep “Failed password” grep
“Failed password” /var/log/auth.log | awk ’{print <span
class="math inline">$11}' | uniq -c | sort -nr # the number of failed
attempts of each IP address,
--------------------------------------------------------------------------------------------------------------------
tar -czf - ./Documents/ | (pv -p --timer --rate --bytes &gt; backup.tgz)
#Monitor tar progress
pv -p history.log | wc #Count number of lines, words, bytes
pv -p /etc/hosts | wc
pv history.log | zip&gt;$</span>HOME/Documents/history.zip #history.log
and show progress pv origin-cdn.cyberciti.org_access.log &gt;
/tmp/origin-cdn-access.log #copy a file and show progress pv
origin-cdn.cyberciti.org_access.log &gt; /dev/null #show progress pv -cN
rawlogfile origin-cdn.cyberciti.org_access.log | gzip | pv -cN
gziplogfile &gt; access.log.gz #see progress of both pipes</p>
<p>(pv -n backup.tar.gz | tar xzf - -C path/to/data ) 2&gt;&amp;1 |
dialog –gauge “Running tar, please wait…” 10 70 0 #extract tar ball and
show progress using the dialog command tar -czf - ./Documents/ | (pv -n
&gt; backup.tgz) 2&gt;&amp;1 | dialog –gauge “Progress” 10 70</p>
<p>nc -l -v -w 30 -p 2000 &gt; /tmp/data.bin #create a network port 2000
nc -l -v -w 30 -p 2000 &gt; /tmp/data.bin #Open another terminal
——————————————————————————————————————– timeout 10s tail -f
/var/log/pacman.log #terminate after 10 seconds timeout 3.2s dmesg -w
#display all messages from the kernel ring buffer, only 3.2 seconds
timeout 3m ping 127.0.0.1 #ping command after 3 minutes timeout 2d ping
127.0.0.1 #ping command after 2 days timeout –foreground 2m test.sh #By
default runs in background, run it foreground</p>
<p>timeout -k 20 10 tail -f /var/log/pacman.log #if the command is still
running even after the time out, send a kill signal timeout -s 9 3s ping
127.0.0.1 #use 9 as SIGKILL kill -l #list all acceptable signal timeout
-k 5s 3m sh test.sh #let the script run for 3 minutes, if it does not
exit, kill after 5 seconds ——————————————————————————————————————–
/home/user01/test.file can also be denoted by ~/test.file #The tilde (~)
is a Linux “shortcut” to denote a user’s home directory. cd ~ #change
into user’s home directory ——————————————————————————————————————– w
#show who is logged on and what they are doing. w user #print info for a
specific user w -i #display IP address instead of hostname for from
field. w -o #print blank space for idle times less than one minute
——————————————————————————————————————– # stops after 50secs, stdout
seen skaffold dev &amp; sleep 50s; kill <span
class="math inline">! − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − −</span>
ssh root@192.168.1.1 ‘bash -s’ &lt; script.sh #Execute the local
script.sh on the remote server ssh $ ssh root@192.168.1.1 ‘uptime; df
-h’ $ ssh root@192.168.1.1 ‘free -m | cat /proc/loadavg’</p>
<p>$ ssh root@192.168.1.1 &lt;&lt; EOF uname -a lscpu | grep “^CPU(s)”
grep -i memtotal /proc/meminfo EOF
——————————————————————————————————————– #setting system locale to
en_US.utf8 localectl set-locale LC_CTYPE=en_US.utf8 localectl status
—————————————————————————————————- ip -o -4 addr list enp0s8 | awk
‘{print $4}’ | cut -d/ -f1 # print IP with a given interface ip -o -6
addr list enp0s8 | awk ‘{print $4}’ | cut -d/ -f1 ifconfig | awk
‘/192.168.18.84/ {print $1}’ RS=“” # print interface with a given IP
—————————————————————————————————- #-n do not output the trailing
newline echo -n $PASSWORD | faas-cli login –username admin
–password-stdin —————————————————————————————————- cat verifyURL.sh
#!/bin/bash</p>
<p>url=“https://gist.github.com/githubfoam/d313d580a92d84123b841ebbd4f255a6”</p>
<p>if wget $url &gt;/dev/null 2&gt;&amp;1 ; then echo “Url : $url …is
online” else echo “Url : $url …is not online” fi</p>
<p>#if link exists #–head avoid downloading the file contents #–fail
make the exit status nonzero on a failed request #–silent avoid status
or errors
url=“https://www.katacoda.com/courses/kubernetes/launch-single-node-cluster”
if curl –output /dev/null –silent –head –fail “$url”; then echo “URL
exists: $url” else echo “URL does not exist: $url” fi</p>
<p>time curl -I http://mydomain.com | grep HTTP # get the header for the
page, and time the process curl -I “www.google.com” 2&gt;&amp;1 | awk
‘/HTTP// {print $2}’ # see only the HTTP status code curl -I
“https://www.google.com” 2&gt;&amp;1 | grep -w “200|301” # see if a
given website is up or down curl -w “” http://localhost:8080/hello #
avoid your terminal printing a ‘%’ or put both result and next command
prompt on the same line lynx -head -dump http://www.google.com #Check
Whether a Website is up or down lynx -head -dump http://www.google.com
2&gt;&amp;1 | awk ‘/HTTP// {print $2}’ # see only the HTTP status
code</p>
#SSL certificate problem curl -kfsSL
https://download.docker.com/linux/ubuntu/gpg | sudo gpg –dearmor -o
/usr/share/keyrings/docker-archive-keyring.gpg curl
https://curl.se/ca/cacert.pem -o
/etc/pki/ca-trust/source/anchors/curl-cacert-updated.pem &amp;&amp;
update-ca-trust wget –no-check-certificate
http://curl.haxx.se/ca/cacert.pem —————————————————————————————————- $
time ./a.out
<output from code>
<p>real 0m5.279s #real is the wall-clock time,Elapsed real time, real
time, wall-clock time, or wall time is the actual time taken from the
start of a computer program to the end. In other words, it is the
difference between the time at which a task finishes and the time at
which the task started. user 0m1.915s #user is the time spent executing
the user’s program, sys 0m0.006s #sys is the time spent on system tasks
required by the program —————————————————————————————————- #linux
benchmark sysbench –test=cpu run sysbench –test=cpu help sysbench
–test=cpu –cpu-max-prime=20000 run sysbench –test=memory run sysbench
–test=memory help sysbench –test=fileio help sysbench –test=fileio
–file-test-mode=seqwr run sysbench –test=fileio –file-total-size=100G
cleanup —————————————————————————————————- # generate load $ yes &gt;
/dev/null &amp;</p>
<h1 id="maximum-number-of-processes-available-to-a-single-user.">maximum
number of processes available to a single user.</h1>
<p>$ ulimit -u # The limit is set with the -S option $ ulimit -S -u
500</p>
<p>#inspect the load figures on the server before and after the stress
test uptime sudo stress –cpu 100 –timeout 300 uptime</p>
<p>$ sudo (yum/apt-get) install stress ## Stress using CPU-bound task
stress -c 4 ## Stress using IO-bound task stress -i 2 # a load average
of four is imposed on the system by specifying two CPU-bound processes,
one I/O-bound process, and one memory allocator process stress -c 2 -i 1
-m 1 –vm-bytes 128M -t 10s</p>
<p>$ sudo apt-get install stress-ng stress-ng –cpu 4 –io 4 –vm 1
–vm-bytes 1G –timeout 60s –metrics-brief stress-ng –hdd 5 –hdd-ops
100000 stress –cpu 4 –io 3 –vm 2 –vm-bytes 256M –timeout 35s</p>
<h1
id="the-restriction-can-be-made-permanent-by-configuring-the-nproc-value">The
restriction can be made permanent by configuring the nproc value</h1>
<p>/etc/security/limits.conf # initiate a fork bomb “:(){ :|:&amp; };:”
# run ./$0&amp; twice #!/bin/sh ./$0&amp; ./$0&amp;
—————————————————————————————————- # Listing all currently known events:
perf list # CPU counter statistics for the specified command: perf stat
command # CPU counter statistics for the specified PID, until Ctrl-C:
perf stat -p PID # Sample on-CPU functions for the specified command, at
99 Hertz: perf record -F 99 command # Trace all block device (disk I/O)
requests with stack traces, until Ctrl-C: perf record -e
block:block_rq_insert -ag # Add a tracepoint for the kernel
tcp_sendmsg() function entry (“–add” is optional): perf probe –add
tcp_sendmsg # Trace system calls by process, showing a summary
refreshing every 2 seconds: perf top -e raw_syscalls:sys_enter -ns comm
# Show perf.data with a column for sample count: perf report -n</p>
<table>
<colgroup>
<col style="width: 100%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">#ls command ltrace -c ls ltrace -p <PID>
ltrace -l /lib/libselinux.so.1 id -Z #execute the id -Z command and show
the calls made to the libselinux.so module ltrace -o foobar.log ./foobar
#edirect output of ltrace to a file ltrace -e malloc ./foobar #filter
and display only calls to a certain library function</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">PATH=/data/myscripts:$PATH #add directory
/data/myscripts to the beginning of the <span
class="math inline"><em>P</em><em>A</em><em>T</em><em>H</em><em>e</em><em>n</em><em>v</em><em>i</em><em>r</em><em>o</em><em>n</em><em>m</em><em>e</em><em>n</em><em>t</em><em>v</em><em>a</em><em>r</em><em>i</em><em>a</em><em>b</em><em>l</em><em>e</em><em>P</em><em>A</em><em>T</em><em>H</em>=</span>PATH:/data/myscripts
#add that directory to the end of the path</td>
</tr>
<tr class="even">
<td style="text-align: left;">echo ‘export PATH=$PATH:/new/directory’
&gt;&gt; ~/.zshrc source ~/.zshr</td>
</tr>
</tbody>
</table>
<p>echo “$(pwd)” #interpret backslash escapes echo -e “Tecmint ” echo -e
“Tecmint ” echo -e “Tecmint ” echo -e “” echo -e “”</p>
<p>echo -e “Geeks ” -e here enables the interpretation of backslash
escapes, it removes all the spaces in between the text echo -e “Geeks
Geeks” suppress trailing new line with backspace interpretor ’-e‘ to
continue without emitting new line. echo -e “Geeks ” : this option
creates new line from where it is used. echo -e “Geeks ” this option is
used to create horizontal tab spaces. echo -e “Geeks this option is used
to create vertical tab spaces. echo -e”# SNMP version 2c
communitymonsvronly 192.168.58.8” &gt;&gt; /etc/snmp/snmpd.conf echo *
#print all files/folders, similar to ls command
—————————————————————————————————- #sh calls the program sh as
interpreter and the -c flag means execute the following command as
interpreted by this program #sh -c spawns a non-login, non-interactive
session of sh (dash in Ubuntu).</p>
<p>$ sudo sh -c “echo 0” #In Ubuntu, sh is usually symlinked to
/bin/dash, meaning that if you execute a command with sh -c the dash
shell will be used to execute the command instead of bash $ readlink -e
$(which sh) /usr/bin/dash sudo sh -c ‘ls -hal /root/ &gt;
/root/test.out’ #The redirection of the output is performed by sudo.
sudo sh -c “echo foo &gt; ~root/out.txt” sudo echo “foo” | sudo dd
of=/root/test2.out sudo su -c ‘echo “foo” &gt; ~root/test4.out’ sudo su
-c ‘echo “foobarr” | tee ~root/test5.out’ sudo su -c ‘echo “append
foobarr” | tee -a ~root/test5.out’ sudo ls /root/out.txt</p>
<p>$ sudo bash -c “echo 0” $ readlink -e $(which bash) /usr/bin/bash</p>
<p>#the features that are specific to interactive shells only (by
default), e.g. history expansion, source-ing of ~/.bashrc and
/etc/bash.bashrc etc will not be available in this session as it is
non-interactive #simulate an interactive sessions behavior (almost), by
using the -i option sh -ic ‘ls -hal /root/ &gt; /root/test.out’ #the
features that are specific to login shells only (by default)
e.g. source-ing of ~/.profile (given ~/.bash_profile and ~/.bash_login
do not exist) and /etc/profile will not be done as the shell is a
non-login shell #simulate login-shells behavior using the -l option sh
-lc ‘ls -hal /root/ &gt; /root/test.out’ #simulate both login and
interactive sessions sh -lic ‘ls -hal /root/ &gt; /root/test.out’
—————————————————————————————————- brew install <formula> #install a
package (or Formula in Homebrew vocabulary) brew uninstall <formula>
brew upgrade <formula> brew update brew list –versions brew search
<formula> brew info <formula> brew cleanup –dry-run #see what formulas
Homebrew would delete without actually deleting</p>
<p>#Homebrew-Cask extends Homebrew and allows you to install large
binary files via a command-line tool brew tap caskroom/cask #make Cask
available by adding it as a tap</p>
<p>#https://brew.sh/ /bin/bash -c “<span class="math inline">$(curl
-fsSL
https://raw.githubusercontent.com/Homebrew/install/master/install.sh)"
#Install Homebrew
----------------------------------------------------------------------------------------------------
bash -c "$</span>(curl -sL
https://raw.githubusercontent.com/ilikenwf/apt-fast/master/quick-install.sh)”
#remote script install curl
https://raw.githubusercontent.com/golang/dep/v0.5.1/install.sh | sh
#remote script install —————————————————————————————————-</p>
<h2 id="ln--s-pwdistioctl-usrlocalbinistioctl-create-symbolic-link">ln
-s $PWD/istioctl /usr/local/bin/istioctl #create symbolic link</h2>
<h2
id="hwclock-utc-systohc-set-the-hardware-clock-to-match-system-software-clock-on-a-linux-only-computer-the-utc-option-tells-it-to-use-utc-which-is-appropriate-for-a-linux-only-system-systohc-sets-the-hardware-clock-based-on-the-current-value-of-the-software-clock">hwclock
–utc –systohc # set the hardware clock to match system (software) clock
on a Linux-only computer, The –utc option tells it to use UTC, which is
appropriate for a Linux-only system, –systohc sets the hardware clock
based on the current value of the software clock</h2>
<h2
id="logger-shutting-down-to-add-network-card-create-a-log-file-entry-noting-that-youre-manually-shutting-down-the-system-to-add-a-new-network-card-prior-to-using-shutdown-the-logger-utility-can-be-used-to-create-a-one-time-log-fle-entry-that-you-specify">logger
shutting down to add network card #create a log file entry noting that
you’re manually shutting down the system to add a new network card prior
to using shutdown, The logger utility can be used to create a one-time
log fle entry that you specify</h2>
<p>rsyslogd -v #Check if rsyslog is installed rsyslogd -f
/etc/rsyslog.conf -N1 #Check Rsyslog Configuration for Errors</p>
<p>semanage port -l| grep syslog #view the current SELinux ports
settings for rsyslog semanage port -a -t syslogd_port_t -p udp 541 #add
a UDP port 541 to SELinux</p>
<p>#Verifying the Configuration</p>
<p>#On the client server logger “Test message from the system
<code>hostname</code>” nc -u 192.168.59.12 514 #verify connectivity to
remote rsyslog server TCP port 50514 telnet 192.168.59.12 50514 #verify
connectivity to remote rsyslog server TCP port 50514</p>
<p>#On the Centralized rsyslog server tail /var/log/messages<br />
tail –f /var/log/messages netstat –pnltu # Confirm That the Syslog
Server Is Listening on Port 514 ss -tunlp | grep 514 ss -4altunp | grep
514 ss -tulnp | grep “rsyslog” nc -ulp 514 #cannot telnet to UDP port
514, use netcat</p>
<p>#add the necessary UDP and/or TCP firewall rules to allow incoming
syslog traffic # systemctl restart rsyslog # firewall-cmd
–add-port=514/udp –permanent # firewall-cmd –add-port=514/tcp –permanent
# firewall-cmd –reload —————————————————————————————————- username must
contain fewer than 32 characters and start with a letter may consist of
letters, numbers, and certain symbols —————————————————————————————————-
Deleting a group does not delete all the accounts associated with the
group Groups may have passwords, these are not account login passwords
—————————————————————————————————- /etc/modprobe.d #all the modules and
other files, except for the optional configuration files stat
/lib/modules/<code>uname -r</code> #modprobe searches the module
directory more /proc/modules #a text list of the modules that the system
has loaded</p>
<p>lsmod #list of currently loaded device drivers lsmod | wc -l #total
loaded Linux kernel modules lsmod | grep nvidia #see if Linux kernel
drivers (modules) named nvidia loaded or not lsmod | egrep -i
‘nvidia|e1000e|kvm_intel’ #Search for multiple Linux device driver
modules</p>
<h2 id="modinfo-e1000-information-about-specific-driver">modinfo e1000 #
information about specific driver</h2>
<p>#KVM</p>
<p>$ egrep -c ‘(vmx|svm)’ /proc/cpuinfo | echo “virtualization is
supported” | echo “virtualization is not supported” $ egrep -c
‘(vmx|svm)’ /proc/cpuinfo &amp;&amp; echo “virtualization is supported”
|| echo “virtualization is not supported” grep -i vmx /proc/cpuinfo
#check if the CPU supports virtualization lsmod | grep kvm #check if the
kvm kernel module is loaded</p>
<p>$ grep -c ^processor /proc/cpuinfo #check that your server has (at
least) 8 CPU cores</p>
<p>To run KVM, you need a processor that supports hardware
virtualization. Intel and AMD both have developed extensions for their
processors, deemed respectively Intel VT-x (code name Vanderpool) and
AMD-V (code name Pacifica) #If 0 it means that your CPU doesn’t support
hardware virtualization. #If 1 or more it does - but you still need to
make sure that virtualization is enabled in the BIOS. <span
class="math inline"><em>e</em><em>g</em><em>r</em><em>e</em><em>p</em> − <em>c</em>′(<em>v</em><em>m</em><em>x</em>|<em>s</em><em>v</em><em>m</em>)′/<em>p</em><em>r</em><em>o</em><em>c</em>/<em>c</em><em>p</em><em>u</em><em>i</em><em>n</em><em>f</em><em>o</em></span>egrep
-q ‘vmx|svm’ /proc/cpuinfo &amp;&amp; echo yes || echo no #To use VM
drivers, verify that your system has virtualization support enabled #If
the above command outputs “no” #If you are running within a VM, your
hypervisor does not allow nested virtualization. You will need to use
the None (bare-metal) driver #If you are running on a physical machine,
ensure that your BIOS has hardware virtualization enabled $cat
/sys/hypervisor/properties/capabilities #if it is enabled or not from
xen</p>
<p>$kvm-ok #If you see You can still run virtual machines, but it’ll be
much slower without the KVM extensions INFO: Your CPU does not support
KVM extensions KVM acceleration can NOT be used</p>
<p><span class="math inline">$egrep -c ' lm ' /proc/cpuinfo #If 0 is
printed, it means that your CPU is not 64-bit. If 1 or higher it is
64-bit$</span> uname -m x86_64</p>
<p>#By default dhcpd based network bridge configured by libvirtd $ brctl
show $ virsh net-list</p>
<p>#All VMs (guest machine) only have network access to other VMs on the
same server. #A private network 192.168.122.0/24 created $ virsh
net-dumpxml default</p>
<p>virt-install –name=linuxconfig-vm<br />
–vcpus=1<br />
–memory=2048<br />
–cdrom=/media/sanchez/KARNAK/linux_distributions/CentOS-Stream-8-x86_64-20210617-dvd1.iso<br />
–disk size=5<br />
–os-variant=centos-stream8 —————————————————————————————————-</p>
<p>wc -mlw file1.txt file2.txt #Count words, characters, and lines in
multiple files<br />
ls -l *.pdf | wc -l #Count a Certain Type of Files in a Directory wc -m
yourTextFile # count the total number of characters<br />
wc -w yourTextFile #count the number of words $ wc -c file1.txt #the
number of characters in a file $ wc -l file1.txt #the number of lines in
a file $ head -5 .bash_history | wc -w # the number of words in the
first 5 lines of the file</p>
<h1 id="filecountls-wc--l">filecount=$(ls | wc -l)</h1>
<h1
id="echo-filecount------------------------------------------------------------------------------------------------------terminal1-ls-pipe2">echo
<span class="math inline">$filecount
----------------------------------------------------------------------------------------------------
# terminal1$</span> ls &gt; pipe2</h1>
<p>$ mkfifo pipe5 -m700 $ ls -l &gt; pipe5 $ rm pipe5 $rm dir1 #remove a
non-empty directory</p>
<h1 id="terminal2">terminal2</h1>
<p>$ ls -lart pipe2 # list hidden files in the current directory
prw-rw-r– 1 vagrant vagrant 0 Feb 25 15:33 pipe2 $ ls -lart pipe5 prwx——
1 vagrant vagrant 0 Feb 25 20:52 pipe5 $ cat &lt; pipe5 total 15828
prw-rw-r– 1 vagrant vagrant 0 Feb 25 15:33 pipe2 prw-rw-r– 1 vagrant
vagrant 0 Feb 25 20:51 pipe4 prwx—— 1 vagrant vagrant 0 Feb 25 20:52
pipe5 -rw-rw-r– 1 vagrant vagrant 16207833 Jan 22 22:02
terraform_0.12.20_linux_amd64.zip —————————————————————————————————-
pushd #stores a directory path in the directory stack,adds directory
paths onto a directory stack (history), allows you to navigate back to
any directory in history pushd +2 #use the directory index in the form
pushd +# or pushd -# to add directories to the stack and move into popd
#removes the top directory path from the same stack popd +1 #remove a
directory from the directory stack inded use popd +# or popd -# dirs
#display directories in the directory stack (or history) dirs -v</p>
<p>pushd $(pwd) &amp;&amp; cd /opt popd</p>
<table>
<colgroup>
<col style="width: 100%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">#from windows to linux copy problem fix $
make Makefile:21: *** missing separator. Stop. $ perl -pi -e ’s/^ */’
Makefile</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"># ls do not provide creation time but
change time $ type ll ll is aliased to `ls -alF’</td>
</tr>
<tr class="even">
<td style="text-align: left;"># -a option shows all hidden files and
directories (Those who start with .”) #the -F classify the results in
files and folders,makes it more visual when a lot of files and
directories with different extensions exist ls -alF</td>
</tr>
<tr class="odd">
<td style="text-align: left;">ls -i About-TecMint #inode</td>
</tr>
<tr class="even">
<td style="text-align: left;">The Bash shell feature that is used for
matching or expanding specific types of patterns is called globbing $ ls
-l ????.txt #files whose names are four characters long $ ls -l
foot????.doc # files whose names are 8 characters long, first 4
characters are f, o, o and t and extension is doc $ ls -l best.??? #all
files with the name ‘test’ having any extension of three characters
long</td>
</tr>
<tr class="odd">
<td style="text-align: left;">$ ls –lt #lists files in long listing
format, and sorts files based on modification time, newest first $ ls
–lth $ ls –ltr #list down files /folders sorted with modified time, -r
reverse order $ ls -ltr | grep
“<code>date | awk '{print $2" "$3}'</code>” #todays date $ ls -ltr |
grep “<span class="math inline">$(date +"%b %e")"$</span> ls -ltr |
grep”Feb 18” #current date “Mar 22” # list files on specific dates $ ls
-ltr | awk ‘$6 == “Feb” &amp;&amp; $7 &gt;=15 &amp;&amp; $7 &lt;= 31
{print $6,$7,$8,<span class="math inline">$9}' # list files after Feb
15t$</span> ls -ltr . | awk’$6 == “Feb” &amp;&amp; $7 &gt;=15 &amp;&amp;
$7 &lt;= 31 {print $6,$7,$8,$9}’ # list files after Feb 15t on specific
directory</td>
</tr>
<tr class="even">
<td style="text-align: left;">$ ls -lrt /var/log | awk ‘{ total += $5 };
END { print total }’ # sum of file sizes</td>
</tr>
<tr class="odd">
<td style="text-align: left;">$ ls -FaGl /var/log/apt | printf “%‘d”
$(awk’{SUM+=<span class="math inline">$4}END{print SUM}') #total
size$</span> ls -FaGl /var/log/apt | sudo tee /dev/stderr | printf”%‘d”
$(awk’{SUM+=<span class="math inline">$4}END{print SUM}') #list
directory contents and total size$</span> ls -laUR /var/log/apt | grep
-e “^-” | tr -s ” ” | cut -d ” ” -f5 | awk ‘{sum+=$1} END {print sum}’
#only sum up file sizes not the directory itself</td>
</tr>
<tr class="even">
<td style="text-align: left;"># total size, sum of files listed $
sumcol() &gt; { &gt; awk “{sum+=$<span class="math inline">$1} END
{print sum}"
&gt; }$</span> ls -lrt /var/log/apt/ | sumcol 5</td>
</tr>
<tr class="odd">
<td style="text-align: left;">$ ls -l | grep ‘Mar 22 12:27’ | tr -s ’ ’
| cut -d ’ ’ -f9 | xargs rm -rf #delete files on specific date</td>
</tr>
<tr class="even">
<td style="text-align: left;">#Listing of files in directory based on
last modification time of file’s status information, or the ‘ctime’
#list that file first whose any status information like: owner, group,
permissions, size etc has been recently changed. $ ls –lct #List Files
Based on Last Modification Time $ ls –ltu #Listing of files in directory
based on last access time, i.e. based on time the file was last
accessed, not modified.</td>
</tr>
<tr class="odd">
<td style="text-align: left;">#Sorting Ouptut of ls -l based on Date
#based on 6th field month wise, then based on 7th field which is date,
numerically ls -l | sort -k6M -k7n ls -l | head -n 10 | sort -k6 ls -l |
head -n 10| sort -k6M -k7n #based on 6th field month wise, then based on
7th field which is date</td>
</tr>
<tr class="even">
<td style="text-align: left;">ls -lt –time=birth #sorted by
creation/birth date time ls -l –time=creation #sorted by creation/birth
date time</td>
</tr>
<tr class="odd">
<td style="text-align: left;">$ ls -l *.pl #all files of ‘pl’
extension</td>
</tr>
<tr class="even">
<td style="text-align: left;">$ ls -l [p-s]* #all files and folders
whose name contains p or q or r or s $ ls -l [1-5]* #all files and
folders whose name starts with any digit from 1 to 5</td>
</tr>
<tr class="odd">
<td style="text-align: left;">$ ls -l {?????.sh,<em>st.txt} #files whose
names are 5 characters long and the extension is ‘sh’ or the last two
characters of the files are ‘st’ and the extension is ‘txt’ $ rm
{</em>.doc,*.docx} #delete all files whose extensions are ‘doc’ or
‘docx’</td>
</tr>
<tr class="even">
<td style="text-align: left;">$ ls a*+(.bash|.sh) #filenames which are
starting with character ‘a’ and has the extension ‘bash’ or ‘sh’</td>
</tr>
<tr class="odd">
<td style="text-align: left;">ls -alt #list files in last modifed date
order use the -t flag which is for ‘time last modified’. ls -altr #list
files in last modifed date order use the -t flag which is for ‘time last
modified’, reverse order</td>
</tr>
</tbody>
</table>
<p>echo test &gt; &gt;(cat) #the output of echo would be redirected to
the file that serves as the input to cat, and cat would produce the
contents of that file on standard output</p>
<p>echo foo | cat -n echo foo &gt; &gt;(cat -n) # emulate pipe above</p>
<p>The process substitution &gt;(command) will be replaced by a file
name. This file name corresponds to a file that is connected to the
standard input of the “command” inside the substitution</p>
<p>$ cat .profile | while read line; do ((counter1++)); done $ echo
<span
class="math inline"><em>c</em><em>o</em><em>u</em><em>n</em><em>t</em><em>e</em><em>r</em>1</span>
while read line; do ((count++)); done &lt; &lt;(cat ~/.profile) $ echo
<span class="math inline">$count
101
----------------------------------------------------------------------------------------------------
#Network Troubleshooting
Step 1: Check if your interface is configured$</span> ifconfig</p>
<p>sudo resolvconf -u</p>
<p>Step 2: Setting up your interface check if the drivers are loaded $
dmesg | grep -3 -i eth configure the interface ifconfig eth0
128.42.14.176 netmask 255.255.255.0 up Assign a Broadcast to Network
Interface ifconfig eth0 netmask 255.255.255.224 If the loopback
interface is not up ifconfig lo up now be able to ping your own machine
$ ping -c 3 127.0.0.1</p>
<p>Step 3: Check if you can ping the gateway ping the DNS server</p>
<p>Step 6: Setting up routing # route add -net <naddr> netmask <maddr>
eth0 # route add default gw <gaddr> eth0 setup the loopback route if
it’s missing # route add -host 127.0.0.1 lo</p>
<p>#Adding and removing routes ip ro add 10.0.0.0/16 via 192.0.2.253 ip
ro del 10.0.0.0/16 via 192.0.2.253 ip ro ip -6 ro #IPv6 ip route get
8.8.8.8 | sed -n ‘/src/{s/.<em>src </em>([^ ]<em>).</em>/\1/p;q}’ # IP
reaching the public internet, multiple IPs interfaces ip ro get $dst_ip
from $src_ip #Check routing path ip ro get 192.0.0.0</p>
<p>$ ip route show default via 10.0.2.2 dev eth0 proto dhcp metric 100
10.0.2.0/24 dev eth0 proto kernel scope link src 10.0.2.15 metric 100
192.168.18.0/24 dev eth1 proto kernel scope link src 192.168.18.9 metric
101</p>
<p>traffic to anywhere else should be forwarded through eth0 to the
gateway at 10.0.2.2 traffic to 10.0.2.2 (the gateway to the public
Internet) should be forwarded directly to its destination through eth0
traffic to anywhere within 192.168.18.0/24 (the local area network)
should be forwarded directly to its destination through eth1</p>
<p>$ ip route get to 192.168.18.12 from 192.168.18.9 iif eth1 $ ip route
get to 192.168.18.9 from 192.168.18.12 iif eth1</p>
<p>$ route -n route add dest_ip_address gateway_address #Add a route to
a destination through a gateway route add subnet_ip_address/24
gateway_address #Add a route to a /24 subnet through a gateway route -t
add dest_ip_address/24 gateway_address #Run in test mode (does not do
anything, just print) route flush #Remove all routes route delete
dest_ip_address/24 #Delete a specific route</p>
<p>Step 7: Name resolution 3 files: /etc/host.conf, /etc/hosts,
/etc/resolv.conf</p>
<p>/etc/host.conf: order hosts,bind multi on</p>
<p>/etc/hosts: 127.0.0.1 localhost loopback <IPaddr> this.host.name</p>
<p>/etc/resolv.conf: domain yourdept.yourcompany.com search
yourdept.yourcompany.com yourcompany.com nameserver <domainaddr></p>
<table>
<colgroup>
<col style="width: 100%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;"># ping a host ping 192.168.0.2 #show
routing table without resolving domain names netstat -nr netstat -r -n #
The flag U indicates that route is up and G indicates that it is gateway
netstat -alun | grep 161 # show informations about errors/collisions
netstat -ni # show statistics about your network card netstat -i -I em0
netstat -a netstat -at netstat -s netstat -au netstat -l netstat -lu
netstat -lt netstat -tulpn netstat -plan netstat -plan | grep “:80”
netstat -lntp | grep ‘:8080.<em>java’ &gt; /dev/null &amp;&amp; command
netstat -pan -A inet,inet6 | grep -v ESTABLISHED #determine which ports
are listening for connections from the network netstat -tlnw #Use the -l
option of the netstat command to display only listening server sockets:
netstat -plnS #Scan for Open SCTP Ports netstat -nl -A inet,inet6 | grep
2500 #Scan for Open SCTP Ports netstat -pant | grep -Ei
’apache|:80|:443’ netstat -tunlp | grep “:80” List all TCP sockets and
related PIDs netstat -antp netstat -anp List all UDP sockets and related
PIDs netstat -anup # find out on which port a program is running netstat
-ap | grep ssh #If there is an IP address instead, then the port is open
only on that specific interface #For listening ports, if the source
address is 0.0.0.0, it is listening on all available interfaces #The
Recv-Q and Send-Q fields show the number of bytes pending acknowledgment
in either direction #the PID/Program name field shows the process ID and
the name of the process responsible for the listening port or connection
netstat -anptu #number of established connection netstat -an|grep
ESTABLISHED|awk ’{print $5}’|awk -F: ’{print $1}’|sort|uniq -c|awk ’{
printf(“%s%s,$2,$1); for (i = 0; i &lt; $1; i++) {printf(”</em>”)};
print ““}’</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">#ss is the socket statistics command that
replaces netstat ss -tr #netstat -t ss -ntr #see port numbers ss -an
|grep LISTEN #netstat -an |grep LISTEN ss -an | grep 2500 #show SCTP
open ports ss -tlw # list open ports in the listening state ss -plno -A
tcp,udp,sctp #The UNCONN state shows the ports in UDP listening
mode</td>
</tr>
</tbody>
</table>
<h1 id="find-route-to-example.com">find route to example.com</h1>
<p>traceroute www.example.com #find route to example.com using
tcptraceroute (which uses tcp to discover path) tcpdraceroute
www.example.com # The maximum number of hops can be adjusted with the -m
flag. traceroute -m 255 obiwan.scrye.net # adjust the size of the packet
that is sent to each hop by giving the integer after the hostname
traceroute google.com 70</p>
<p>Specify Gateway sudo traceroute -g 10.0.2.2 yahoo.com traceroute -g
192.5.146.4 -g 10.3.0.5 35.0.0.0 #shows the path of a packet that goes
from istanbul to sanfrancisco through the hosts cairo and paris #The -I
option makes traceroute send ICMP ECHO probes to the host sanfrancisco
#The -i options sets the source address to the IP address configured on
the interface qe0 traceroute -g cairo -g paris -i qe0 -q 1 -I
sanfrancisco ip r / ip route #gateway / router ip r | grep default
#default gateway route -n # The flag U indicates that route is up and G
indicates that it is gateway route -nee netstat -r -n # The flag U
indicates that route is up and G indicates that it is gateway routel
#list routes routel | grep default #default gateway</p>
<p>Specify Source Interface sudo traceroute -i eth0 yahoo.com Autonomous
Systems traceroute -A yahoo.com</p>
<p>tracepath yahoo.com tracepath -n yahoo.com tracepath -b yahoo.com
sets the initial packet length tracepath -l 28 yahoo.com set maximum
hops (or maximum TTLs) to max_hops tracepath -m 5 yahoo.com set the
initial destination port to use tracepath -p 8081 yahoo.com</p>
<p>hostname -f #show fully qualified domain name (FQDN) hostname
#shortname hostname -I #the primary/first IP address hostname -I | awk
‘{print $1}’ # get primary/first IP IP address of server hostname -I |
awk ‘{print $2}’ # get second IP IP address of server</p>
<p>real-time view of the current state of your system $ htop</p>
<p>$ timedatectl $ timedatectl list-timezones $ sudo timedatectl
set-timezone ‘Africa/Lubumbashi’</p>
<h1 id="enable-ntp-synchronization">Enable NTP synchronization</h1>
<p>timedatectl set-ntp true timedatectl status</p>
<h1 id="show-connected-sockets">show connected sockets</h1>
<p>sockstat -c # show listening sockets and processes sockstat -l</p>
<h1 id="show-arp-table">show arp table</h1>
<p>arp -a #Show current arp tabl arp -na ip neighbour #Show neighbors
(ARP table) arp -d 192.168.0.2 # delete a record from arp table sudo arp
-a -d #Clear the entire cach arp -s 192.168.0.2 00:10:b5:99:bf:c4 #add a
static record in arp table # listen on em0 network interface and sniff
packets that pass via em0 $ sudo arp -i eth0</p>
<p>find out reachability of an IP on the local Ethernet with arping i.e
send ARP request 192.168.1.1: $ sudo arping -I eth0 -c 3 192.168.18.12 $
sudo arping -I eth1 -c 3 192.168.18.12 Find duplicate IP $ sudo arping
-D -I eth1 -c 3 192.168.18.12</p>
<p>ping -I eth0 8.8.8.8 #ping 8.8.8.8 using eth0 as a source interface
ping google.com ping -6 hostname/IPv6 #request IPv6 or IPv4 address ping
-4 hostname/IPv4 #The default interval between each ping request is set
to one second. You can increase or decrease that time using the –i
switch #decrease the ping interval, use values lower than 1 ping -i 0.5
google.com ping -s 1000 google.com #use -s to increase the packet size
from the default value of 56 (84) bytes. ping -f hostname-IP #use ping
flood to test your network performance under heavy load ping -c 2
google.com #Limit Number of Ping Packets ping -w 25 google.com #stop
printing ping results after 25 seconds ping -c 10 -q google.com #The
letter “q” in this command stands for “quiet” output. ping -D google.com
#Add Timestamp Before Each Line in ping Output</p>
$ file * 20:30: empty file1: ASCII text file2: ASCII text $ file
raw_file.txt #if a text file contains ASCII or Unicode $ file -b
symbolic_test1.txt symbolic link to test1.txt
—————————————————————————————————– # parse html with curl curl -s
https://miloserdov.org/ | grep -E -o ’
<h3 class="ftitle">
.*
</h3>
’ | sed ’s/
<h3 class=ftitle>
//’ | sed ‘s/&lt;/h3&gt;//’ curl http://test.com | sed -rn ’s@(^.*
<dd>
)(.*)(
</dd>
<p>)@\2@p’</p>
cat - &gt; file.html &lt;&lt; EOF
<div class="tracklistInfo">
<p class="artist">
Diplo - Justin Bieber - Skrillex
</p>
<p>
Where Are U Now
</p>
</div>
<div class="tracklistInfo">
<p class="artist">
toto
</p>
<p>
tata
</p>
</div>
EOF cat file.html | tr -d ‘’ | sed -e “s/&lt;/div&gt;/&lt;/div&gt;/g” |
sed -n ’s/^.<em>class=“artist”&gt;([^&lt;]</em>)&lt;/p&gt; *
<p>
([^&lt;]<em>)&lt;.</em>$/artist : \1: \2/p’ cat file.html | grep -A2 -E
-m 1 ’
<div class="tracklistInfo">
’ cat file.html | grep -A2 -E -m 1 ’
<div class="tracklistInfo">
’ | tail -n1 cat file.html | grep -A2 -E -m 1 ’
<div class="tracklistInfo">
’ | tail -n2 | head -n1 cat file.html | grep -A2 -E -m 1 ’
<div class="tracklistInfo">
<h2 id="tail--n2-head--n1-sed-sg">’ | tail -n2 | head -n1 | sed
’s/&lt;[^&gt;]*&gt;//g’</h2>
<p>Check what ethernet devices exist currently # ls -al /sys/class/net #
ls -Rl list hidden files and the contents of all subdirectories ls -aR
/home/username # ls -pu see eth* devices # ls -al /sys/class/net Get the
PCI address of the NIC # lspci | grep Mellanox # lspci | grep Eth</p>
<p>iw distinguishes between wireless LAN hardware devices (the physical
layer, referred to as phy) and the network interface configured to use
that hardware (e.g. wlan0, similar to an Ethernet eth0 interface). To
see the list of devices, and interfaces for each device #iw dev</p>
<p>**MAC_ADDRESS 08:00:27:e3:b0:01 $ ip link show eth1 3: eth1:
&lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state
UP mode DEFAULT group default qlen 1000 link/ether 08:00:27:e3:b0:01 brd
ff:ff:ff:ff:ff:ff $ ip addr show eth1 3: eth1:
&lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state
UP group default qlen 1000 link/ether 08:00:27:e3:b0:01 brd
ff:ff:ff:ff:ff:ff inet 192.168.1.253/24 brd 192.168.1.255 scope global
noprefixroute eth1 valid_lft forever preferred_lft forever inet6
fe80::a00:27ff:fee3:b001/64 scope link valid_lft forever preferred_lft
forever</p>
<p>#temporarily set the IP address ifconfig eth0 192.168.8.185 ifconfig
eth0 192.168.8.185 netmask 255.255.255.0 up #temporarily change the MAC
address ifconfig eth0 down hw ether AA:BB:CC:DD:EE:FF &amp;&amp;
ifconfig eth0 up ifconfig eth0 netmask 255.255.255.0 ifconfig eth0
broadcast 192.168.70.255</p>
<p>ip addr show -&gt; List IP address of the server ip addr show eth0 ip
addr | grep inet6 #check that your server supports IPV6 ip addr show
eth1 | grep “inet” ip addr add 10.132.1.1/24 dev eth1 -&gt; Add a new
IP4 address ip addr show eth1 -&gt; confrm that the new address is
available on the interface</p>
<p>ip link set eth2 down -&gt; bring an interface down<br />
ip link set eth2 up</p>
<p>ip -s link-&gt;view basic network statistics on all interfaces ip -s
link ls eth0 -&gt;see the statistics for the eth0 interface ip -s -s
link ls eth0 -&gt;see additional info</p>
<p>ss -t -&gt;show established TCP connections ss -u -&gt;show
established UDP connections ss -A tcp ss -x ss -ltn -&gt;see which ports
are listening for connections ss -nt ss -ltn ss -ua ss -a -A udp ss -lun
-&gt;udp ss -s-&gt;prints out the statistics</p>
<p>#Install sysstat package # /etc/default/sysstat ENABLED=“true” #sudo
service sysstat restar vmstat 1 99999 -&gt;the system statistics every
second, for the number of times specifed (99999 in this instance) vmstat
–a 1 99 -&gt;show memory usage information vmstat -a -S M 1 9 -&gt;
reformat in Mega Bytes vmstat 1 99999 -&gt;gather information for disks
and other block devices vmstat -d -w iostat 1 9 -&gt;CPU information and
disk information for all devices iostat -d -p sda 1 9-&gt; show
information for device sda with disk statistics sar -u 1 30 -&gt;
display CPU statistics every second for 30 seconds sar -r 1 30 -&gt;
display memoru statistics every second for 30 seconds sar -b 1 30 -&gt;
display block device statistics every second for 30 seconds</p>
<p>#=====================================================================</p>
<h1
id="curl-the-binay-version-info-from-latest-download-and-later-wget-the-file-with">curl
the binay version info from latest download and later wget the file
with</h1>
<p><span class="math inline">$curl -s
https://api.github.com/repos/prometheus/prometheus/releases/latest \
| grep browser_download_url \
| grep linux-amd64 \
| cut -d '"' -f 4 \
| wget -qi -$</span> ls prometheus-2.37.0.linux-amd64.tar.gz <span
class="math inline"><em>t</em><em>a</em><em>r</em><em>x</em><em>v</em><em>f</em><em>p</em><em>r</em><em>o</em><em>m</em><em>e</em><em>t</em><em>h</em><em>e</em><em>u</em><em>s</em> * .<em>t</em><em>a</em><em>r</em>.<em>g</em><em>z</em></span>cd
prometheus*/</p>
<p>#specify directory and rename the file wget
–output-document=“/home/my_new_file_name” http://someurl #add the
appropriate BeeGFS repositories wget -o
/etc/yum.repos.d/beegfs-rhel7.repo
http://www.beegfs.com/release/beegfs_2015.03/dists/beegfs-rhel7.repo
wget -q https://www.virtualbox.org/download/oracle_vbox.asc -O- |
apt-key add -</p>
<p>wget example.com/big.file.iso #start download and stop download
ctrl+c key pair wget -c example.com/big.file.iso #resume download</p>
<p>wget ‐‐continue example.com/big.file.iso #Resume an interrupted
download previously started by wget itself wget ‐‐continue
‐‐timestamping wordpress.org/latest.zip #Download a file but only if the
version on server is newer than your local copy wget ‐‐page-requisites
‐‐span-hosts ‐‐convert-links ‐‐adjust-extension
http://example.com/dir/file #Download a web page with all assets - like
stylesheets and inline images - that are required to properly display
the web page offline. wget -q http://somesite.com/TheFile.jpeg #-q: Turn
off wget’s output wget http://example.com/images/{1..20}.jpg # Download
a list of sequentially numbered files from a server wget -m -r -linf -k
-p -q -E -e robots=off http://127.0.0.1 # Download a complete website
wget ‐‐mirror ‐‐domains=abc.com,files.abc.com,docs.abc.com ‐‐accept=pdf
http://abc.com/ #Download the PDF documents from a website through
recursion but stay within specific domains. wget ‐‐execute robots=off
‐‐recursive ‐‐no-parent ‐‐continue ‐‐no-clobber http://example.com/
#Download an entire website including all the linked pages and files
wget ‐‐level=1 ‐‐recursive ‐‐no-parent ‐‐accept mp3,MP3
http://example.com/mp3/ #Download all the MP3 files from a sub-directory
wget –recursive –no-clobber –page-requisites –html-extension
–convert-links –restrict-file-names=windows –domains some-site.com
–no-parent www.some-site.com #Download Entire Website wget ‐‐recursive
‐‐no-clobber ‐‐no-parent ‐‐exclude-directories /forums,/support
http://example.com #Download all files from a website but exclude a few
directories wget –reject=png www.some-site.com #Reject file types while
downloading wget -r -A .pdf http://some-site.com/ #Download all PDF
files from a website wget -r -H –convert-links –level=NUMBER
–user-agent=AGENT URL #Download With Wget Recursively,declare a user
agent such as Mozilla (wget –user-agent=AGENT) wget -e
https_proxy=xx.xx.xx.xx:8080 https://example.com/ #use proxy server with
wget</p>
<p>wget -S –spider http://www.uniqlo.com/ #Only Header Information</p>
<p>##if link exists
url=“https://www.katacoda.com/courses/kubernetes/launch-single-node-cluster”
if wget –spider “$url” 2&gt;/dev/null; then #2&gt; /dev/null silences
wget’s stderr output echo “URL exists: $url” else echo echo “URL does
not exist: $url” fi</p>
<p>#connect to a remote server,start download on the remote
server,disconnect from the remote server,let it run on the background $
nohup wget -q url &amp;</p>
<p>wget -i file.txt #Read download URLs from a file,useful in a shell
script.</p>
<p>#one liner if condition wget –spider http://192.168.50.15/<span
class="math inline">${distribution}_$</span>{codename}_oscap_report.html
2&gt;/dev/null &amp;&amp; echo “link exists” || echo “link does not
exist”</p>
<p>wget –spider -S “www.magesh.co.in” 2&gt;&amp;1 | awk ‘/HTTP// {print
$2}’ #see only the HTTP status code wget –spider -o wget.log -e
robots=off –wait 1 -r -p http://www.mysite.com/ #crawl a website and
generate a log file of any broken links</p>
<p>wget –spider https://example.com/filename.zip 2&gt;&amp;1 | grep
Length #file download size without downloading the actual file wget
‐‐spider ‐‐server-response http://example.com/file.iso #Find the size of
a file without downloading it (look for ContentLength in the response,
the size is in bytes)</p>
<p>wget ‐‐output-document - ‐‐quiet google.com/humans.txt #Download a
file and display the content on the screen without saving it locally
wget ‐‐server-response ‐‐spider http://www.labnol.org/ #the last
modified date of a web page (check the LastModified tag in the HTTP
header) wget ‐‐output-file=logfile.txt ‐‐recursive ‐‐spider
http://example.com #Check the links on your website to ensure that they
are working. The spider option will not save the pages locally. wget
‐‐limit-rate=20k ‐‐wait=60 ‐‐random-wait ‐‐mirror example.com # limited
the download bandwidth rate to 20 KB/s and the wget utility will wait
anywhere between 30s and 90 seconds before retrieving the next resource.
wget -O index.html –certificate=OK.crt –private-key=OK.key
https://example.com/ #Client SSL Certificate wget -q -O -
–header=“Content-Type:application/json” –post-file=foo.json
http://127.0.0.1 # POST a JSON file and redirect output to stdout wget
-O wget.zip http://ftp.gnu.org/gnu/wget/wget-1.15.tar.gz #Download file
with different name wget -o download.log
http://ftp.gnu.org/gnu/wget/wget-1.15.tar.gz #redirect the wget command
logs to a log file using ‘-o‘ switch. wget
‐‐output-document=filename.html example.com #Download a file but save it
locally under a different name wget ‐‐directory-prefix=folder/subfolder
example.com #Download a file and save it in a specific folder wget -r -l
inf -A .png,.jpg,.jpeg,.gif -nd https://jekyllrb.com # Download all
images of a website wget -r –level=1 -H –timeout=1 -nd -N -np
–accept=mp3 -e robots=off -i musicblogs.txt #take a text file of your
favourite music blogs and download any new MP3 files wget –ftp-user=User
–ftp-password=Mir URL # FTP download wget
http://ftp.gnu.org/gnu/wget/wget-1.15.tar.gz
ftp://ftp.gnu.org/gnu/wget/wget-1.14.tar.gz.sig #Download multiple file
with http and ftp protocol wget -i /wget/urls.txt #Read URL’s from a
file wget -Q10m -i download-list.txt #Setting Download Quota wget -c
http://ftp.gnu.org/gnu/wget/wget-1.15.tar.gz #Resume download wget -b
/wget/log.txt http://ftp.gnu.org/gnu/wget/wget-1.15.tar.gz #Download
files in background wget -b -c –tries=NUMBER URL #number of tries (wget
–tries=NUMBER), continue partial download (wget -c) wget -b
–limit-rate=SPEED -np -N -m -nd –accept=mp3 –wait=SECONDS
http://www.uniqlo.com/ #no parent to ensure you only download a
sub-directory (wget -np),update only changed files (wget -N), mirror a
site (wget -m), ensure no new directories are created (wget -nd), accept
only certain extensions (wget –accept=LIST) wget -c –limit-rate=100k
/wget/log.txt http://ftp.gnu.org/gnu/wget/wget-1.15.tar.gz #Limit
download speed wget –http-user=username –http-password=password
http://some-network.net/some-file.txt #Options –http-user=username,
–http-password=password wget –ftp-user=username –ftp-password=password
ftp://some-network.net/some-file.txt #–ftp-user=username,
–ftp-password=password wget –tries=75
http://ftp.gnu.org/gnu/wget/wget-1.15.tar.gz #Increase Retry Attempts.
wget ‐‐refer=http://google.com ‐‐user-agent=“Mozilla/5.0 Firefox/4.0.1”
http://nytimes.com #Wget can be used for downloading content from sites
that are behind a login screen or ones that check for the HTTP referer
and the User-Agent strings of the bot to prevent screen scraping. wget
‐‐cookies=on ‐‐save-cookies cookies.txt ‐‐keep-session-cookies
‐‐post-data ’user=labnol&amp;password=123’ http://example.com/login.php_
_wget ‐‐cookies=on ‐‐load-cookies cookies.txt ‐‐keep-session-cookies
http://example.com/paywall #Fetch pages that are behind a login page.
You need to replace user and password with the actual form fields while
the URL should point to the Form Submit (action) page. wget ‐‐span-hosts
‐‐level=inf ‐‐recursive dmoz.org # wget -r –level=inf -p -k -E
–span-hosts –domains=domainA,domainB http://www.domainA #download an
entire site (domain A) when its resources are on another domain, (domain
B) wget –page-requisites –convert-links –adjust-extension –span-hosts
–domains domainA,domainB domainA # wget –recursive –level=inf
–page-requisites –convert-links –html-extension -rH -DdomainA,domainB
domainA # wget –recursive –level=inf –page-requisites –convert-links
–adjust-extension –span-hosts –domains=domainA,domainB domainA #</p>
<p>#=====================================================================
sudo permission denied The redirection to a file is handled by bash. It
does therefore not inherit permissions granted by sudo. “sudo tee” for
writing to a file as root.</p>
<p>lsblk -f -&gt; when used with the -f option, it prints file system
type on partitions sudo file -sL /dev/sdb1 -&gt; file system type on
partitions lsblk -f lsblk -l lsblk –scsi lsblk -o
name,type,fstype,label,partlabel,model,mountpoint,size lsblk –json | jq
-c ‘.blockdevices[]|[.name,.size]’</p>
<p>#/etc/fstab explained, Each field can be separated by another either
by spaces or tabs</p>
<p>First field – The block device,reference a block device is by using
its LABEL or UUID (Universal Unique IDentifier) $ lsblk -d -fs /dev/sdb1
# get UUID</p>
<p>Second field – The mountpoint Third field – The filesystem type
Fourth field – Mount options, use the default set of mount options we
specify default as a value Fifth field – Should the filesystem be
dumped?, either 0 or 1,used by the dump backup program (if
installed)</p>
<p>Sixth field – Fsck order;fsck utility, should check filesystems on
boot; value of 1 must always be used for the root filesystem if not root
filesystem,for all the others, value of 2 If not provided it defaults to
0</p>
<h1 id="generate-traces-of-the-io-traffic-on-block-devices">generate
traces of the i/o traffic on block devices</h1>
<p>“sudo blktrace -d /dev/sda -o - | blkparse -i -”</p>
<p>#writing ISO usb bootable sudo umount /dev/sdX sudo dd
if=/path/to/ubuntu.iso of=/dev/sdX bs=4M &amp;&amp; sync sdx-&gt; lslbk
command sync-&gt; sync bit is important as dd can return before the
write operation finishes.</p>
<h1 id="mount-all-file-systems-on-etcfstab">mount all file systems on
/etc/fstab</h1>
<p>mount -a mount -fav cat /proc/mounts # format linux swap partition
mkswap ——————————————————————————————————————– #search man pages</p>
<p>man -k . #List all available man pages on the system and provide a
short description man -f virt-manager # Keyword must be the exact name
of a man page man -K date -&gt; display a list of all manual pages
containing the keyword “date” man -wK word -&gt;list out all manual
files with some word. man -wK –regex “ipv4.<em>listen” man –regex
”.</em>network$”</p>
<p>#search through all man pages on a system for the specified keyword
and output the location of any man pages that contain that keyword man
-S 1 –regex “^virsh”</p>
<p>man yum | less +/“install @” #search “install @” pattern in man yum
page man -P ‘less -p install’ yum #search “install” pattern in man yum
page ——————————————————————————————————————– # Clone / Compile specific
kernel sudo git clone
git://git.kernel.org/pub/scm/linux/kernel/git/stable/linux-stable.git
linux -&gt; latest stable kernel to “linux” directory git tag -l | grep
v4.9.1 -&gt; find specific kernel version git checkout -b kernel490
v4.9.1 -&gt; switch to kernel with custom name “kernel490”</p>
<p>#tail -f vs less +F #tail -f only reads the end of the file #tail -f
doesn’t keep the whole file in memory. tail -f /var/log/syslog #less +F
reads the whole file #less +F impractical for very large files. #less +F
can highlight, search, navigate through file #hit Ctrl-c to go to
“normal” less mode (as if you had opened the file without the +F flag)
#the search with /foo,next or previous occurrence with n or N, up and
down with j and k,, create marks with m #hit F to go back to watching
mode less +F /var/log/syslog</p>
<p>less -n +F #read only the end of the file</p>
<p>tail -100f /var/log/messages | grep -V ACPI | grep -i ata #real-time
monitoring,tailing 100 lines from the end tail -f
/var/log/nginx/access.log /var/log/nginx/access.log #watching multiple
files</p>
<p>#top 10 internet protocol addresses hitting a webserver from the
access log cat /var/log/nginx/access.log | cut -f 1 -d ’ ’ | sort | uniq
-c | sort -hr | head -n 10</p>
<p>multitail /var/log/auth.log /var/log/kern.log #shows the contents of
log files horizontally multitail -s 2 /var/log/auth.log
/var/log/kern.log #view the contents of log files vertically in two
columns multitail -s 2 /var/log/syslog, /var/log/kern.log,
/var/log/daemon.log and var/log/messages multitail -s 2 -ci green
/var/log/auth.log -ci blue /var/log/kern.log lnav /var/log/syslog
/var/log/messages lnav a.zip b.zip
——————————————————————————————————————– #crontab Display scheduled jobs
for the specified user crontab -l -u vagrant crontab -l # Display Cron
Table ls -la /etc/cron*</p>
<p>sudo crontab -u user -e # crontab -e #when running as a non-root user
sudo crontab -e #the root user’s crontab</p>
<p>#If the /etc/cron.allow file exists, then users must be listed in it
in order to be allowed to run the crontab command #If the
/etc/cron.allow file does not exist but the /etc/cron.deny file does,
#then users must not be listed in the /etc/cron.deny file in order to
run crontab #If the /etc/cron.allow file exists, then users must be
listed in it in order to be allowed to run the crontab command
/etc/cron.deny # If a blank cron.deny file has been created, cron only
available to root or users in cron.allow.</p>
<h1 id="delete-all-cron-jobs">Delete All Cron Jobs</h1>
<p>crontab -r crontab -r -i #the command prompt to confirm # All scripts
in each directory are run as root #Cron jobs may not run with the
environment, in particular the PATH, that you expect. Try using full
paths to files and programs #The “%” character is used as newline
delimiter in cron commands. If you need to pass that character into a
script, you need to escape it as “%”. #anacron uses the run‑parts
command and /etc/cron.hourly, /etc/cron.weekly, and /etc/cron.monthly
directories. #anacron itself is invoked from the /etc/crontab file #user
crontabs /etc/cron.hourly/, /etc/cron.daily/, /etc/cron.weekly/, and
/etc/cron.monthly/ ls -la /etc/cron.daily/ #View daily cron jobs</p>
<p>crontab -l &gt; backup_cron.txt #Backup All Cron Jobs</p>
<p>/etc/crontab #not recommended that you add anything,this could cause
a problem if the /etc/crontab file is affected by updates /etc/cron.d
#not be affected by updates, several people might look after a server,
then the directory /etc/cron.d is probably the best place to install
crontabs /etc/cron.d #These files also have username fields</p>
<p>#the files inside /etc/cron.d chown root:root /etc/cron.d/<em> chmod
go-wx /etc/cron.d/</em> chmod -x /etc/cron.d/*</p>
<p>$ cat /etc/cron.allow barak $ sudo systemctl restart cron $ cat
/etc/cron.d/barak_job <em>/1 </em> * * * barak echo “Nightly Backup
Successful: $(date)” &gt; /tmp/test1_job.log <em>/1 </em> * * *
/usr/bin/free -m | awk ‘{ if($1 == “Mem:” ) print $3}’ | awk ‘{ if ( $1
&gt; 140 ) print $0; else print “less” }’ &gt;&gt; /tmp/memo.log</p>
<p>#troubleshooting cron $ cat /etc/cron.d/barak_job <em>/1 </em> * * *
barak echo “Nightly Backup Successful: $(date)” &amp;&gt;
/tmp/test1_job.log #redirect stdout and stderr to a file. <em>/1 </em> *
* * barak echo “Nightly Backup Successful: $(date)” &gt;
/tmp/test1_job.log2 2&gt;&amp;1 #redirect stdout and stderr to a
file.</p>
<p>#php specific php /bla/bla/something.php &gt;&gt;
/var/logs/somelog-for-stdout.log #the only difference from the syntax of
the user crontabs is that the line specifies the user to run the job as
00 01 * * * rusty /home/rusty/rusty-list-files.sh #run Rusty’s command
script as user rusty from his home directory.</p>
<p>/usr/bin/php /home/username/public_html/cron.php #Execute PHP script:
mysqldump -u root -pPASSWORD database &gt; /root/db.sql #MySQL dump:
/usr/bin/wget –spider “http://www.domain.com/cron.php” #Access URL:</p>
<p>$ cat /etc/cron.allow barak $ sudo systemctl restart cron/crond $ cat
/etc/cron.d/barak_job <em>/1 </em> * * * barak echo “Nightly Backup
Successful: <span class="math inline">$(date)" &gt;&gt;
/tmp/mybackup.log$</span> crontab -u barak -l #<em>/1 </em> * * * barak
echo”Nightly Backup Successful: <span class="math inline">$(date) runs"
&gt;&gt; /tmp/barak_job.log$</span> sudo tail -f /var/log/syslog | grep
–color=auto CRON</p>
<p>crontab -e <span class="citation" data-cites="hourly">@hourly</span>
echo “Nightly Backup Successful: $(date)” &gt;&gt; /tmp/mybackup.log</p>
<p>#“-u borg” is used take the identity of the borg user # cat
/etc/cron.daily/borgbackup_check #!/bin/bash sudo -u borg borg check
/borgbackup &gt;&gt; /var/log/borgbackup.log</p>
<p>#once every 5 minutes cat | sudo tee /etc/cron.d/cron-mrtg &lt;&lt;
EOF <em>/5 </em> * * * env LANG=C /usr/bin/mrtg /etc/mrtg.cfg EOF
#verify cat /etc/cron.d/cron-mrtg crontab -l</p>
<p>cat | sudo tee /etc/cron.d/sysinfo &lt;&lt; EOF #once every 5 minutes
<em>/5 </em> * * * /bin/bash /home/vagrant/sysinfo_func.sh EOF #verify
cat /etc/cron.d/cron-mrtg</p>
<ul>
<li><ul>
<li><ul>
<li><ul>
<li><ul>
<li>/bin/date &gt;&gt; /tmp/cron_output #This will append the current
date to a log file every minute.</li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
<li><ul>
<li><ul>
<li><ul>
<li><ul>
<li>/usr/bin/php /var/www/domain.com/backup.php &gt; /dev/null
2&gt;&amp;1 #run a script but keep it running in the background at
specific time 00 15 * * 4 sh /root/test.sh 35 21 * * 7 /bin/date
&gt;&gt; /tmp/cron_output every 5 minutes <em>/5 </em> * * * mycommand
an hourly cron job but run at minute 15 instead (i.e. 00:15, 01:15,
02:15 etc.): 15 * * * * [command] once a day, at 2:30am: 30 2 * * *
[command] once a month, on the second day of the month at midnight
(i.e. January 2nd 12:00am, February 2nd 12:00am etc.): 0 0 2 * *
[command] on Mondays, every hour (i.e. 24 times in one day, but only on
Mondays): 0 * * * 1 [command] three times every hour, at minutes 0, 10
and 20: 0,10,20 * * * * [command] # Stop download Mon-Fri, 6am 0 6 * *
1,2,3,4,5 root virsh shutdown download <em>/5 </em> * * *
/path/to/some-script.sh #every 5 minutes <span class="citation"
data-cites="reboot">@reboot</span> /scripts/script.sh #tasks to execute
on system reboot <span class="citation"
data-cites="hourly">@hourly</span> /scripts/script.sh #execute on an
hourly. 0 * * * <em>/scripts/script.sh #execute on an hourly. <span
class="citation" data-cites="daily">@daily</span> /scripts/script.sh #
execute on a daily basis. 0 2 </em> * * /scripts/script.sh # executes
the task in the second minute of every day.# <span class="citation"
data-cites="weekly">@weekly</span> /bin/script.sh #execute on a weekly
basis 0 0 4 * sun /bin/script.sh #execute on a weekly basis <span
class="citation" data-cites="monthly">@monthly</span> /scripts/script.sh
#execute on a monthly basis 0 0 1 * * /scripts/script.sh #execution of a
task in the first minute of the month <span class="citation"
data-cites="yearly">@yearly</span> /scripts/script.sh #schedule tasks on
a yearly basis. <span class="citation"
data-cites="yearly">@yearly</span> /scripts/script.sh #executes the task
in the fifth minute of every year.</li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
<li><ul>
<li><ul>
<li><ul>
<li><ul>
<li>sleep 15; /scripts/script.sh #schedule a cron to execute after every
15 Seconds 0 4,17 * * mon,tue /scripts/script.sh #execute twice on
Monday and Tuesday 0 17 * * mon,wed /script/script.sh #run each Monday
and Wednesday at 5 PM 0 7,17 * * * /scripts/script.sh #execute at 7 AM
and 5 PM daily 0 5 * * mon /scripts/script.sh #execute the task on every
Monday at 5 AM 0 <em>/6 </em> * * /scripts/script.sh #run a script for 6
hours interval 0 8-10 * * * /scripts/script.sh # run every hour between
08-10AM 0 2 * * sat [ <span class="math inline">$(date +%d) -le 06 ]
&amp;&amp; /script/script.sh #execute on first Saturday of every month
0   12  1-7 *   *   [ "$</span>(date ‘+%a’)” = “Mon” ] &amp;&amp; echo
“It’s Monday” #on the first Monday of every month</li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
<li><ul>
<li><ul>
<li><h2
id="febjunsep-scriptscript.sh-run-tasks-in-feb-june-and-september-months">feb,jun,sep
* /script/script.sh #run tasks in Feb, June and September months</h2>
tail -n 1 /usr/share/dict/words #limit the number of lines to show tail
-c 24 /usr/share/dict/words #limit the number of bytes to show tail
/usr/share/dict/words /usr/share/dict/french #show the last ten lines of
multiple files tail -n 5 file_1 file_2 tail -n +N <filename> #the lines
starting from line number N tailf -F /var/log/syslog #monitoring the log
file even at its rotation tail -q /usr/share/dict/words
/usr/share/dict/french #suppress the header line pass the -q option ls
-t /etc | tail -n 5 #show the five files or folders modified the longest
time ago</li>
</ul></li>
</ul></li>
</ul>
<h2 id="brctl-show---bridge-connections">#brctl show -&gt; Bridge
connections</h2>
<p>#LVM pvdisplay pvck pvs lvscan lvdisplay lvmdiskscan vgchange vgscan
-a y e4defrag -cv /path/to/myfiles (defrag folder )</p>
<p>$ sudo pvcreate /dev/sdb $ sudo pvs PV VG Fmt Attr PSize PFree
/dev/sda2 centos lvm2 a– &lt;63.00g 4.00m /dev/sdb vg_iscsi lvm2 a–
&lt;30.00g 0 $ sudo pvdisplay — Physical volume — PV Name /dev/sdb VG
Name vg_iscsi PV Size 30.00 GiB / not usable 4.00 MiB Allocatable yes
(but full) PE Size 4.00 MiB Total PE 7679 Free PE 0 Allocated PE 7679 PV
UUID hG93NW-gvRB-njUP-pgj8-omRF-YzFe-rTMWOz</p>
<p>— Physical volume — PV Name /dev/sda2 VG Name centos PV Size
&lt;63.00 GiB / not usable 3.00 MiB Allocatable yes PE Size 4.00 MiB
Total PE 16127 Free PE 1 Allocated PE 16126 PV UUID
rFHI2D-fvZw-Mf2P-gKTC-ZTwt-vdiY-TEQc14</p>
<p>$ sudo vgcreate vg_iscsi /dev/sdb $ sudo vgdisplay — Volume group —
VG Name vg_iscsi System ID Format lvm2 Metadata Areas 1 Metadata
Sequence No 2 VG Access read/write VG Status resizable MAX LV 0 Cur LV 1
Open LV 0 Max PV 0 Cur PV 1 Act PV 1 VG Size &lt;30.00 GiB PE Size 4.00
MiB Total PE 7679 Alloc PE / Size 7679 / &lt;30.00 GiB Free PE / Size 0
/ 0 VG UUID j63noX-S9I0-5Gp0-3FPg-IZ23-oZNK-6qpb7X $ sudo lvcreate -l
100%FREE -n lv_iscsi vg_iscsi [vagrant@vg-suricata-30 ~]$ sudo lvscan
ACTIVE ‘/dev/vg_iscsi/lv_iscsi’ [&lt;30.00 GiB] inherit ACTIVE
‘/dev/centos/swap’ [2.00 GiB] inherit ACTIVE ‘/dev/centos/home’
[&lt;20.01 GiB] inherit ACTIVE ‘/dev/centos/root’ [40.98 GiB] inherit $
sudo lvdisplay — Logical volume — LV Path /dev/vg_iscsi/lv_iscsi LV Name
lv_iscsi VG Name vg_iscsi LV UUID exEdIG-s2bK-vFEa-fD3X-dplu-q2W3-1rTXsE
LV Write Access read/write LV Creation host, time vg-suricata-30,
2019-12-18 12:35:56 +0000 LV Status available # open 0 LV Size &lt;30.00
GiB Current LE 7679 Segments 1 Allocation inherit Read ahead sectors
auto - currently set to 8192 Block device 253:3</p>
<p>$ sudo vgremove vg_iscsi $ sudo pvremove /dev/sdb
——————————————————————————————————————– #troubleshooting prometheus</p>
<p>#Shutting down Prometheus lsof -n -i4TCP:9090 #find a process
(Prometheus) listening on port 9090 pgrep -f prometheus curl -X POST
:9090/-/quit curl -X POST http://localhost:9090/-/quit # (when the
–web.enable-lifecycle flag is enabled)</p>
<p>#Prometheus Reload curl -i -XPOST localhost:9090/-/reload killall
-HUP prometheus</p>
<p>./promtool check config prometheus.yml #check if prometheus.yml is
valid</p>
<p>journalctl –boot | grep prometheus</p>
<p>#reload Prometheus config file kill -HUP 9783
——————————————————————————————————————–</p>
<p>#list open files lsof #list open files owned by user1 lsof -u user1
#list open file via tcp lsof -i TCP:1-1024 lsof -i TCP:80 PID 27808 lsof
-Pan -p 27808 -i lsof -p 2</p>
<h1 id="troubleshooting-1">troubleshooting #1</h1>
<p>find all the opened files and processes along with the one who opened
them # lsof –p PID Count number of files &amp; processes # lsof -p 4271
| wc -l Check the currently opened log file lsof –p | grep log Find out
port number used by daemon # lsof -i -P |grep 4271</p>
<h1
id="find-out-what-running-processes-are-associated-with-each-open-port-on-linux">find
out what running processes are associated with each open port on
Linux</h1>
<p>netstat -nlp|grep 9000 sudo ss -lptn ‘sport = :80’ sudo netstat -nlp
| grep :80 sudo lsof -n -i :80 | grep LISTEN fuser 3306/tcp fuser 80/tcp
ss -tanp | grep 6379 fuser -v -n tcp 22 sudo netstat -ltnp | grep -w
‘:80’ netstat -tulpn | grep :80 netstat -tulpn ls -l /proc/1138/exe sudo
ss -tulpn sudo ss -tulpn | grep :3306 fuser 7000/tcp ls -l
/proc/3813/exe man transmission whatis transmission # find out current
working directory of a process pid 3813 ls -l /proc/3813/cwd pwdx 3813 #
Find Out Owner Of a Process on Linux cat /proc/3813/environ grep –color
-w -a USER /proc/3813/environ lsof -i :80 | grep LISTEN # The file
/etc/services is used to map port numbers and protocols to service names
grep port /etc/services grep 443 /etc/services</p>
<p>#Start a Linux Process or Command in Background $ tar -czf
home.tar.gz . $ tar -tvf home.tar.gz # list the contents of a .tar file
$ bg $ jobs OR $ tar -czf home.tar.gz . &amp; $ jobs #Keep Linux
Processes Running After Exiting Terminal $ sudo rsync Templates/*
/var/www/html/files/ &amp; $ jobs $ disown -h %1 $ jobs OR $ nohup tar
-czf iso.tar.gz Templates/* &amp; $ jobs #Detach a Linux Processes From
Controlling Terminal firefox </dev/null &>/dev/null &amp;</p>
<p>count &amp; # count command running on the background jobs fg bg fg
%# #Replace the # with serial number of the job,bring any job in the
foreground fg %2 #bring job 2 into the foreground jobs -l count 2&gt;
/dev/null &amp;</p>
<p>$ tail -f temp.log #Placing a Foreground Job into the
Background,suspend the job with a Ctrl-Z, ^Z[1]+ Stopped tail -f
temp.log<br />
$ bg # bg to place the suspended job in the background $ jobs # list the
jobs in the background</p>
<p>$ jobs -l # list job in the background, process id 105231 [1]+ 105231
Running $ fg 1 # bring job #1 in the foreground from the background,
process id 105231 sudo rsync</p>
<p>$ fg 1 #type ctrl+z to send the job #1 to the background, process id
105231 sudo rsync ^Z [1]+ Stopped</p>
<p>$ jobs -l # list the job #1 in the background which is stopped,
process id 105231 [1]+ 105231 Stopped</p>
<p>$ bg 1 # run the job 1 in the background again, process id 105231
[1]+ sudo rsync</p>
<p>$ jobs -l # list the job #1 in the background, process id 105231 [1]+
105231 Running —————————————————————————————————– 2 is the file
descriptor of stderr the integer file descriptors associated with the
streams stdin, stdout, and stderr are 0, 1, and 2, respectively.</p>
<p>a number 0 = standard out (i.e. STDIN) a number 1 = standard out
(i.e. STDOUT) a number 2 = standard error (i.e. STDERR) if a number
isn’t explicitly given, then number 1 is assumed by the shell (bash)</p>
<p>“&gt;” send to as a whole completed file, overwriting target if
exists</p>
<p>“echo test &gt; file.txt” is equivalent to “echo test 1&gt; file.txt”
echo test 2&gt; file.txt #redirect stderr to file.txt</p>
<p>“/dev/null” is the null device it takes any input you want and throws
it away. It can be used to suppress any output</p>
<p>“2&gt;/dev/null” Redirect STDERR to /dev/null (nothing shows up on
console) The general form of this one is “M&gt;/dev/null”, where “M” is
a file descriptor number. This will redirect the file descriptor, “M”,
to “/dev/null”.</p>
<p>“&gt;&amp;” is the syntax to redirect a stream to another file
descriptor</p>
<p>“echo test 1&gt;&amp;2” equivalent to “echo test &gt;&amp;2”</p>
<p>“2&gt;&amp;1” The general form of this one is “M&gt;&amp;N”, where
“M” &amp; “N” are file descriptor numbers. It combines the output of
file descriptors “M” and “N” into a single stream. “&amp;” indicates
that what follows and precedes is a file descriptor, and not a
filename.</p>
<p>“2&gt;&amp;-” closing a file descriptor used with redirection The
general form of this one is “M&gt;&amp;-”, where “M” is a file
descriptor number. This will close output for whichever file descriptor
is referenced, i.e. “M”</p>
<p>“|&amp;” Redirect STDERR and STDOUT to STDIN This is just an
abbreviation for “2&gt;&amp;1 |”</p>
<p>“&amp;&gt;/dev/null” Redirect both STDERR &amp; STDOUT to /dev/null
(nothing shows up on console) This is just an abbreviation for
&gt;/dev/null 2&gt;&amp;1. It redirects file descriptor 2 (STDERR) and
descriptor 1 (STDOUT) to /dev/null</p>
<p>“&gt;/dev/null” Redirect STDOUT to /dev/null (only STDERR shows on
console) This is just an abbreviation for 1&gt;/dev/null. It redirects
file descriptor 1 (STDOUT) to /dev/null.</p>
<p>“command &gt; /dev/null 2&gt;&amp;1 &amp;” #Run command in the
background, discard stdout and stderr “command &gt;&gt; /path/to/log
2&gt;&amp;1 &amp;” #Run command and append stdout and stderr to a log
file</p>
<p>./command &gt;/dev/null 2&gt;&amp;1 #Hide standard and error
outputs</p>
<p>Hide standard output ./command &gt;/dev/null sends 2 (stderr) into 1
(stdout), and sends stdout to file.log command &gt; file.log 2&gt;&amp;1
Hide standard and error outputs and release terminal (run the command in
background) ./command &gt;/dev/null 2&gt;&amp;1 &amp; prevent standard
output and error output, redirecting them both to /dev/null script &gt;
/dev/null 2&gt;&amp;1</p>
<table>
<colgroup>
<col style="width: 100%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">#Identify processes using files,
directories, or sockets.Who is Using a File or Directory $ fuser . $
fuser -v ./ Check Processes Using TCP/UDP Sockets fuser -v -n tcp 5000
the processes that are using my ‘home’ directory $ fuser ~ $ fuser ~ -v
check for the root directory $ fuser / $ fuser / -v $ fuser -v
/home/ismail $ fuser -v -m /home/ismail/.bashrc $ fuser -v -n tcp 8080 $
fuser -v -n udp 53 kill this TCP listener, you can use option -k $ fuser
-i -k 8080/tcp shows all processes at the (local) TELNET port $ fuser
telnet/tcp list signals $ fuser -l STOP a process $ fuser -i -k STOP
[FILE/DIRECTORY] kills all processes accessing the file system /home $
fuser -km /home</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"># detect driver hardware problems dmesg |
more The output of dmesg is maintained in the log file /var/log/dmesg
cat /var/log/dmesg | less data from /dev/kmsg use syslog # dmesg -S #
limit the output to only error and warnings dmesg –level=err,warn #
dmesg produce timestamps dmesg –level=err -T dmesg -T | grep -i eth0
dmesg –level=err,warn -T | grep -i eth0 # limit dmesg’s output only to
userspace messages dmesg -u # timestmaps along with decode facility and
levels in dmesg command output dmesg -Tx Supported log levels
(priorities): emerg - system is unusable alert - action must be taken
immediately crit - critical conditions err - error conditions warn -
warning conditions notice - normal but significant condition info -
informational debug - debug-level messages dmesg -TL -f kern dmesg -TL
-f daemon Supported log facilities: kern - kernel messages user - random
user-level messages mail - mail system daemon - system daemons auth -
security/authorization messages syslog - messages generated internally
by syslogd lpr - line printer subsystem news - network news subsystem #
verify vt-d is ON “dmesg | grep Virtualization” # dmesg | grep -i memory
# dmesg | grep -i dma # dmesg | grep -i usb # dmesg | grep -E
“memory|dma|usb|tty” # dmesg | grep -E “sda|dma” Clear dmesg logs #
dmesg -C # dmesg -c Display colored messages # dmesg -L Monitor real
time dmesg logs # dmesg –follow # dmesg -Tx –follow # watch “dmesg |
tail 7-20” Display raw message buffer # dmesg -r #virtual machine check
$ dmesg |grep -i hypervisor</td>
</tr>
</tbody>
</table>
<h2 id="dmidecode--s-system-manufacturer">$ dmidecode -s
system-manufacturer</h2>
<p>#32x 64x query uname –m arch #linux version lsb_release -a cat
/etc/issue cat /etc/os-release cat /etc/lsb-release cat /etc/*-release
cat /proc/version hostnamectl set-hostname server1 hostnamectl
set-hostname –pretty “Web dev test environment” hostnamectl set-hostname
–static webdev-test-env $ hostname –ip-address $ hostname
–all-ip-addresses</p>
<p>dnsdomainname -f</p>
<p>#create file w multiple lines echo<br />
“deb [arch=$(dpkg –print-architecture)
signed-by=/usr/share/keyrings/docker-archive-keyring.gpg]
https://download.docker.com/linux/ubuntu<br />
$(lsb_release -cs) stable” | sudo tee
/etc/apt/sources.list.d/docker.list &gt; /dev/null</p>
<p>sudo ls -hal /tmp/ | sudo tee /tmp/test.out &gt; /dev/null #The
redirect to /dev/null is needed to stop tee from outputting to the
screen sudo ls -hal /tmp/ | sudo bash -c “cat &gt;&gt; /tmp/test.out”
#To append instead of overwriting the output file METHOD1 sudo ls -hal
/tmp/ | sudo tee /tmp/test.out #To append instead of overwriting the
output file METHOD2 sudo ls -hal /tmp/ | sudo tee –append /tmp/test.out
#To append instead of overwriting the output file METHOD2</p>
<h1 id="append-text-with-non-root-user">append text with non-root
user</h1>
<p>echo “deb http://research.cs.wisc.edu/htcondor/ubuntu/8.8/bionic
bionic contrib” |sudo tee -a /etc/apt/sources.list</p>
<p>#do not see the contents of the website (may receive an access denied
or ‘bad bot’ message) curl -A ‘Mozilla/5.0 (Windows NT 10.0; Win64; x64)
AppleWebKit/537.36 (KHTML, like Gecko) Chrome/64.0.3282.140
Safari/537.36’ URL curl –compressed URL curl URL | iconv -f windows-1251
-t UTF-8 #convert from the windows-1251 encoding to the UTF-8 encoding
curl -u username:password URL #websites require a username and password
to view their content,specify other authentication methods using –ntlm |
–digest #showing only headers, HTML code not displayed curl -s -I -A
‘Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML,
like Gecko) Chrome/64.0.3282.140 Safari/537.36’
https://www.acrylicwifi.com/AcrylicWifi/UpdateCheckerFree.php?download |
grep -i ‘^location’ curl -s -v
http://www.paterva.com/web7/downloadPaths41.php -d
‘fileType=exe&amp;os=Windows’ 2&gt;&amp;1 | grep -i ‘Location:’</p>
<p>#save cookies,data transfer using the POST method, the –data option
is used curl –cookie-jar cookies.txt http://forum.ru-board.com/misc.cgi
–data
‘action=dologin&amp;inmembername=f123gh4t6&amp;inpassword=111222333&amp;ref=http%3A%2F%2Fforum.ru-board.com%2Fmisc.cgi%3Faction%3Dlogout’
#get information from a page that only registered users have access to,
specify the path to the file with previously saved cookies curl -b
cookies.txt
‘http://forum.ru-board.com/topic.cgi?forum=35&amp;topic=80699&amp;start=3040’
| iconv -f windows-1251 -t UTF-8</p>
<p>#extracting entire archive curl -L -o ds.tar.gz
https://downloads.dockerslim.com/releases/1.37.3/dist_linux.tar.gz tar
-xvf ds.tar.gz -C /usr/local/bin</p>
<p>tar xvzf tkn_0.10.0_Darwin_x86_64.tar.gz -C /usr/local/bin tkn tar
xjvf backup.tbz tar -zxvf backup.tar.gz tar -xf file_name.tar.gz
–directory /target/directory</p>
<p>#ssh and tar to make secure backups. Make a backup via encrypted file
transfer tar –create –directory /home/joe/tmp/ –file - *|<br />
ssh raspberrypi “tar –directory /home/joe<br />
–verbose –list –file -”</p>
<p>wget –no-check-certificate
https://www.cacti.net/downloads/cacti-latest.tar.gz tar -zxvf
cacti-latest.tar.gz mv cacti-1* /opt/cacti (OR tar -xf
cacti-latest.tar.gz –directory /opt/cacti)</p>
<p>tar -zxvf /tmp/onos-1.12.0.tar.gz –strip-components 1 –directory /opt
–one-top-level=onos tar xvf mysql-5.7.23-linux-glibc2.12-x86_64.tar.gz
–one-top-level=mysql57 –strip-components 1 tar zxvf ugly_name.tgz
–one-top-level=pretty_name #extract .xz file unxz
tor-browser-linux32-5.5.4_en-US.tar.xz tar xvf
tor-browser-linux32-5.5.4_en-US.tar #extract .bz2 file bzip2 -dk
FileZilla_3.29.0_x86_64-linux-gnu.tar.bz2 tar xvf
FileZilla_3.29.0_x86_64-linux-gnu.tar #extract .zip file unzip
terraform_0.11.7_linux_amd64.zip -d terraform #extract .rar file unrar e
extract.rar r # create user home directory backup tar cvf filename.tar
/home/vagrant/ # show which files were changed tar dvf filename.tar #
update the changed files tar uvf filename.tar # make smaller backup gzip
filename.tar</p>
<p>#format a USB storage device with FAT32 file system mkfs –t vfat
<USB-device-mount-point> # mount -o loop,offset=$((10860003 * 512))
disk.img /mnt #find out the USB device mount point fdisk -l #unmount the
drive,you can’t format a mounted drive. sudo umount /dev/sdb1 sudo
mkfs.vfat /dev/sdb1 sudo mkfs.ntfs /dev/sdb1 mkfs.ext4
<USB-device-mount-point> mkfs.ntfs <USB-device-mount-point> #Set label
name to USB drives sudo mkfs.vfat /dev/sdb1 -n sk</p>
<p>==========================================================================================================
#Create a New Sudo User(CentOS) adduser username passwd username usermod
-aG wheel username #add user to the wheel group.By default, on CentOS,
members of the wheel group have sudo privileges su - username # switch
to the new user account</p>
<p>#verify if user is sudoer sudo -l -U userjohndoe #list user’s
privileges or check a specific command sudo –validate / sudo -v #update
the user’s cached credentials, authenticating the user if necessary sudo
–list #print the list of allowed and forbidden commands for the user who
is executing the sudo command groups #verify if user is sudoer, member
of wheel group sudo whoami # returns root</p>
<table>
<colgroup>
<col style="width: 100%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">#Create a New Sudo User (ubuntu) sudo
adduser barak #create new user sudo adduser barak sudo #Add the user to
sudo group usermod -aG sudo barak #Add the user to sudo group</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">echo $HOME $USER sudo bash -c ‘echo $HOME
$USER’ sudo -H bash -c ‘echo $HOME $USER’</td>
</tr>
</tbody>
</table>
<p>cmd: sudo sh -c “go build .”</p>
<p>problem: bash: line 1: go: command not found</p>
<p>fix: # indicates that the go command is not in the system’s PATH when
running the command with sudo. #This is because sudo does not preserve
the user’s environment variables, including the PATH variable.</p>
<h2 id="sudo-env-pathpath-sh--c-go-build-.">sudo env “PATH=$PATH” sh -c
“go build .”</h2>
<p>When you use the “su otheruser” command without the hyphen (-), you
switch to the specified user’s account, but you inherit the current
environment variables and working directory of the original user. This
can lead to potential issues if you need the new user’s environment to
be set up completely.</p>
<p>Example Use Cases:</p>
<p>If you only need to quickly execute a single command as “otheruser”
but do not require the environment to be exactly the same, you might use
“su otheruser” to avoid the overhead of starting a new shell
session.</p>
<p>┌──(vagrant㉿vg-kali-02)-[~] └─$ su barak Password:
┌──(barak㉿vg-kali-02)-[/home/vagrant] └─$ echo $HOME /home/barak</p>
<p>┌──(barak㉿vg-kali-02)-[/home/vagrant] └─$ pwd /home/vagrant</p>
<p>┌──(barak㉿vg-kali-02)-[/home/vagrant] └─$ exit exit</p>
<p>┌──(vagrant㉿vg-kali-02)-[~] └─$ —————————————————————————————————-
When you use the “su - otheruser” command with the hyphen (-), you not
only switch to the specified user’s account but also start a new shell
session with the target user’s environment variables and home directory.
This ensures a clean environment as if you had logged in directly as
that user.</p>
<p>In general, you should use su - otheruser if you need to change the
shell environment. This is especially important if you are going to be
running commands that require specific permissions or settings that are
not available in the default shell environmen</p>
<p>Example Use Cases:</p>
<p>Suppose you are the “originaluser” and you want to run a script that
requires specific environment variables and settings of “otheruser.” In
this case, you would use “su - otheruser” to ensure the script runs with
the correct environment.</p>
<p>┌──(vagrant㉿vg-kali-02)-[~] └─$ su - barak Password:
┌──(barak㉿vg-kali-02)-[~] └─$ echo $HOME /home/barak</p>
<p>┌──(barak㉿vg-kali-02)-[~] └─$ pwd /home/barak</p>
<p>┌──(barak㉿vg-kali-02)-[~] └─$ exit logout</p>
<p>┌──(vagrant㉿vg-kali-02)-[~] └─$ —————————————————————————————————-
#-H flag makes sudo assume root’s home directory as HOME instead of the
current user’s home directory sudo -H #sudo user echo “stack ALL=(ALL)
NOPASSWD: ALL” |sudo tee -a /etc/sudoers</p>
<p>#allow a user aaron to run all commands using sudo without a
password, open the sudoers file $ sudo visudo aaron ALL=(ALL) NOPASSWD:
ALL</p>
<p>%sys ALL=(ALL) NOPASSWD: ALL #all member of the sys group will run
all commands using sudo without a password alf ALL=(ALL) NOPASSWD: ALL
#permit a user to run a given command (/bin/kill) using sudo without a
password %sys ALL=(ALL) NOPASSWD: /bin/kill, /bin/rm #the sys group to
run the commands: /bin/kill, /bin/rm using sudo without a password</p>
<p>#su vs sudo #“sudo” asks for your password,“su” asks for the password
for the user whom you are switching to #sudo lets you issue commands as
another user without changing your identity,entry in /etc/sudoers to
execute these restricted permissions #without entering the root password
#su keeps the environment of the old/original user even after the switch
to root #creates a new environment (as dictated by the ~/.bashrc of the
root user), #similar to the case when you explicitly log in as root user
from the log-in screen. “su -”<br />
“su -l” #pass more arguments</p>
<p>“su -c” #su [target-user] -c [command-to-run] a command that you want
to run after switching to the target user. su -c
‘/home/annie/annie-script.sh’ annie #While logged in as user dave, run
the annie-script.sh as user annie su -c ‘echo I am $(whoami)’ #Without
specifying a target user,switch into root</p>
<p>#The password prompt is not preferable, during scripting #disable the
password prompt when user dave is executing scripts as user annie.dave
uses su without having to input annie‘s password. #/etc/pam.d/su,add the
following lines right after the line “auth sufficient pam_rootok.so”
auth [success=ignore default=1] pam_succeed_if.so user = annie #rule
checks if the target user is annie auth sufficient pam_succeed_if.so
use_uid user = dave #rule to check if the current user is dave su -c
/home/annie/annie-script.sh annie #run by dave</p>
<p>auth sufficient pam_rootok.so auth [success=ignore default=1]
pam_succeed_if.so user = otheruser auth sufficient pam_succeed_if.so
use_uid user ingroup somegroup</p>
<p>#/etc/sudoers echo ‘dave ALL=(annie) /home/annie/annie-script.sh’ |
EDITOR=‘tee -a’ visudo #The rule grants dave the permission to execute
the script annie-script.sh as user annie on any hosts sudo -u annie
/home/annie/annie-script.sh #while logged in as dave sudo -u root
/home/annie/annie-script.sh #Sorry, user dave is not allowed to execute
‘/home/annie/annie-script.sh’ as root “sudo -s” or “sudo -i” #mimic “su”
or “su -l” “sudo -s or sudo -i” #temporarily become a user with root
privileges</p>
<p>#/etc/sudoers echo ‘dave ALL=(ALL) /home/annie/annie-script.sh’ |
EDITOR=‘tee -a’ #The rule grants dave to execute the script
annie-script.sh as any users sudo -u root /home/annie/annie-script.sh
#while logged in as dave</p>
<p>#The password prompt is not preferable, during scripting
#/etc/sudoers dave ALL=(ALL) NOPASSWD: /home/annie/annie-script.sh’ |
EDITOR=‘tee -a’</p>
<h1
id="switching-to-root-using-sudo--i-or-sudo-su-cancels-auditinglogging">switching
to root using sudo -i (or sudo su) cancels auditing/logging</h1>
<h1
id="when-a-sudo-command-is-executed-the-original-username-and-the-command-are-logged">when
a sudo command is executed, the original username and the command are
logged</h1>
<p>“sudo su” “sudo -i” su is equivalent to sudo -i gives you the root
environment, i.e. your ~/.bashrc is ignored. simulates a login into the
root account Your working directory will be /root will read root’s
.profile</p>
<p>“sudo -s” gives you the user’s environment, so your ~/.bashrc is
respected. launches a shell as root doesn’t change your working
directory</p>
<p>“sudo bash” #runs bash as a super user sudo -E #The -E (preserve
environment) option indicates to the security policy that the user
wishes to preserve their existing environment variables.
==========================================================================================================
mount -l lshw -short sudo lshw -class disk sudo lshw -short -class disk
lshw -class processor file -Ls dmesg denyhosts vmstat w uptime ps free
iostat pmap paste uname sudo mkdir chown ptree pkill</p>
<p>killall kill -KILL PID kill –TERM [PID] #means terminate.the default
signal sent by kill,equivalent to kill <PID></p>
<p>kill –HUP [PID] #reset or restart the process all signals $ kill -l
stop and restart process $ kill -1 13980 1 SIGHUP 9 SIGKILL stop process
without letting gracefully 15 SIGTERM stop process
—————————————————————————————————————— $ touch mylog $ ls -lai mylog
3145761 -rw-rw-r– 1 vagrant vagrant 0 Mar 27 21:01 mylog update the
access time of existing file $ touch -c mylog Change file access time -
‘a’ of existing file $ touch -a mylog Change the modified time ‘-m’ of
existing file $ touch -m mylog $ touch -am mylog Set a specific
access/modify time instead of current time, specify the datetime in
format [[CC]YY]MMDDhhmm[.ss] $ touch -c -t 201603051015 mylog $ touch -c
-d ‘5 Jan 2009’ mylog $ touch -c -d ‘20:30’ myfile Use the timestamp of
another file as reference $ touch myfile -r mylog use the timestamps of
‘apl’ for ‘apl.c’ $ touch apl.c -r apl $ ls -lai mylog 3145761 -rw-rw-r–
1 vagrant vagrant 0 Mar 27 21:06 mylog</p>
<p>$ stat mylog File: ‘mylog’ Size: 0 Blocks: 0 IO Block: 4096 regular
empty file Device: fc00h/64512d Inode: 3145761 Links: 1 Access:
(0664/-rw-rw-r–) Uid: ( 1000/ vagrant) Gid: ( 1000/ vagrant) Access:
2019-03-27 21:07:54.953000000 +0000 Modify: 2019-03-27
21:07:54.953000000 +0000 Change: 2019-03-27 21:07:54.953000000 +0000
Birth: - force touch to not create any new file $ touch -c newfile $ ls
-l newfile ls: cannot access ‘newfile’: No such file or directory $ stat
newfile stat: cannot stat ‘newfile’: No such file or directory</p>
<table>
<colgroup>
<col style="width: 100%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;"># create symbolic link ln -s test1.txt
symbolic_test1.txt stat symbolic_test1.txt touch -c -d ‘5 Jun 2001’ -h
symbolic_test1.txt stat symbolic_test1.txt # detect symbolic link touch
a.xt ln -s a.txt b.txt stat b.txt file b.txt</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">df –h # view the amount of free disk space
df -HT #Display File System Type df -hT /home df -t ext3 #display a
certain file system type use the ’-t‘ option df -x ext3 #Exclude Certain
File System Type df -k #usage in 1024-byte blocks, use the option ’-k‘
df -m # MB (MegaByte) df -i # view number of inodes in the system df -kl
# get a detail description on disk space usage</td>
</tr>
</tbody>
</table>
<p>du -sh /* # list directory sizes under root / disk du -sh /* | sort
-h du -m /some/path | sort -nr | head -n 20 #sorted list containing the
20 biggest dirs for each in <span class="math inline">$(ls) ; do du -hs
"$</span>each” ; done du –threshold=1M -h | sort -h #includes hidden dot
folders (folders which start with .). du -h | sort -h 3</p>
<p>du -bch #-b gives you the file size instead of disk usage, and -c
gives a total at the end du -ch | tail -1 du -sh /some/dir #the summary
of a grand total disk usage size of an directory use the option “-s” du
-sh /var/* |grep G du -ah /home/tecmint # displays the disk usage of all
the files and directories du -kh /home/tecmint #the disk usage of a
directory tree with its subtress in Kilobyte blocks. Use the “-k”
(displays size in 1024 bytes units). du -kh /home/tecmint #Megabytes
(MB) du -ch /home/tecmint #The “-c” flag provides a grand total usage
disk space at the last line du -ah –exclude=“*.txt” /home/tecmint du -ha
–time /home/tecmint #the disk usage based on modification of time, use
the flag “–time”</p>
<p>#The problem with du is that it adds up the size of the directory
nodes as well,not to sum up only the file sizes. # total size of files
in a directory du -h -c directory #listing path du -h -c directory|tail
-1 #only total size $ du -sh /var/log/apt #only total size and
listing</p>
<p>#du prints actual disk usage rounded up to a multiple of (usually) 4
KB instead of logical file size $ for i in {0..9}; do echo -n $i &gt;
<span class="math inline">$i.txt; done #create files$</span> ls <em>.txt
0.txt 1.txt 2.txt 3.txt 4.txt 5.txt 6.txt 7.txt 8.txt 9.txt $ du -ch
</em>.txt | tail -1 40K total $ ls -FaGl *.txt | printf “%‘d”
$(awk’{SUM+=$4}END{print SUM}’) 10</p>
<p>du /var/* -shc –exclude=lib #–exclude to exclude any directory du
/var/ -h –exclude=lib –max-depth=1 #first-level sub-directories in the
/var/ directory.</p>
<p>$ du -ch /var/log/apt | tail -1 | cut -f 1 $ du -ac –bytes
/var/log/apt $ du -ac –bytes /var/log/apt | grep “log$” | awk ‘{ print;
total += <span class="math inline">$1 }; END { print "total lobsters: ",
total, " Bytes" }'$</span> du -ac –bytes /var/log/apt | grep “log$” |
awk’{ print; total += <span class="math inline">$1 }; END { print "total
lobsters: ", total/1024, " KB" }'$</span> du -ac –bytes /var/log/apt |
grep “log$” | awk ’{ print; total += <span class="math inline">$1 }; END
{ print "total lobsters: " total/1024/1024 " MB" }'$</span> du
/var/log/apt/*.log | awk ‘{ print; total += <span class="math inline">$1
}; END { print "total size: ",total }'
----------------------------------------------------------------------------------------------------$</span>
dir /var/log/apt #list directory contents $ dir /var/log/apt | tee &gt;(
awk’{ total += <span class="math inline">$4 }; END { print total }' )
#list directory contents and total size$</span> dir /var/log/apt | awk
‘{ print; total += $4 }; END { print “total size:”,total }’ #total
size</p>
<table>
<colgroup>
<col style="width: 100%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">#List all running processes containing the
string stuff cat /proc/cpuinfo grep “physical id” /proc/cpuinfo | wc -l
cat /proc/meminfo grep MemTotal /proc/meminfo | awk ‘{FS=“:”}{print $2
}’ | awk ‘{print $1/1024/1024}’ cat /proc/zoneinfo cat /proc/mounts cat
/etc/issue</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"># history,The ! prefix is used to access
previous commands. !$ - last argument from previous command(last
command) !:1 # last command’s 1st argument !:2 # last command’s 2nd
argument !:1-2 # last command’s 1st and 2nd argument !^ - first argument
(after the program/built-in/script) from previous command !* - all
arguments from previous command</td>
</tr>
<tr class="even">
<td style="text-align: left;">!! - previous command (often pronounced
“bang bang”) !n - command number n from history !pattern - most recent
command matching pattern !!:s/find/replace - last command, substitute
find with replace !3:2 #take the second argument from the third command
in the history !-5:3 #take the third argument from the fifth last
command in the history,Using a minus sign to traverse from the last
command of the history</td>
</tr>
<tr class="odd">
<td style="text-align: left;">$ echo ‘one’ ‘two’ one two $ !$ ‘two’ $ !^
‘one’ $ !* ‘one’ ‘two’ $ !! echo ‘one’ ‘two’ one two</td>
</tr>
<tr class="even">
<td style="text-align: left;">$ ls /tmp &amp;&amp; cd !*</td>
</tr>
</tbody>
</table>
<p>$ curl -kL http://localhost/banana #curl -IL http://localhost
HTTP/1.1 200 OK Server: nginx/1.10.2</p>
<p>curl -Is http://www.google.com | head -n 1 #check whether a web site
is up, and what status message the web server is showing curl -sSf
http://example.org &gt; /dev/null curl -XGET
‘localhost:9200/?pretty’</p>
<p>curl -X PUT “http://127.0.0.1:9200/mytest_index” #sending data with
POST and PUT requests curl -d “param1=value1&amp;param2=value2” -X POST
http://localhost:3000/data curl -d “param1=value1&amp;param2=value2” -H
“Content-Type: application/x-www-form-urlencoded” -X POST
http://localhost:3000/data curl -d “<span class="citation"
data-cites="data.txt">@data.txt</span>” -X POST
http://localhost:3000/data curl -d ‘{“key1”:“value1”, “key2”:“value2”}’
-H “Content-Type: application/json” -X POST http://localhost:3000/data
curl -d “<span class="citation"
data-cites="data.json">@data.json</span>” -X POST
http://localhost:3000/data</p>
<h1 id="check-if-apache-is-running">check if apache is running</h1>
<p>curl -sf http://webserver/check_url # process was holding a
particular port open ss -tp state listening sport = :80 | grep httpd #
check a particular process id lsof -p 1036 -P | grep ‘TCP *:80’ $ echo
“The process id is” <span class="math display">$$
$ echo "The process id is" $$</span>$$ # check what process is listening
$ sudo fuser -n tcp 22 22/tcp: 1088 14324 14354</p>
<p>echo $SHELL -&gt; determine current shell type cat /proc/cpuinfo |
grep ‘vmx|svm’ -&gt; VT-x/AMD-v virtualization is enabled in BIOS</p>
<h1 id="troubleshooting-nginx">troubleshooting nginx</h1>
<p>journalctl -u nginx.service tail -n 50 /var/log/nginx/error.log tail
-n 50 //var/log/nginx/access.log nginx -t sudo ss -tulpn # Verify that
port 80 or 443 curl -I http://10.21.136.13 curl http://10.21.136.13 dig
+short localhost <span class="citation"
data-cites="8.8.8.8">@8.8.8.8</span> ————————————————————————————————
#/etc/systemd/journald.conf #SystemMaxUse=100M cat
/etc/systemd/journald.conf | grep SystemMaxUse journalctl
–vacuum-size=100M</p>
<p>sudo usermod -a -G systemd-journal $USER # add the current user to
the systemd-journal group</p>
<p># process the data further with text processing tools like grep, awk,
or sed, or redirect the output to a file journalctl –no-pager #print its
output directly to the standard output instead of using a pager by
including the –no-pager flag</p>
<p>journalctl -o json -n 10 –no-pager #change the format to format like
JSON journalctl -o json-pretty -n 10 –no-pager</p>
<pre><code>cp /etc/systemd/journald.conf{,.orig}
cp a.txt{,.$(date +%Y%m%d-%H%M)} #clone with date info</code></pre>
<p>sudo mkdir -p /var/log/journal ls -l
/var/log/journal/3a0d751560f045428773cbf4c1769a5c/ sudo cp
/etc/systemd/journald.conf{,.orig} sed -i
’s/#Storage.*/Storage=persistent/’ /etc/systemd/journald.conf # set
“Storage” type to “persistent sudo vi /etc/systemd/journald.conf
Storage=persistent systemctl restart systemd-journald.service journalctl
–flush # move the journal log files from /run/log/journal to
/var/log/journal #The options prefixed with”Runtime” apply to the
journal files when stored on a volatile in-memory file system, #more
specifically /run/log/journal</p>
<p>journalctl –vacuum-files=2 # have 10 archived journal files and want
to reduce these down to 2 journalctl –verify</p>
<p>journalctl | head -1 #What time range do I have logs for? journalctl
-F _SYSTEMD_UNIT #What systemd services do I have logs for?<br />
journalctl -F _COMM journalctl -F _EXE journalctl -F _CMDLINE #What
users do the services that logged something run as (swap _UID/-u with
_GID/-g for groups)? journalctl -F _UID | xargs -n1 id -nu journalctl -F
_UID | xargs -n1 id -ng</p>
<p>#provide test input for journalctl logger -p err ‘something erronous
happened’ systemd-cat -p info echo ‘something informational
happened’</p>
<p>#What selector fields are there? Show up to 8 values each for f in
<span
class="math inline">(<em>s</em><em>u</em><em>d</em><em>o</em><em>j</em><em>o</em><em>u</em><em>r</em><em>n</em><em>a</em><em>l</em><em>c</em><em>t</em><em>l</em> − −<em>f</em><em>i</em><em>e</em><em>l</em><em>d</em><em>s</em>); <em>d</em><em>o</em><em>e</em><em>c</em><em>h</em><em>o</em> =  =  =  =  =  =  =  =  =  = =</span>f;
sudo journalctl -F $f; done | grep -A8 ========</p>
<p>#remove all entries journalctl –rotate journalctl –vacuum-time=1s
journalctl -m –vacuum-time=1s #-m flag, it merges all journals and then
clean them up #remove all entries find /var/log/journal -name
“<em>.journal” | xargs sudo rm systemctl restart systemd-journald
#remove all entries rm -rf /run/log/journal/</em></p>
<p>journalctl –rotate –vacuum-size=500M #rotate journal files and remove
archived journal files until the disk space they use is under 500M</p>
<p>#Rotating is a way of marking the current active log files as an
archive and create a fresh logfile from this moment # The flush switch
asks the journal daemon to flush any log data stored #in
/run/log/journal/ into /var/log/journal/, if persistent storage is
enabled. #Manual delete,removes all archived journal log files until the
last second,clears everything journalctl –flush –rotate #applies to only
archived log files only, not on active journal files journalctl
–vacuum-time=1s #Manual delete,clears all archived journal log files and
retains the last 400MB files journalctl –flush –rotate journalctl
–vacuum-size=400M #Manual delete,only the last 2 journal files are kept
and everything else is removed journalctl –flush –rotate journalctl
–vacuum-files=2</p>
<p>journalctl -b -&gt;all of the journal entries that have been
collected since the most recent reboot journalctl –list-boots #list of
boot numbers, their IDs, and the timestamps of the first and last
message pertaining to the boot journalctl –boot=ID _SYSTEMD_UNIT=foo
journalctl -b -1 -&gt; see the journal from the previous boot,use boot
number to pick specific boot journalctl -k -b -1 -&gt; Shows kernel logs
for the current boot.</p>
<p>$ journalctl –list-boots #list boot id -1
340f8a96d40749f8b2530cc76810d62d Tue 2022-01-18 14:33:46 +03—Tue
2022-01-18 15:14:42 +03 0 75c35ddeb4274787ad78d1092bf9743a Tue
2022-01-18 23:08:10 +03—Wed 2022-01-19 09:25:35 +03 $ journalctl -b
75c35ddeb4274787ad78d1092bf9743a #use boot id</p>
<p>journalctl –since “2015-01-10 17:15:00” journalctl -S “2020-91-12
07:00:00” journalctl -S -1d #The “d” stands for “day”, and the “-1”
means one day in the past journalctl -S -1h journalctl –since
“2015-06-26 23:15:00” –until “2015-06-26 23:20:00” journalctl -S
“2020-91-12 07:00:00” -U “2020-91-12 07:15:00” journalctl –since
yesterday journalctl -S yesterday journalctl –since yesterday –until now
journalctl –since today journalctl -S -2d -U today #everything from two
days ago up until the start of today journalctl –since 09:00 –until “1
hour ago” journalctl –since ‘1h ago’ –until ‘10 min ago’</p>
<p>#syslog log levels i.e. “emerg” (0), “alert” (1), “crit” (2), “err”
(3), “warning” (4), “notice” (5), “info” (6), “debug” (7) journalctl -p
0 journalctl -p 0..2 # logs for a range between emerg(0) and critical(2)
journalctl -f -p warning # show me warnings journalctl -p err # show all
errors</p>
<p>journalctl -xp info journalctl -xu sshd journalctl -fxu httpd.service
journalctl -fxu sshd.service -p debug journalctl -fx journalctl -xn</p>
<p>journalctl /dev/sda -&gt; displays logs related to the /dev/sda file
system. journalctl /sbin/sshd #logs from the sshd binary journalctl -n20
_EXE=/usr/sbin/sshd journalctl /usr/bin/bash</p>
<p>journalctl -u nginx.service -&gt; see all of the logs from an Nginx
unit on our system journalctl -u nginx.service –since today journalctl
-b -u docker -o json journalctl -u docker.service –since “2016-10-13
22:00” journalctl _SYSTEMD_UNIT=sshd.service journalctl -u sshd.service
journalctl -u sshd.service -x #logs with more details journalctl
_PID=8088 journalctl -b _SYSTEMD_UNIT=foo _PID=number #logs for
systemd-units that match foo and the PID number #all messages from the
foo service process with the PID plus all messages from the foo1 service
journalctl -b _SYSTEMD_UNIT=foo _PID=number + _SYSTEMD_UNIT=foo1
journalctl -b _SYSTEMD_UNIT=foo _SYSTEMD_UNIT=foo1 #shows logs matching
a systemd-unit foo or a systemd-unit foo1</p>
<p>#Filter logs based on user id -u www-data 33<br />
journalctl _UID=33 –since today</p>
<p>journalctl -k -&gt;Kernel messages, those usually found in dmesg
output journalctl _TRANSPORT=kernel</p>
<p>journalctl -n 20 -&gt;see with a number after the -n journalctl -n 10
-o short-full #Changing the Display Format journalctl -n 10 -o verbose
journalctl -n 10 -o json journalctl -n 10 -o json-pretty journalctl -n
10 -o cat #see the log entry messages, without time stamps or other
metadata</p>
<p>journalctl –disk-usage #using persistent storage then the below
output shows the amount of disk used #removes archived journal files
until the disk space they use falls below the specified size #(specified
with the usual “K”, “M”, “G”, “T” suffixes), journalctl –vacuum-size=1G
journalctl –vacuum-time=1weeks #clear all messages older than one week
journalctl –vacuum-time=2d #Retain only the past two days</p>
<p>journalctl -f -&gt; continuously prints log messages, similar to tail
-f<br />
journalctl -u mysql.service -f journalctl -f -e -p err docker –since
today # -e implies -n1000</p>
<p>#who ran sudo in the past week, what commandline, what PWD and user?
journalctl –since ‘1 week ago’ _COMM=sudo -o json<br />
| jq -r ’(.__REALTIME_TIMESTAMP|tonumber|(./1e6)|todate) + “ + ._CMDLINE
+” + .MESSAGE’<br />
| column -ts $‘ #How many ssh auth errors today?<br />
journalctl -o cat -p err -u ssh –since today | wc -l #filter specific
error journalctl -o cat -p err | grep “tx hang” #executables have been
logging errors at a loglevel lower than error in the past month?
journalctl –since -1month -p 7..4 -o json | jq -r ’select (.MESSAGE |
contains(“error”)) | ._EXE’ | sort -u #show error logs for a particular
version of a service journactl -p err
/opt/fooservice/9e76/bin/fooservice #Filter by start and end dates and
particular PIDs journalctl _SYSTEMD_UNIT=docker –since ‘2018–11–01
14:00’ –until ‘2018–11–13 14:00’ _PID=123 _PID=456
———————————————————————————————— Job for autofs.service failed because a
configured resource limit was exceeded. See “systemctl status
autofs.service” and “journalctl -xe” for details. systemctl start autofs
systemctl is-active autofs systemctl is-active autofs &gt;/dev/null
2&gt;&amp;1 &amp;&amp; echo YES || echo NO</p>
<p>ps -aux | grep -i autofs | grep -v grep #grep command was shown in
the output, remove this distraction is to add another pipe to grep -v
grep</p>
<p>kill -9 <code>ps -ef | grep '[k]eyword' | awk '{print $2}'</code> #
get the pid from ps command ps -aux | grep dockerd | grep -v grep | awk
‘{print $2}’ # get the pid from ps command</p>
<table>
<colgroup>
<col style="width: 100%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">$ ps aux | grep root #list services
running as root ps aux | grep 3813 ps -eo
pid,user,group,args,etime,lstart | grep ‘[3]813’ ps aux | grep ‘[1]616’
ps -eo pid,user,group,args,etime,lstart | grep ‘[1]616’ ps aux | grep
stuff The init process, with process ID 1, which does nothing but wait
around for its child processes to die. Usually started for /etc/inittab
$ ps -ef| grep init # see the name of the process $ sudo ps 1088 14324
14354 # CPU time, page faults of child processes ps -Sla $ ps -lu
vagrant memory information long format $ ps -lma signal format $ ps -sx
controlling terminal $ ps –tty 1 -s #print a process tree ps -ejH ps
axjf</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">renice -n -19 -p 3534 -&gt; Change the
Priority of a Running Process #adding more virtual runtime to the
process #The OS thinks that the process has taken more virtual runtime
time than other processes in the run queue. #in the next cycle, the CPU
gives less time to the process #The process finishes late as it’s
getting less time “on CPU” renice +10 PID #The OS thinks that the
process hasn’t got enough “on CPU” time than other processes in the run
queue #in the next cycle, the CPU gives more “on CPU” time to that
process as compared to other processes in the run queue. renice -10 PID
/etc/security/limits.conf -&gt; set the default nice value of a
particular user or group $ pidof rsync $ renice +10 2395 2395 (process
ID) old priority 0, new priority 10</td>
</tr>
</tbody>
</table>
<p>#Process affinity is the scheduler property that helps to bind or
unbind the process so that the process will run only with the allotted
CPU #Processor affinity, or CPU pinning or “cache affinity”, enables the
binding and unbinding of a process or a thread to a central processing
unit (CPU) or a range of CPUs</p>
<p>#According to the taskset command man pages, value f means “any CPU.”
$ pidof rsync $ taskset -p 2395 #use the PID to get CPU affinity,
returns the current CPU affinity in a hexadecimal bit mask format pid
2395’s current affinity mask: f $ taskset -cp 2395 #get the CPU range of
a process pid 2395’s current affinity list: 0-3</p>
<p>$ taskset -c 0 vlc #start the VLC program on CPU core ID 0 taskset
0xa gedit #launch gedit with CPU affinity 0xa.</p>
<p>#If the server gets a reboot or the process is restarted, the PID
changes taskset -p 0x11 9030 #assign a process to cores 0 and 4 taskset
-cp 0,4 9030 #assign a process to cores 0 and 4 taskset -cp 1 9030 #
bound the process 9030 to run only on CPU 1, configuration is not
permanent —————————————————————————————————–</p>
<h2
id="gpg-verify-gnupg-2.2.3.tar.bz2.sig-gnupg-2.2.3.tar.bz2---check-the-signature-of-the-file-gnupg-2.2.3.tar.bz2">gpg
–verify gnupg-2.2.3.tar.bz2.sig gnupg-2.2.3.tar.bz2 -&gt; check the
signature of the file gnupg-2.2.3.tar.bz2</h2>
<p>systemd-analyze #the actual boot time of the machine systemd-analyze
blame #see how long every program and service takes to start up
systemd-analyze critical-chain # print out the results in a chain of
events style systemd-analyze critical-chain ntp.service
networking.service systemd-analyze plot &gt; boot_analysis.svg xviewer
boot_analysis.svg<br />
systemd-analyze time -H tecmint@192.168.56.5 #view information from a
remote host over ssh systemd-analyze blame -H tecmint@192.168.56.5</p>
<h2
id="systemd-cgtop-top-control-groups-by-their-resource-usage-such-as-tasks-cpu-memory-input-and-output">systemd-cgtop
#top control groups by their resource usage such as tasks, CPU, Memory,
Input, and Output</h2>
<p>PARSING JSON FILE</p>
<p>sudo apt-get install -y jq curl -s
‘https://api.github.com/users/lambda’ | jq -r ‘.name’</p>
<p>grep -w "key_name" /vagrant/test.json |tail -1 | cut -d" -f4 grep -w
"author" /vagrant/test.json |tail -1 | cut -d" -f4</p>
<p>$ FOOBAZ=“tester” $ jq -n –arg foobaz “<span
class="math inline">$FOOBAZ" '{"foobaz":$</span>foobaz}’ &gt; test1.json
$ cat test1.json</p>
<p>export $(jq -r ‘<span class="citation" data-cites="sh">@sh</span>
“FOO=(.foo) BAZ=(.baz)”’) #fill environment variables from JSON object
keys (e.g. <span class="math inline">$FOO from jq query ".foo")
echo '{ "foo": 123, "bar": 456 }' | jq '.foo' #print out the foo
property
apod_url=$</span>(curl -s
https://api.nasa.gov/planetary/apod?api_key=DEMO_KEY | jq -r ‘.hdurl’)
#get the URL of the current Astronomy Picture of the Day (APOD) echo ‘{
“Version Number”: “1.2.3” }’ | jq ‘.”Version Number”’ #if a property has
a spaces or weird characters echo ‘[1,2,3]’ | jq ‘.[]’ #how iteration
works echo ‘[ {“id”: 1}, {“id”: 2} ]’ | jq ‘.[].id’ #access a property
on each item echo ‘{ “a”: 1, “b”: 2 }’ | jq ‘.[]’ #the value of each
key/value pair —————————————————————————————————- bootstrap.sh</p>
<p>parted /dev/sdb mklabel msdos parted /dev/sdb mkpart primary 512 100%
mkfs.xfs /dev/sdb1 mkdir /mnt/disk</p>
<p>mount /mnt/disk # Format the /dev/sdb partition with XFS filesystem
and with a GPT partition table sudo parted -s /dev/sdb mklabel gpt
mkpart primary xfs sudo mkfs.xfs /dev/sdb -f sudo blkid -o value -s TYPE
/dev/sdb # list disk UUIDs ls -l /dev/disk/by-id $ fdisk -v $ sudo fdisk
-l $ sudo fdisk -l /dev/sda1 —————————————————————————————————– cut -c3
-&gt; print the character from each 3rd line as a new line of output.
cut -c2,7 -&gt; Display the 2nd and 7th character from each line of text
cut -c-4 -&gt; Display the first four characters from each line of text
cut -c13- -&gt; Print the characters from thirteenth position to the
end. cut -d’ ’ -f4 -&gt; Given a sentence, identify and display its
fourth word. Assume that the space (’ ‘) is the only delimiter between
words. cut -d’ ’ -f1-3 -&gt; Given a sentence, identify and display its
first three words. Assume that the space (’ ’) is the only delimiter
between words.</p>
<p>cut -f 1-3 -&gt; Given a tab delimited file with several columns (tsv
format) print the first three fields. cut -f2- -&gt; Given a tab
delimited file with several columns (tsv format) print the fields from
second fields to last field. —————————————————————————————————– uniq -ci
-&gt; count the number of times each line repeats itself (only consider
consecutive repetions).compare consecutive lines in a case insensitive
manner uniq -u -&gt; display only those lines which are not followed or
preceded by identical replications</p>
<p>Given a text file, count the number of times each line repeats itself
(only consider consecutive repetions). Display the count and the line,
separated by a space. uniq -ci | cut -c7-
—————————————————————————————————– head -v -n 3 file1 # list the names
of the files before outputting their content to the terminal head -n2 -q
file1 file2 #Use the -n option to print the first n lines from a file
head -n 20 -&gt; Display the first lines of an input file. head -n-2
example.txt # skips the last 2 lines and prints the remaining lines.
head -n10 filename | tail -5 #prints the lines between numbers 5 and 10
head -c5 example.txt #prints the first 5 bytes from the file. head -c-7
example.txt #skip printing last 7 bytes. head -c20 -&gt; Display the
first characters of an input file. head -n 22 | tail -n +12 -&gt;
Display the lines (from line number 12 to 22, both inclusive) of a given
text file # print the lines between 5 and 10, both inclusive cat
filename | head | tail -6 —————————————————————————————————– tail -n 20
| tail -n +12 -&gt; Display the last lines of an input file. tail -c 20
-&gt; Display the last characters of an input file
—————————————————————————————————– echo BigcapsSmallCaps | tr [:lower:]
[:upper:] # convert string into lower case, capital case etc tr ‘()’
‘[]’ -&gt; In a given fragment of text, replace all parentheses with box
brackets tr -d [:lower:] -&gt; In a given fragment of text, delete all
the lowercase characters tr -d “[:space:]” &lt; raw_file.txt #remove all
whitespace characters from the file echo -e ” | tr -d “[:blank:]”
#deletes any space or tabulation character tr -s ’ ’ -&gt; In a given
fragment of text, replace all sequences of multiple spaces with just one
space distribution=$(lsb_release –id | cut -f2 | tr [:upper:] [:lower:])
#all big caps to small caps —————————————————————————————————– sort
-&gt; Given a text file, order the lines in lexicographical order. sort
-r -&gt; Given a text file, order the lines in reverse lexicographical
order sort -n -&gt; the lines reordered in numerically ascending order
sort -nr -&gt; The text file, with lines re-ordered in descending order
(numerically).</p>
<p>given a file of text,in TSV (tab-separated) format.Rearrange the rows
of the table in descending order of the values sort -t<span
class="math inline">$'\t' -rnk2
given a file of tab separated weather data (TSV). There is no header
column in this data file.Sort the data in ascending order
sort -nk2 -t$</span>‘ given a file of pipe-delimited weather data (TSV).
There is no header column in this data file. sort -nrk2 -t$’|’</p>
<table>
<colgroup>
<col style="width: 100%" />
</colgroup>
<thead>
<tr class="header">
<th>paste -s -&gt; Given a CSV file where each row contains the name of
a city and its state separated by a comma.replace the newlines in the
file with tabs paste - - - -&gt; given a CSV file where each row
contains the name of a city and its state separated by a comma,
restructure the file in such a way, that three consecutive rows are
folded into one, and separated by tab. paste -s -d “;” -&gt; given a CSV
file where each row contains the name of a city and its state separated
by a comma.replace the newlines in the file with semicolon paste - - -
-d “;” -&gt; given a CSV file where each row contains the name of a city
and its state separated by a comma. restructure the file so that three
consecutive rows are folded into one line and are separated by
semicolons</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>#Detect exploitation attempts of the vulnerability in uncompressed
files in the Linux logs directory /var/log and all its subdirectories
egrep -I -i -r
‘$({|%7B)jndi:(ldap[s]?|rmi|dns|nis|iiop|corba|nds|http):/[^\n]+’
/var/log find /var/log/ -type f -exec sh -c “cat {} | sed -e
‘s/${lower://’g | tr -d’}’ | egrep -I -i
‘jndi:(ldap[s]?|rmi|dns|nis|iiop|corba|nds|http):’” ; find /var/log/
-name ’*.gz’ -type f -exec sh -c “zcat {} | sed -e ‘s/${lower://’g | tr
-d’}’ | egrep -i ‘jndi:(ldap[s]?|rmi|dns|nis|iiop|corba|nds|http):’” ;
#searches for exploitation attempts in compressed files in folder
/var/log and all sub folders find /var/log -name *.gz -print0 | xargs -0
zgrep -E -i
‘$({|%7B)jndi:(ldap[s]?|rmi|dns|nis|iiop|corba|nds|http):/[^\n]+’</td>
</tr>
<tr class="even">
<td>#files starting at the current directory (.) and that up to a
maximum of 1 level of subdirectories find . -maxdepth 2 -type f -name
file.txt | xargs -I{} cat {} &gt; ./total_file.txt</td>
</tr>
<tr class="odd">
<td>#Get total size of a list of files perl -le ‘map { $sum += -s }
<span class="citation" data-cites="ARGV">@ARGV</span>; print $sum’ –
*.pdf #Size of all non-hidden PDF files in current directory.</td>
</tr>
<tr class="even">
<td>#list files between 1st Dec 2021 and 1st Jan 2022 and total size of
each file find . -type f -newermt 2012-01-01 ! -newermt 2022-01-01 -exec
du -sh {} ; find . -type f -newermt 2012-01-01 ! -newermt 2022-01-01
-exec ls -lt {} ; | sort -k6M -k7n #sorting month &amp; date based find
. -name ’flibble*’ -ctime +90 -exec du -sh {} ;</td>
</tr>
<tr class="odd">
<td>find . -type f -mmin -5 -print0 | xargs -0 /bin/ls -ltr #which files
was modified in last 5 minutes find . -type f -mmin -5 -exec ls -ltr {}
+ find . -mmin -5 -exec ls -ltrd {} + #not limiting to files</td>
</tr>
<tr class="even">
<td>#list files between 1st Dec 2021 and 1st Jan 2022 and grand total
size of each found files, not sum of total sizes “find . -name”*.tar”
-type f -newermt 2012-01-01 ! -newermt 2022-01-01 -exec du -sch {} +”
find . “<em>.tar” -type f -newermt 2012-01-01 ! -newermt 2022-01-01
-exec du -sch {} + | tail -1 #only total find . -name ”</em>.tar” -type
f -newermt 2012-01-01 ! -newermt 2022-01-01 -exec du -sch {} + | tail -1
| awk ‘{print $1}’</td>
</tr>
<tr class="odd">
<td>$ find . -size +2G #search for all files greater than 2 Gigabytes $
find . -size -10k #search for all files with less than 10 Kilobytes $
find . -size +10M -size -20M #search for files greater than 10MB but
smaller than 20MB $ sudo find /var -size +5M -exec ls -sh {} + #search
for files in /etc directory which are greater than 5MB and print file
size $ find . -type f -exec ls -s {} + | sort -n -r | head -3 #Find
first 3 largest files located in a in a current directory recursively $
find /etc/ -type f -exec ls -s {} + | sort -n | head -3 #Find first 3
smallest files located in a in a current directory recursively $ find .
-type f -size 0b # search for empty files $ find . -type f -empty #
search for empty files</td>
</tr>
<tr class="even">
<td>$ sudo find /var/log -name *.log -size +1M -exec ls -lrt {} ; # find
files larger than 1M,`M’ for Megabytes (units of 1048576 bytes) $ sudo
find /var/log -name *.log -size +1M -exec ls -lrt {} ; | wc -l #get
count $ sudo find /var/log -name *.log -size +1M -exec ls -lrt {} ; |
awk ‘{ total += $5 }; END { print total }’ # get total size, column
5(size) of ls command,</td>
</tr>
<tr class="odd">
<td>#total size of all found files $ sudo find /var/log -name *.log
-size +1M -exec ls -l {} ; | awk ‘{ sum += $5} END<br />
{hum[1024^3]=“Gb”; hum[1024^2]=“Mb”; hum[1024]=“Kb”; for (x=1024^3;
x&gt;=1024; x/=1024) { if (sum&gt;=x) { printf “%.2f %s”,sum/x,hum[x];
break; } } if (sum&lt;1024) print “1kb”; }’</td>
</tr>
<tr class="even">
<td>$ find /var/log/apt -type f -name “*.dat” -size +100M #list files
larger than 100M</td>
</tr>
<tr class="odd">
<td>$ find /var/log/apt -iname <em>.log -print0 | xargs -r0 du -csh |
tail -n 1; # -iname case insensitive $ find /var/log/apt -iname
</em>.log -exec ls -lh {} ;</td>
</tr>
<tr class="even">
<td>$ find /var/log/apt -name <em>.log -size +10c -print0 | du -c
–files0-from=- | awk ’END{print <span class="math inline">$1}'$</span>
find /var/log/apt -name </em>.log -size +10c -print0 | du -ch
–files0-from=- | awk ‘END{print <span class="math inline">$1}'$</span>
find /var/log/apt -name <em>.log -size +10c -print0 | du -ch
–files0-from=- –total -s|tail -1 #xargs pipe “|” calls du command many
times $ find /var/log/apt -name </em>.log -type f -exec ls -s ; |
awk’{sum+=$1;} END {print sum/1000;}’ #excludes all directories du -ch
/var/log/apt | tail -1 | cut -f 1</td>
</tr>
<tr class="odd">
<td>$ (find /var/log/apt -name <em>.log -size +10c -printf ‘%s+’; echo 0
) | bc $ ( find /var/log/apt -name </em>.log -size +10c -printf ‘s+=%s’;
echo s ) | bc</td>
</tr>
<tr class="even">
<td>$ find /var/log/apt -name <em>.log -size +10c -printf ‘%s’ | jq -s
add $ find /var/log/apt -name </em>.log -size +10c -exec stat -c%s ‘{}’
+ | jq -s add</td>
</tr>
<tr class="odd">
<td>find . -name “*.tar” -type f -newermt 2012-01-01 ! -newermt
2022-01-01 -print0 | xargs -0 du -c –block-size=human-readable find .
-name ‘flibble<em>’ -ctime +90 -print0 &gt; filenames &amp;&amp; du -shc
–files0-from=filenames du -c
<code>find . -name 'flibble*' -ctime +90</code> | tail -1 find . -name
’flibble</em>’ -ctime +90 -printf “%s” |perl -lnE ’$sum += $_} END {say
<span class="math inline">$sum'
find . -name 'flibble*' -ctime +90 -printf "%s\t%p\n" |perl -apE
'$</span>sum += $F[0]} END {say <span class="math inline">$sum'
echo "$</span>(( ($(find . -name ’flibble*’ -ctime +90 -type f -printf
‘%k+’ )0)/1024/1024 )) GB”</td>
</tr>
<tr class="even">
<td>#-mtime +7 means older than 8 days (age rounded to integer number of
days greater than 7). log_history=13 &amp;&amp; find
/opt/freeswitch/var/log/freeswitch -type f -mtime +<span
class="math inline">$log_history -delete #Delete old/rotated log files
# if tomcat directory exists,delete logs
log_history=13 &amp;&amp; [[ -d /var/log/tomcat7 ]] &amp;&amp; find
/var/log/tomcat7 -type f -mtime +$</span>log_history -delete #Delete
FreeSWITCH wav/opus recordings older than 13 days history=13 &amp;&amp;
find /var/freeswitch/meetings/ -name “*.wav” -mtime +$history
-delete</td>
</tr>
<tr class="odd">
<td># find all files, SUID bit enabled find / -perm -4000 -exec ls -l {}
; find /usr/bin/ -perm -4000 -exec ls -l {} ; find /bin/ -perm -4000
-exec ls -l {} ; find / -xdev -perm -4000 2&gt;/dev/null</td>
</tr>
<tr class="even">
<td>#-perm denotes that we will search for the permissions that follow:
#-u=s denotes that we will look for files which are owned by the root
user #-type states the type of file we are looking for #f denotes a
regular file, excluding directories and special files find / -perm -u=s
-type f 2&gt;/dev/null</td>
</tr>
<tr class="odd">
<td>find / -uid 0 –perm -4000 -print #find all programs whose SetUID is
set to run as root find / -perm -2000 -exec ls -l {} ; # find all files,
SGID bit enabled</td>
</tr>
<tr class="even">
<td>find /lib/modules/<code>uname -r</code> -type f -name
’<em>quota_v</em>.ko*’</td>
</tr>
<tr class="odd">
<td>#counts files recursively in all subfolders in the specified folder
find /data -type f | wc -l #counts files in the current dir, not
recursively find /data -maxdepth 1 -type f | wc -l #counts folders
recursively in all subfolders in the specified folder find /data -type d
| wc -l</td>
</tr>
<tr class="even">
<td>find -type f -exec md5sum -t {} ; | cut -d ’ ’ -f 1 | sort | md5sum
#compute checksum</td>
</tr>
<tr class="odd">
<td>find . -type f -newermt 2012-02-01 ! -newermt 2022-01-01 #between
1st Dec 2021 and 1st Jan 2022 find . -type f -newermt 2012-02-01 !
-newermt 2022-01-01 -ls #list files between 1st Dec 2021 and 1st Jan
2022 find . -type f -newermt 2012-02-01 ! -newermt 2022-01-01 -exec echo
{} ; #test before delete find . -type f -newermt 2012-02-01 ! -newermt
2022-01-01 -exec rm -rf {} ; #delete between 1st Dec 2021 and 1st Jan
2022 find . -type f -newermt 2012-01-01 ! -newermt 2022-01-01 -exec ls
-l {} ;</td>
</tr>
<tr class="even">
<td>#never put the -delete action at the first position #If the -delete
action is at the first position, during its evaluation, it deletes the
given directory and everything in it #the -delete action implies the
-depth option #The -depth option asks the find command to search each
directory’s contents before the directory itself. # -delete as the first
option, it starts deletion from each directory tree’s very bottom $ find
test -delete -type d -name ‘.git’ # the test directory has been deleted
$ ls test ls: cannot access ‘test’: No such file or directory</td>
</tr>
<tr class="odd">
<td>#the -delete action cannot delete a non-empty directory recursively,
can only delete files and empty directories</td>
</tr>
<tr class="even">
<td>find test -depth -type d -name ‘.git’ -exec rm -r ‘{}’ ; #remove all
.git directories find test -type d -name ‘.git’ | xargs rm -r #remove
all .git directories find ~/Downloads/ -empty -type d -delete #delete
all empty directories find /path/ -empty -type d | wc -l ## count empty
dirs only ## find /path/to/dir/ -type d -empty -print0 | xargs -0 -I {}
/bin/rmdir “{}” #find and delete all empty directories find /path/to/dir
-type d -empty -print0 -exec rmdir -v “{}” ; #find and delete all empty
directories,slow due to -exec $ sudo find /var -type d -empty -mtime +50
$ sudo find /var -type d -empty -mtime +5 -exec sh -c ‘du -sch’ sh {}
+</td>
</tr>
<tr class="odd">
<td>#-exec with an external command, it fills each found file in the
‘{}’ placeholder find test -name ‘whatever.txt’ -exec rm {} ; #remove
all whatever.txt files find test -name ‘whatever.txt’ | xargs rm #remove
all whatever.txt files find ~/Downloads/ -empty -type -f -delete #delete
all empty files find /path/ -empty -type f | wc -l ## count empty files
only ##</td>
</tr>
<tr class="even">
<td>find /path/to/dir/ -type f -empty -print0 | xargs -0 -I {} /bin/rm
“{}” #delete all empty files find /path/to/dir/ -type f -empty -print0
-exec rm -v “{}” ; #delete all empty files,slow due to -exec</td>
</tr>
<tr class="odd">
<td>find / -name .DS_Store -delete #-delete will perform better because
it doesn’t have to spawn an external process for each and every matched
file find / -name “.DS_Store” -exec rm {} ; #recommended because -delete
does not exist in all versions of find find / -iname “*~” -exec rm -i {}
; # gives an interactive delete find / -name .DS_Store -exec rm {} +
#The command termination + instead of ; highly optimizes the exec clause
by not running the rm command for each and every .DS_Store present on
the file system find / -name .DS_Store -print0 | xargs -0 rm #avoiding
the overhead of spawning an external process for each matched file</td>
</tr>
<tr class="even">
<td>find . -type f -newermt 2012-01-01 ! -newermt 2022-01-01 -exec du
-sh {} ;#list files between 1st Dec 2021 and 1st Jan 2022 and total
size</td>
</tr>
<tr class="odd">
<td>#-delete does not delete empty directories $ find /path/to/dir/
-type d -name “.TemporaryItems” -delete find: cannot delete
‘./.TemporaryItems’: Directory not empty $ find /path/to/dir/ -type d
-name “.TemporaryItems” -exec rm -rv “{}” +</td>
</tr>
<tr class="even">
<td>find /home -group ftpusers # list file owned by a user or group find
/data/project -group ftpusers -name “<em>.c” # list file owned by all
</em>.c file belongs to a group called “ftpusers find /data/project
-group ftpusers -name”<em>.c” # list file owned by all </em>.c file
belongs to a group called “ftpusers ,case insensitive find $HOME
-name”<em>.mp4” -group pedro -ls #list file in ls command format pass
the -ls find /var -user pedro find /var/www -user pedro -name “</em>.pl”
# find all *.pl (perl files) file belongs to a user find / -type f -user
bonnie -o -user clyde #find files by users bonnie and clyde find / -type
d -user vivek -o -user wendy #find dirs by users bonnie and clyde</td>
</tr>
</tbody>
</table>
<p>#delete multiple folders in a folder which have files in them</p>
<p>Run the following command to list the folders that will be affected
by the deletion command The output of the find command will display a
list of folder names. Carefully review this list to make sure that it
includes only the folders you intend to delete find . -type d</p>
<p>Once you’re satisfied with the list and have made any necessary
modifications to exclude specific folders, you can run the original
deletion command: find . -type d -exec rm -r {} ;</p>
<p>Use the xargs command to pass the output of the find command to the
rm command: find . -type d | xargs rm -rf</p>
<p>find . -type d -exec rm -r {} ; find .: Searches for files and
directories in the current directory and its subdirectories. -type d:
Specifies that the search should only include directories (folders).
-exec rm -r {} ;: Executes the rm -r command on each found directory.
The {} is a placeholder for the found directory name, and ; indicates
the end of the -exec command. Be cautious when using this command, as it
will delete all directories, including their contents, within the
specified directory.</p>
<p>find . -type d -exec rm -rf {} ; use the -f option with rm to
suppress confirmation prompts and force deletion. However, be cautious
with the -f option, as it will delete without asking for confirmation.
—————————————————————————————————-</p>
<p>find test -type d -name ‘.git’ # list git directories find . -type d
-newermt 2012-02-01 ! -newermt 2022-01-01 -ls #list directories between
1st Dec 2021 and 1st Jan 2022 find . -type d -newermt 2012-03-22 !
-newermt 2022-03-24 -exec echo {} ; #test before delete find . -type d
-newermt 2012-02-01 ! -newermt 2022-01-01 -exec rm -rf {} ; #delete
directories between 1st Dec 2021 and 1st Jan 2022</p>
<p>find /dir/ -type f -newerXY ‘yyyy-mm-dd’ The letters X and Y can be
any of the following letters: a – The access time of the file reference
B – The birth time of the file reference c – The inode status change
time of reference m – The modification time of the file reference t –
reference is interpreted directly as a time</p>
<p>find . -type f -newerat 2017-09-25 ! -newerat 2017-09-26 #all files
accessed on the 25/Sep/2017 find /home/you -iname “<em>.c” -atime 30
-type f #all </em>.c file accessed exactly 30 days ago find /home/you
-iname”<em>.c” -atime -30 -type f #all </em>.c file accessed 30 days
ago, not older than 30 days find /home/you -iname “<em>.c” -atime -30
-type f -ls find /home/you -iname ”</em>.c” -atime +30 -type f #all
<em>.c file accessed more than 30 days ago, older than 30 days find
/home/you -iname “</em>.c” -atime +30 -type f -ls
—————————————————————————————————– #Users of the bash shell need to use
an explicit path in order to run the external time command and #not the
shell builtin variant. On systemwhere time is installed in /usr/bin,</p>
<p>#Real is wall clock time - time from start to finish of the call.
This is all elapsed time including #time slices used by other processes
and time the process spends blocked (for example if it is waiting for
I/O to complete).</p>
<p>#User is the amount of CPU time spent in user-mode code (outside the
kernel) within the process. #This is only actual CPU time used in
executing the process. Other processes and time the process #spends
blocked do not count towards this figure.</p>
<p>#Sys is the amount of CPU time spent in the kernel within the
process. This means executing CPU time #spent in system calls within the
kernel, as opposed to library code, which is still running in
user-space</p>
<p>$ /usr/bin/time -o out.txt sudo find /var/log -name ’*log’ -ctime +1
-exec du -sh {} ; $ cat out.txt 0.01user 0.03system 0:00.06elapsed
76%CPU (0avgtext+0avgdata 8756maxresident)k 0inputs+0outputs
(0major+2771minor)pagefaults 0swaps</p>
<p>#the -exec action runs the specified command on the selected files,
but the command line is built by appending each selected file name at
the end $ /usr/bin/time -o outplus.txt sudo find /var/log -name ’*log’
-ctime +1 -exec du -sh {} +; $ cat outplus.txt 0.00user 0.01system
0:00.02elapsed 73%CPU (0avgtext+0avgdata 8804maxresident)k
0inputs+0outputs (0major+1091minor)pagefaults 0swaps</p>
<p>$ /usr/bin/time -o out.txt sudo find /var/log -name ’<em>log’ -ctime
+1 -exec du -sh {} ; $ /usr/bin/time -f
“—————————————————————————————————- # displays without comments<br />
egrep -v”<sup>#|</sup>$” /etc/zabbix/zabbix_server.conf
—————————————————————————————————– #r = recursive i.e, search
subdirectories within the current directory #n = to print the line
numbers to stdout #i = case insensitive search grep -rni “string” </em>
grep -rni “apache /etc/cron.d”</p>
<p>#string search current and subfolders $ grep -rl “900990” .
./.crs-setup.conf.swp ./crs/crs-setup.conf ./crs-setup.conf</p>
<h1 id="displays-the-comments">displays the comments</h1>
<p>grep ^# /etc/resolv.conf</p>
<h1 id="displays-without-comments">displays without comments</h1>
<p>grep <a href="#fn1" class="footnote-ref" id="fnref1"
role="doc-noteref"><sup>1</sup></a> /etc/resolv.confprint directory/file
structure in the form of a tree grep <a href="#fn2" class="footnote-ref"
id="fnref2" role="doc-noteref"><sup>2</sup></a> /etc/resolv.conffind . |
sed -e “s/[^-][^\/]*// |/g” -e “s/|([^ ])/|-\1/” grep -v “^#”
/etc/zabbix/zabbix_server.conf | grep -v “^$”sed ’’ quote.txt -&gt;
display the contents of the file</p>
<h1 id="search-multiple-strings-words">search multiple strings,
words</h1>
<p>grep ‘string1’ filename | grep ‘string2’ #search two strings in one
line grep -n ‘string1’ filename | grep ‘string2’ #search two strings in
one line and print line numbers grep
‘string1.<em>string2|string2.</em>string1’ filename #search two strings
in one line grep -n ‘string1.<em>string2|string2.</em>string1’ filename
#search two strings in one line and print line numbers grep -E
“string1(?.<em>)string2” file #search two strings in one line grep -nE
”string1(?.</em>)string2” file #search two strings in one line and print
line numbers</p>
<p>#Grep for Multiple Strings grep ‘wordA<em>’'’wordB’ </em>.py ###
Search all python files for ’wordA’ or ‘wordB’ grep ‘word<em>’ </em>.txt
### Search all text files grep ’word1|word2|word3’ /path/to/file grep
‘warning|error|critical’ /var/log/messages grep -e
‘warning|error|critical’ /var/log/messages egrep -wi –color
‘warning|error|critical’ /var/log/messages #-i (ignore case) egrep -wi
–color ‘foo|bar’ /etc/*.conf egrep -Rwi –color ‘foo|bar’ /etc/
#including sub-directories egrep -w ‘warning|error|critical’
/var/log/messages grep -w ‘warning|error|critical’ /var/log/messages</p>
<p>egrep -ne ‘null|three’ #search multiple string and output line
numbers</p>
<p>grep -o “0x[^']*” file.txt # matching text starting with “0x” grep
“zip$” #filters the lines that end in zip</p>
<p>grep -r –include “*.jar” JndiLookup.class / #Detect the presence of
Log4j</p>
<p>grep –color regex filename #Highlight grep –color ksh /etc/shells
grep -o regex filename #Only The Matches, Not The Lines egrep “v{2}”
filename #Match a character “v” two times egrep ‘co{1,2}l’ filename
#match both “col” and “cool” words egrep ‘c{3,}’ filename #match any row
of at least three letters ‘c’ grep “[[:digit:]]{2}[ -]?[[:digit:]]{10}”
filename #match mobile number format 91-1234567890 egrep
‘[[:digit:]]{1,3}.[[:digit:]]{1,3}.[[:digit:]]{1,3}.[[:digit:]]{1,3}’
file #match an IP address,All three dots need to be escaped</p>
<p>$ grep ‘<a href="#fn3" class="footnote-ref" id="fnref3"
role="doc-noteref"><sup>3</sup></a>’ list.txt #lines from list.txt file
that starts with P or Q or R $ grep ‘[^A-C]’ list.txt #lines from
list.txt file that starts with A or B or C</p>
<p>$ grep [!P-R] list.txt #from list.txt file that starts with ‘P’ or Q
or R $ grep [!4-8] list.txt #lines from list.txt file that starts with
any digit from 4 to 8.</p>
<p>$ grep a$ list.txt #lines from list.txt file that ends with ‘a’ $
grep 50$ list.txt #lines from list.txt file that end with the number
50</p>
<p>grep -i “boar” /etc/passwd #Perform a case-insensitive search for the
word ‘bar’</p>
<p>grep “Gnome Display Manager” /etc/passwd #If the search string
includes spaces, enclose it in single or double quotation marks</p>
<p>#the string “linux” will match only if it occurs at the very
beginning of a line grep ‘^linux’ file.txt #The ^ (caret) symbol grep
‘linux<span class="math inline">$' file.txt #lines end with linux string
grep '^linux$</span>’ file.txt #lines contain only linux string grep
‘^.[0-9]’ filename #lines starting with a dot and digit grep ‘^..$’
filename #lines with two characters</p>
<p>#The . (period) symbol is a meta-character that matches any single
character grep ‘kan..roo’ file.txt #match anything that begins with
“kan” then has two characters and ends with the string “roo” grep
‘acce[np]t’ file.txt #find the lines that contain “accept” or “accent”
grep ‘co[^l]a’ file.txt #match any combination of strings starting with
“co” followed by any letter except “l” followed by “la”, such as “coca”,
“cobalt” and so on grep ‘<a href="#fn4" class="footnote-ref" id="fnref4"
role="doc-noteref"><sup>4</sup></a>’ file.txt #matches each line that
starts with a capital letter</p>
<p>grep ‘s<em>right’ #match “right”, “sright” “ssright” and so on grep
-E ’<a href="#fn5" class="footnote-ref" id="fnref5"
role="doc-noteref"><sup>5</sup></a>.</em>[.,]$’ file.txt #matches all
lines that starts with capital letter and ends with either period or
comma</p>
<p>grep ‘b?right’ file.txt #match both “bright” and “right”. The ?
character is escaped with a backslash because we’re using basic regular
expressions grep -E ‘b?right’ file.txt</p>
<p>grep -E ‘s+right’ file.txt #match “sright” and “ssright”, but not
“right” grep -E ‘[[:digit:]]{3,9}’ file.txt #matches all integers that
have between 3 and 9 digits</p>
<p>grep ‘word’ filename grep ‘word’ file1 file2 file3 grep -i “boar”
/etc/passwd #Perform a case-insensitive search for the word ‘bar’</p>
<p>“grep -R ‘httpd’ .” #Look for all files in the current directory and
in all of its subdirectories # search for a keyword in text files within
a folder and its subfolders. grep -r “keyword” /path/to/directory grep
-r “keyword” –include “*.txt” /path/to/directory # search for a keyword
in a specific type of file grep -r -i “keyword” /path/to/directory
#case-sensitive when searching for keywords</p>
<p>grep -r “192.168.1.5” /etc/ #search recursively i.e. read all files
under each directory for a string “192.168.1.5” grep -c ‘nixcraft’
frontpage.md #display the total number of times that the string
‘nixcraft’ appears in a file named frontpage.md</p>
<p>#Grep NOT #-v flag to print inverts the match; that is, it matches
only those lines that do not contain the given word grep -v -c -e “that”
-&gt; find out how many lines that does not match the pattern grep -v
Sales employee.txt #all the lines except those that contains the keyword
“Sales”</p>
<p>grep -w “the” -&gt; Output only those lines that contain the word
‘the’. grep -iw “the” -&gt; Output only those lines that contain the
word ‘the’. The search should NOT be case sensitive. grep -viwe “that”
-&gt; Only display those lines that do NOT contain the word ‘that’. grep
-Eiw “th(e|ose|en|at)” &lt; /dev/stdin -&gt; display all those lines
which contain any of the following words “the,that,then,those” .The
search should not be sensitive to case. Display only those lines of an
input file, which contain the required words.<br />
grep ’([0-9]) *\1’ -&gt; Given an input file, with N credit card
numbers,grep out and output only those credit card numbers which have
two or more consecutive occurences of the same digit (which may be
separated by a space, if they are in different segments). Assume that
the credit card numbers will have 4 space separated segments with 4
digits each</p>
<p>#top 10 IP addresses in the log file. grep -E -o
“([0-9]{1,3}[.]){3}[0-9]{1,3}” access.log | uniq -ci | sort -nr | head
-n10</p>
<p>ifconfig -a | grep -E -o “([0-9]{1,3}[.]){3}[0-9]{1,3}” | awk
’ORS=NR%2?” , “:”“’ ip addr show eth1 | grep inet | awk ‘{ print <span
class="math inline">$2; }' | sed 's/\/.*$</span>//’ ifconfig -a | grep
-E -o”([0-9]{1,3}[.]){3}[0-9]{1,3}”</p>
<p>#list process binary path and permissions ps aux | awk ‘{print $11}’
| xargs -r ls -la 2&gt;/dev/null |awk ‘!x[$0]++’ ps -elf | grep autofs |
grep -v grep | awk ‘{print $4}’ | xargs kill -9</p>
<p>######group expressions,grep -E option is for extended regexp,three
expressions are functionally equivalent grep “(grouping)” file.txt #use
parentheses without using extended regular expressions, escape with the
backslash grep -E “(grouping)” file.txt egrep “(grouping)” file.txt</p>
<p>grep -E “(GPL|General Public License)” GPL-3 #find either GPL or
General Public License in the text grep -E “(copy)?right” GPL-3 #matches
copyright and right by putting copy in an optional group grep -E
‘(fear)?less’ file.txt #matches both “fearless” and “less”. The ?
quantifier makes the (fear) group optional grep -E “free[<a href="#fn6"
class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a>]+”
GPL-3 # matches the string free plus one or more characters that are not
white space characters grep -E “[AEIOUaeiou]{3}” GPL-3 #find all of the
lines in the GPL-3 file that contain triple-vowels grep -E
“[[:alpha:]]{16,20}” GPL-3 #match any words that have between 16 and 20
characters</p>
<p>grep -e pattern1 -e pattern2 filename #Grep OR Using grep -e, egrep
‘Tech|Sales’ employee.txt #Grep OR Using egrep grep ‘Tech|Sales’
employee.txt #Grep OR Using |,grep either Tech or Sales from the
employee.txt file grep ‘fatal|error|critical’ /var/log/nginx/error.log
grep -E ‘fatal|error|critical’ /var/log/nginx/error.log # use the
extended regular expression, then the operator | should not be escaped
grep -E ‘Tech|Sales’ employee.txt #Grep OR Using -E</p>
<p>#Grep AND grep Manager employee.txt | grep Sales #all the lines that
contain both “Manager” and “Sales” in the same line grep -E ’Dev.*Tech’
employee.txt #all the lines that contain both “Dev” and “Tech” in it (in
the same order). grep -E ‘Manager.<em>Sales|Sales.</em>Manager’
employee.txt #all the lines that contain both “Manager” and “Sales” in
it (in any order) —————————————————————————————————– user@host: $
cat&lt;<EOF > file.txt $ &gt; 1 line $ &gt; other line $ &gt; n line $
&gt; EOF user@host: —————————————————————————————————– # append text
cat&lt;&lt;EOF | sudo tee -a ceph.conf public network = 192.168.18.0/24
osd pool default size = 2 EOF —————————————————————————————————– sudo
install consul /usr/bin/consul ( cat &lt;&lt;-EOF [Unit]
Description=consul agent Requires=network-online.target
After=network-online.target [Service] Restart=on-failure
ExecStart=/usr/bin/consul agent -dev ExecReload=/bin/kill -HUP $MAINPID
[Install] WantedBy=multi-user.target EOF ) | sudo tee
/etc/systemd/system/consul.service —————————————————————————————————–
cat &lt;&lt;EOT | sudo tee /lib/systemd/system/procenv.service [Unit]
Description=Display systemd environment</p>
<p>[Service] Type=oneshot ExecStart=/usr/bin/procenv
–file=/tmp/procenv-systemd.log EOT —————————————————————————————————–
&gt; outputs to a file &gt;&gt; appends to a file &lt; reads input
&lt;&lt;Here tells the shell that you are going to enter a multiline
string until the “tag” Here. You can name this tag as you want, it’s
often EOF or STOP. “EOF” is known as a “Here Tag”</p>
<p>The redirection operators “&lt;&lt;” and “&lt;&lt;-” both allow
redirection of lines contained in a shell input file, known as a
“here-document”, to the input of a command.</p>
<p>The format of here-documents is: &lt;&lt;[-]word here-document
delimiter</p>
<p>If the redirection operator is &lt;&lt;-, then all leading tab
characters are stripped from input lines and the line containing
delimiter. This allows here-documents within shell scripts to be
indented in a natural fashion. —————————————————————————————————– #
Assign multi-line string to a shell variable # The <span
class="math inline">$sql variable now holds the new-line characters
# verify with echo -e "$</span>sql” sql=<span class="math inline">$(cat
&lt;&lt;EOF
SELECT foo, bar FROM db
WHERE foo='baz'
EOF
)
-----------------------------------------------------------------------------------------------------
#Pass multi-line string to a file in Bash$</span> cat &lt;<EOF >
print.sh #!/bin/bash echo $PWD echo <span class="math inline">$PWD
EOF
-----------------------------------------------------------------------------------------------------
# Pass multi-line string to a pipe in Bash$</span> cat &lt;&lt;EOF |
grep ‘b’ | tee b.txt foo bar baz EOF —————————————————————————————————–
$ sudo tee &lt;&lt;EOF /etc/somedir/foo.conf &gt;/dev/null # my config
file foo=bar EOF —————————————————————————————————– echo -e ” Home
Directory: $HOME hello world 1 hello world 2 line n… ” &gt; file.txt
—————————————————————————————————– echo write something to file.txt |
cat &gt; file.txt cat &gt;file.txt &lt;&lt;&lt; Write something here</p>
<h1 id="see-the-line-numbers">see the line numbers</h1>
<p>cat -n song.txt # shows at the end of line and also in space showing
’$‘ if there is any gap between paragraphs # useful to squeeze multiple
lines in a single line. cat -e test # all output will be redirected in a
newly created file cat test test1 test2 &gt; test3 # Sorting Contents of
Multiple Files in a Single File cat test test1 test2 test3 | sort &gt;
test4 # Display Multiple Files at Once cat test; cat test1; cat
test2</p>
<h1 id="append-your-text-to-the-end-of-the-file">append your text to the
end of the file</h1>
<p>cat &gt;&gt; ~/.bashrc &lt;&lt;EOF # my config file foo=bar EOF</p>
<p>cat &gt; /sys/devices/system/cpu/cpu1/cpufreq/scaling_governor
&lt;&lt;EOF performance EOF —————————————————————————————————– curl -sSL
https://releases.hashicorp.com/nomad/<span
class="math inline">${NOMAD_VERSION}/nomad_$</span>{NOMAD_VERSION}_linux_amd64.zip
-o nomad.zip https://releases.hashicorp.com/packer/<span
class="math inline">${PACKER_VERSION}/packer_$</span>{PACKER_VERSION}_linux_amd64.zip<br />
curl -sSL https://releases.hashicorp.com/vagrant/<span
class="math inline">${VAGRANT_VERSION}/vagrant_$</span>{VAGRANT_VERSION}_linux_amd64.zip
-o vagrant.zip curl -sSL
https://releases.hashicorp.com/vagrant/2.2.2/vagrant_2.2.2_linux_amd64.zip
-o vagrant.zip unzip vagrant.zip</p>
<p>$ curl -L
https://raw.githubusercontent.com/do-community/ansible-playbooks/master/docker/ubuntu1804.yml
-o /vagrant/docker_ubuntu.yml</p>
<p>export VER=“4.4.6” “curl -SL
https://github.com/NagiosEnterprises/nagioscore/releases/download/nagios-<span
class="math inline"><em>V</em><em>E</em><em>R</em>/<em>n</em><em>a</em><em>g</em><em>i</em><em>o</em><em>s</em>−</span>VER.tar.gz
| tar -xzf -” cd nagios-$VER —————————————————————————————— tar -C
/usr/local -xzf go1.19.linux-amd64.tar.gz # extract the archive into
/usr/local, creating a fresh Go tree in /usr/local/go
—————————————————————————————— split –bytes=2048m WinXP.img WinXP_img_ #
four files (2GB each) appeared WinXP_img_aa WinXP_img_ab WinXP_img_ac
WinXP_img_ad cat WinXP_img_* &gt; WinXP.img</p>
<h1 id="join-smaller-files-into-a-larger-one">join smaller files into a
larger one</h1>
<p>cat partfilename* &gt; outputfilename</p>
<p>video.avi.01 video.avi.02 video.avi.03 cat video.avi.* &gt;
video1.avi</p>
<p>$ cat file1 1. Asia: 2. Africa: 3. Europe: 4. North America:</p>
<p>tac tacexample.txt #print files in reverse $ tac file1 4. North
America: 3. Europe: 2. Africa: 1. Asia:</p>
<p>$ cat file2 1. India 2. Nigeria 3. The Netherlands 4. The US $ join
file1 file2 1. Asia: India 2. Africa: Nigeria 3. Europe: The Netherlands
4. North America: The US</p>
<p>join -1 1 -2 1 -e ‘empty’ /tmp/in /tmp/out | tr ” ” “ #join the two
files,the first column in each file as index</p>
<h1
id="create-a-new-file-new.txt-that-is-a-concatenation-of-file1.txt-and-file2.txt">create
a new file “new.txt” that is a concatenation of “file1.txt” and
“file2.txt”</h1>
<p>cat file1.txt file2.txt &gt; new.txt</p>
<p>format text and convert it to a different width $ fmt –width=20
test.txt —————————————————————————————— g++ -v g++ temp.cpp # run
./a.out —————————————————————————————— # Installing software from source
tar xvzf package.tar.gz tar xvjf package.tar.bz2 cd package ./configure
make make install # Cleaning up make clean make uninstall</p>
<h1
id="make-clean-runs-as-expected-even-if-you-do-have-a-file-named-clean.">“make
clean” runs as expected even if you do have a file named clean.</h1>
<h1
id="there-are-two-reasons-to-use-a-phony-target-to-avoid-a-conflict-with-a-file-of-the-same-name-and-to-improve-performance.">There
are two reasons to use a phony target: to avoid a conflict with a file
of the same name, and to improve performance.</h1>
<p>.PHONY: clean clean: rm -rf *.o</p>
<h1 id="case1">case1</h1>
<p>$ cat make hello : hello.o gcc -Wall hello.o -o hello $ cat hello.c
#include&lt;stdio.h&gt;</p>
<p>int main(void) { printf(“Hello World!!!”); return 0; } $ cp make
mon-makefile $ ls hello.c make mon-makefile</p>
<p>make -C makefile-test1/ hello make -f mon-makefile make -s</p>
<h1 id="case2">case2</h1>
<p>$ cat file2.h void add(int a, int b, void (*f)(int)); $ cat file2.c
#include&lt;stdio.h&gt; #include”file2.h”</p>
<p>void add(int a, int b, void(*f)(int)) { int c = a+b; f(c); } $ cat
file1.c #include&lt;stdio.h&gt; #include”file2.h”</p>
<p>void callback (int result) { printf(“Result is : [%d] ”, result);
}</p>
<p>int main(void) { int a=0,b=0; printf(“Enter two numbers to add:”);
scanf(“%d %d”,&amp;a, &amp;b); add(a,b,callback); return 0; } $ cat
makefile file : file1.o file2.o gcc -Wall file2.o file1.o -o file</p>
<p>file1.o : file1.c file2.h gcc -c -Wall file1.c -o file1.o</p>
<p>file2.o : file2.c file2.h gcc -c -Wall file2.c -o file2.o $ cp make
mon-makefile $ ls file1.c file2.c file2.h makefile mon_makefile</p>
<table>
<colgroup>
<col style="width: 28%" />
<col style="width: 71%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;"># linux system management top sar vmstat
iostat free ps tcpdump iptraf nestat</th>
<th style="text-align: left;">ous Kernel Statistics</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">$ uptime #“system load averages” th #show
three averages, for #If the averages are 0.0, #If the 1 minute average i
#If the 1 minute average i</td>
<td style="text-align: left;">at show the running thread (task) demand
on the system as an average number of running plus waiting threads. 1,
5, and 15 minutes system is idle s higher than the 5 or 15 minute
averages, then load is increasing s lower than the 5 or 15 minute
averages, then load is decreasing.</td>
</tr>
<tr class="even">
<td style="text-align: left;">ps -eL h -o state | egrep #Linux load
average,the in #either in state R or D, e</td>
<td style="text-align: left;">“R|D” | wc -l #The instantaneous number of
such tasks stantaneous load of a system the number of tasks (processes
and threads) that are willing to run at a given time t ither actually
running or blocked on some resource (CPU, IO, …) waiting for an
opportunity to run</td>
</tr>
</tbody>
</table>
<p>list user vagrant’s full command line of processes $ top -c -u
vagrant ignore idle processes $ top -i -u vagrant updated with 5 secs
intervals, including child processes $ top -u vagrant -c -d 5 -S
#determine which Plaso processes are running top -p
<code>ps -ef | grep log2timeline.py | grep python | awk '{ print $2 }' | tr '\n' ',' | sed 's/,$//'</code></p>
<p>#interactive top command #If you have a multi-core CPU, press “1” to
change the display and see individual statistics for each CPU #press “t”
to swap the CPU displays to simple ASCII graphs that show the percentage
of usage for each CPU #Pressing “c” toggles the COMMAND column between
displaying the process name and the full command line #Press “u” to see
the processes for a single user. You’ll be prompted for the name or UID
#Press I to see only active tasks. #press “r” to change the nice value
(priority) for a process #Press “k” to kill a process. You’ll then be
prompted for the process ID you want to kill
—————————————————————————————— The load averages shown by these tools is
read /proc/loadavg file cat /proc/loadavg</p>
<table>
<colgroup>
<col style="width: 100%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;"># same inodes ls -ldi /. /.. 2 drwxr-xr-x
24 root root 4096 Feb 21 20:28 /. 2 drwxr-xr-x 24 root root 4096 Feb 21
20:28 /..</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">#ChatGPT</td>
</tr>
<tr class="even">
<td style="text-align: left;">Both .bashrc and .profile files are used
for setting environment variables and defining user-specific
configurations on Linux, but they have some differences in their purpose
and usage.</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Here are some of the differences between
.bashrc and .profile files:</td>
</tr>
<tr class="even">
<td style="text-align: left;">File Location: .bashrc is a Bash
shell-specific initialization file that is located in the user’s home
directory. On the other hand, .profile is a generic shell initialization
file that is also located in the user’s home directory.</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Shell Usage: .bashrc is loaded for Bash
shell instances only, while .profile is loaded for every shell instance
(including Bash, Korn shell, Bourne shell, etc.) that is started.</td>
</tr>
<tr class="even">
<td style="text-align: left;">Invocation: .bashrc is invoked for
non-login shells, while .profile is invoked for login shells.</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Content: .bashrc is typically used for
setting Bash shell-specific configurations such as aliases, environment
variables, and command prompt settings, while .profile is used for
setting environment variables and other configurations that should be
applied to all shells.</td>
</tr>
<tr class="even">
<td style="text-align: left;">Loading order: When a Bash shell instance
is started, it first loads the /etc/profile file, which is a system-wide
shell initialization file. After that, it loads the user’s
~/.bash_profile or ~/.bash_login or ~/.profile file (in that order) if
it exists. If none of these files exist, it loads the ~/.bashrc
file.</td>
</tr>
<tr class="odd">
<td style="text-align: left;">In summary, .bashrc is used for Bash
shell-specific configurations, while .profile is used for general shell
configurations that should apply to all shells. .bashrc is loaded for
non-login shells, while .profile is loaded for login shells.</td>
</tr>
</tbody>
</table>
<h1 id="the-user-file-creation-mode-mask-umask">The user file-creation
mode mask (umask)</h1>
<p>/etc/profile ~/.bashrc ~/.bash_profile</p>
<h1 id="by-default">By default</h1>
<p>0022 (022) 0002 (002) files 666 directories 777</p>
<p>The default umask 002 used for normal user directory permissions 775
file permissions 664</p>
<p>The default umask for the root user is 022 directory permissions 755
file permissions 644</p>
<p>base permissions directory permissions (rwxrwxrwx) 0777 file
permissions (rw-rw-rw) 0666</p>
<h1 id="no-other-user-can-read-or-write-your-data">No other user can
read or write your data</h1>
<p>umask 077 # when you share data with other users in the same group #
Members of your group can create and modify data files # those outside
your group can read data file, but cannot modify it. umask 022 # exclude
users who are not group members umask 007</p>
<h1
id="the-octal-umasks-are-calculated-via-the-bitwise-and-of-the-unary-complement-of-the-argument-using-bitwise-not">The
octal umasks are calculated via the bitwise AND of the unary complement
of the argument using bitwise NOT</h1>
<pre><code>            Octal value : Permission
            0 : read, write and execute
            1 : read and write
            2 : read and execute
            3 : read only
            4 : write and execute
            5 : write only
            6 : execute only
            7 : no permissions</code></pre>
<table>
<colgroup>
<col style="width: 100%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;"># testing webpages</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"># delete files containing special
chars</td>
</tr>
<tr class="even">
<td style="text-align: left;">$ cat&gt;&gt;“-f”&lt;<EOF
> test &gt; EOF</td>
</tr>
<tr class="odd">
<td style="text-align: left;">$ ls -f test test2 videos</td>
</tr>
<tr class="even">
<td style="text-align: left;">$ ls -li total 260 3145770 -rw-rw-r– 1
vagrant vagrant 5 Mar 5 17:02 -f</td>
</tr>
<tr class="odd">
<td style="text-align: left;">find / -name wget 2&gt;/dev/null find
/home/vagrant -name file1 find /home/vagrant -user root find
/home/vagrant -group root find . -inum 3145770 -delete find . -inum
3145770 -exec rm -i {} ; ls -il {file-name} find . -inum [inode] -exec
rm -i {} ;</td>
</tr>
</tbody>
</table>
<h1
id="steganography-attaching-a-.rar-file-to-a-.jpg-etc.">steganography,
attaching a .rar file to a .jpg etc.</h1>
<h2 id="cat-pic.jpg-file.rar-result.jpg">cat pic.jpg file.rar &gt;
result.jpg</h2>
<h1 id="view-used-irqs">view used IRQs</h1>
<p>cat /proc/interrupts #determine the IRQ number associated with the
Ethernet driver $ grep enp0s3 /proc/interrupts 19: 24006 IO-APIC-fasteoi
enp0s3 $ grep eth0 /proc/interrupts 19: 13247 IO-APIC 19-fasteoi
eth0</p>
<p># troubleshoot network card etc. hardware conflicts, what addresses
are used or free, or move conflicting hardware to free resource #
listing IRQs currently being used.not listed IRQs are considered
free.used when devices alert CPU to take action cat /proc/interrupts #
listing used DMA channel.when devicess access memory directly without
going through CPU cat /proc/dma # listing I/O ports currently being
used.any range not listed is free and can be used by other devices. #
devices have unique I/O addresses cat /proc/ioports</p>
<table>
<colgroup>
<col style="width: 100%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;"># view default shell for each user $ cat
/etc/passwd # There are seven fields in the /etc/passwd file # username,
UID, GID, comment, home directory, command # add an asterisk at the
beginning of the password field in the /etc/passwd file, that user will
not be able to log in /etc/passwd</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">#use useradd instead of its interactive
wrapper adduser</td>
</tr>
<tr class="even">
<td style="text-align: left;"># create new user, new group with the same
name sudo adduser sdn –system –group make sure username is added to the
group libvirtd $ sudo adduser <code>id -un</code> libvirtd $ sudo
adduser $(id -un) libvirtd</td>
</tr>
</tbody>
</table>
<p>#edit the managers entry in /etc/group to make sally, tom, and dale
members of the group managers (GID 501),the #order of users in the
comma-separated user list is unimportant
managers:x:501:dale,sally,tom</p>
<p>cat /etc/group cat /etc/gshadow cut -d: -f1 /etc/group | sort $
groupadd admins #add new group $ sudo groupdel sshusers $ useradd -G
admins member1 sudo usermod -aG docker ${USER} #Add current logged in
user to the docker group. sudo usermod -aG docker $(whoami) #Add current
logged in user to the docker group. gpasswd -a devops1 sudo #Adding user
devops1 to group sudo gpasswd -d devops1 sudo #Removing user devops1
from group sudo</p>
<p>#list groups on Linux,/etc/group file $ getent group $ getent group
sudo # sudo group has ID of 27 and has ubuntu,barak,packer as members
sudo:x:27:ubuntu,barak,packer $ cat /etc/group | awk -F: ’{print <span
class="math inline">$1}'$</span> cat /etc/group | cut -d: -f1</p>
<p>$ groups # list the groups for the current logged user $ groups barak
#get a list of groups a specific user is in</p>
<p>whoami grep “^<span class="math inline">$(whoami):" /etc/subuid
grep "^$</span>(whoami):” /etc/subgid id -u print only the effective
user ID id -Gn id vagrant</p>
<h1
id="the-newgrp-command-allows-a-user-to-override-the-current-primary-group.">The
newgrp command allows a user to override the current primary group.</h1>
<h1
id="newgrp-can-be-handy-when-you-are-working-in-a-directory-where-all-files-must-have-the-same-group-ownership">newgrp
can be handy when you are working in a directory where all files must
have the same group ownership</h1>
<p>newgrp microk8s #When you run the command, the system places you in a
new shell and changes the name of your real group to the group specified
with the Group parameter #If you’re listed as member of the group and
the group has a password assigned, then you won’t be prompted #If there
is no group password set, and the user is not listed as a member of the
group, the user will be denied access #you are not a member of the
developers group and not a root, then you’ll be prompted for a group
password if your account doesn’t have a password assigned #If you’re
root, then no prompted is presented. newgrp developers newgrp -
developers #log in to the group developers sudo groupadd developers
#create group developers sudo usermod -a -G developers richard sudo
gpasswd developers</p>
<p>#system account vs user account #System users will be created with no
aging information in /etc/shadow #numeric identifiers are chosen in the
SYS_UID_MIN–SYS_UID_MAX range defined in /etc/login.defs useradd –system
appuser chage -l appuser useradd –system –shell=/usr/sbin/nologin
<username> #create a system user (without home directory and login
shell) useradd -r subversion #-r, –system create a system account
adduser -r -s /bin/nologin subversion #create system account -s
/sbin/nologin to disable any login shell adduser –system –no-create-home
–group yourusername adduser subversion –system –group adduser -r -s
/bin/nologin subversion</p>
<p>$ sudo groupadd –system –gid 1002 appuser $ cat /etc/group | grep
appuser appuser:x:1002: $ sudo useradd –no-log-init –system –uid 1001
–gid 1002 appuser $ cat /etc/passwd | grep appuser
appuser:x:1001:1002::/home/appuser:/bin/sh</p>
<h1 id="list-a-groups-members">list a group’s members</h1>
<p>$ sudo lid -g sales $ cut -d: -f1,4 /etc/passwd | grep $(getent group
sales | cut -d: -f3) | cut -d: -f1 id username grep “docker” /etc/group
grep -i –color ‘root’ /etc/group getent group -&gt; List all groups cat
/etc/group -&gt; List all groups getent group vboxusers groups -&gt;
View the Groups a User Account groupmod -g 3000 foo -&gt; assign a new
GID to group called foo —————————————————————————————— The command
you’ve provided is a Linux shell command that utilizes the cp command to
copy files and directories. Let’s break down the components of the
command:</p>
<pre><code>cp: This is the command itself, which stands for &quot;copy.&quot; It&#39;s used to copy files or directories from one location to another.

-vrbi: These are options or flags that modify how the cp command behaves:

    -v: Stands for &quot;verbose.&quot; When this option is used, the cp command will provide more detailed output, showing the names of files as they are copied.

    -r: Stands for &quot;recursive.&quot; This option is used when copying directories. It tells the cp command to copy not only the specified directory but also its contents and subdirectories.

    -b: Stands for &quot;backup.&quot; With this option, the cp command will create backup copies of files that already exist in the destination directory before overwriting them.

    -i: Stands for &quot;interactive.&quot; When this option is used, the cp command will prompt you for confirmation before overwriting files in the destination directory. This is a safety measure to prevent accidental data loss.

/etc/skel/.: This is the source directory or file. In this case, it&#39;s the .skel directory located in the /etc directory. The /etc/skel directory is often used as a template for creating user home directories.

~/: This is the destination directory. The tilde (~) is a shorthand notation for the user&#39;s home directory. So, this part of the command specifies that the copied content should be placed in the user&#39;s home directory.</code></pre>
<p>The purpose of this command is to copy the contents of the /etc/skel
directory (which often contains default settings and configurations for
new user accounts) into the user’s home directory. It uses various
options like -v, -r, -b, and -i to control the copying process and
handle situations where files already exist in the destination
directory.</p>
<p>To automatically answer “yes” to the interactive prompts and proceed
with copying without manual confirmation, you can use the yes command in
combination with the cp command. The yes command repeatedly outputs the
letter “y” (or any other specified character) in response to prompts.
Here’s an example of how you could use it:</p>
<p>sh</p>
<p>yes | cp -vrbi /etc/skel/. ~/</p>
<h2
id="in-this-example-the-yes-command-keeps-providing-y-responses-to-the-interactive-prompts-effectively-saying-yes-to-each-one.-this-allows-the-cp-command-to-copy-files-without-requiring-manual-confirmation.">In
this example, the yes command keeps providing “y” responses to the
interactive prompts, effectively saying “yes” to each one. This allows
the cp command to copy files without requiring manual confirmation.</h2>
<p>#Files in /etc/skel are copied from this directory to new users’ home
directories by certain account-creation tools #The files should be in
all new users’ home directories should reside in /etc/skel. “skeleton”
directory is defined in /etc/default/useradd file. # ls -lart /etc/skel
# ls -ldi /etc/skel 33554552 drwxr-xr-x. 2 root root 62 Mar 24 2018
/etc/skel —————————————————————————————— valid login shells # cat
/etc/shells #list all available shells # chsh -l</p>
<p>chsh -s /bin/ksh #Regular user can change their shell to the ksh</p>
<p>$ ps -p $$ PID TTY TIME CMD 56017 pts/0 00:00:00 bash</p>
<p>grep tecmint /etc/passwd #view default login shell usermod –shell
/bin/bash tecmint #change its login shell from /bin/sh to /bin/bash grep
tecmint /etc/passwd #verify /bin/bash</p>
<p>grep tecmint /etc/passwd #view default login shell chsh –shell
/bin/bash tecmint #change its login shell from /bin/sh to /bin/bash grep
tecmint /etc/passwd #verify /bin/bash</p>
<p>$ sudo chsh -s /bin/ksh UserName #The superuser (root) changes the
login shell for any account chsh -s /bin/ksh vagrant #set default login
shell to /bin/ksh for vagrant user</p>
<p>#open the /etc/passwd file, change manually vi /etc/passwd</p>
<p>chsh vagrant -s /bin/rbash #change user vagrant’s shell su - vagrant
#login to activate shell</p>
<p>whereis ksh grep –color ksh /etc/shells cat /etc/shells echo
$SHELL</p>
<p>~ [23]$ ps -p $$ PID TTY TIME CMD 193052 pts/1 00:00:00 ksh</p>
<p>~ [27]$ ps -hp $$ | awk ‘{print $5}’ -ksh</p>
<p>~ [28]$ echo $0 -ksh</p>
<p>~ [29]$ printf “%s” $0 -ksh</p>
<p>~ [30]$ readlink /proc/$$/exe /usr/bin/ksh93</p>
<p>awk -F: ‘/vagrant/ { print <span class="math inline">$7}' /etc/passwd
#list user's shell type
sudo ps -ef | egrep 'tty|pts' #Listing all shell types used by
users$</span> w -h | awk’{print $2}’ | xargs -L1 pgrep -oat</p>
<p>verify user vagrant’s bash # cat /etc/passwd | grep vagrant # echo
$SHELL Reading Library editor $ cat /etc/inputrc keyboard bindings $
bind -v —————————————————————————————— semicolon “;” multiple commands
on the same line backaslash “" run commands longer than one line press
tab key or twice ESC key, command completion”./” run a command from pwd
—————————————————————————————— history file size setting $ cat
/etc/profile $ echo $HISTSIZE $ echo $HISTFILE $ fc -l</p>
<p>#Linux Command History with date and time, temporary
HISTTIMEFORMAT=“%d/%m/%y %H:%M” HISTTIMEFORMAT=“%d/%m/%y %T”</p>
<p>export HISTSIZE=0 #Disable the usage of history using HISTSIZE echo
$HISTSIZE echo $HISTFILE export HISTCONTROL=ignoredups #Eliminate the
continuous repeated entry from history using HISTCONTROL export
HISTIGNORE=“pwd:ls:ls -ltr:” #Ignore specific commands from the history
using HISTIGNORE export HISTCONTROL=erasedups #Erase duplicates across
the whole history using HISTCONTROL export HISTCONTROL=ignorespace
#Force history not to remember a particular command using HISTCONTROL #
service httpd stop [Note that there is a space at the beginning of
service,to ignore this command from history]</p>
<p>history -c #Clear all the previous history</p>
<h1
id="ps-execute-previous-command-that-starts-with-a-specific-word">!ps
#Execute previous command that starts with a specific word</h1>
<h1 id="execute-a-specific-command-from-history">!4 #Execute a specific
command from history</h1>
<h1 id="execute-the-second-last-command">!-1 #execute the second last
command</h1>
<h1 id="run-the-last-executed-command-or-press-ctrlp">!! #run the last
executed command, or press CTRL+P</h1>
<h1
id="dconf-re-run-the-last-command-with-the-keyword-dconf-in-it">!dconf
#re-run the last command with the keyword ‘dconf’ in it</h1>
<p>#lastb #shows users that failed to login,review the /var/log/btmp
file (containing failed login attempts)</p>
<p>#the login history of users last logins last -R #review the contents
of the /var/log/wtmp binary file last | grep sysadmin last -f
/var/log/btmp #Use the last command to view the btmp file last mark
#pass the user name last pts/0 #pass the tty last mark root pts/0
#specify multiple usernames and ttys last -p 2020-01-15 #find out who
logged into the system on a specific date last -s 2020-02-13 -u
2020-02-18 #the -s (–since) and -t (–until) option to tell last to
display the lines since or until the specified time last -F #y default,
last doesn’t show the seconds and the year. Use the -F, –fulltimes
option last -25 #last 25 logins last -i #IP address last -d #DNS address
#the system last rebooted last reboot ——————————————————————————————
echo $PATH view all the env variables $ export -p $ set Set an
Environment Variable $ export MYAPP=1 holds the list of all directories
that are searched by the shell when you type a command name $PATH</p>
<p>system-wide $ cat /etc/profile single user $ cat .bash_profile # add
PATH vi .bash_profile export PATH=<span
class="math inline"><em>P</em><em>A</em><em>T</em><em>H</em>:</span>HOME/Downloads/terraform
system-wide prompt setting $ cat /etc/bashrc $ echo $PS1
—————————————————————————————— Display current libraries from the cache
# ldconfig -p | head -5 Display libraries from every directory ldconfig
-v | head # cat /etc/ld.so.conf —————————————————————————————— # number
the lines in a file nl alphaservices | tee alphabetservices</p>
<p>$ cat file1 1. Asia: 2. Africa: 3. Europe: 4. North America: Display
the contents of file.txt in octal format (one byte per integer) $ od -b
file1 0000000 061 056 040 101 163 151 141 072 012 062 056 040 101 146
162 151 0000020 143 141 072 012 063 056 040 105 165 162 157 160 145 072
012 064 0000040 056 040 116 157 162 164 150 040 101 155 145 162 151 143
141 072 0000060 012 0000061 Display the contents of file.txt in ASCII
(character) format, with byte offsets displayed as hexadecimal. $ od -Ax
-c file1 000000 1 . A s i a : . A f r i 000010 c a : . E u r o p e :
000020 . N o r t h A m e r i c a : 000030 ——————————————————————————————
echo -n “hola” | od -A n -t x1 | sed ’s/ *//g’ | tr -d ‘’ &gt;&gt;
engineID_hex.txt #strips spaces remove newlines
—————————————————————————————— # merge all files in the directory and
split ls | xargs cat | tee file1 | split -5 # printing pr -h “title”
file1 list mounted file systems $ cat /etc/mtab</p>
<p>split -l 4 index.txt split_file #Split file based on number of lines
split index.txt -l 4 –verbose split -l 4 -a 4 index.txt #Change in
suffix length. By default, the suffix length is 2 split -l 4 -d
index.txt #change the split files suffix to numeric split -l 4 index.txt
split_index_ # create split output files with index suffix, split -l 4
-e index.txt #Avoid zero-sized split files split -n 3 index.txt #Create
n chunks output files split -n 2 index.txt #Split the file into two
files of equal length #split the file index.txt into separate files
called indexaa, indexab, …..with each file containing 16 bytes of data
split -b 16 index.txt index split -b=1M -d file.txt file
–additional-suffix=.txt split -b 10M -d system.log system_split.log</p>
<p>~$ cat test.txt | wc -l 40 ~$ split –numeric-suffixes=2
–additional-suffix=.txt -l 22 test.txt file $ ls -lai file* 2139
-rw-rw-r– 1 vagrant vagrant 660 Mar 21 11:01 file02.txt 5482 -rw-rw-r– 1
vagrant vagrant 660 Mar 21 11:01 file03.txt 5483 -rw-rw-r– 1 vagrant
vagrant 660 Mar 21 11:01 file04.txt 18296 -rw-rw-r– 1 vagrant vagrant
220 Mar 21 11:01 file05.txt $ cat file04.txt | wc -l 12 $ cat file05.txt
| wc -l 4 —————————————————————————————————– u stands for user. g stands
for group. o stands for others. a stands for all.</p>
<p>same output: chmod -R 755 /var/www/html #change the permissions of
all files and subdirectories under the /var/www/html directory to 755
chmod +x somefile (Based on umask value) chmod a+x somefile, chmod ugo+x
somefile (Without considering umask value), add the execute permission
for everyone</p>
<p>chmod 644 a.txt stat -c %a a.txt # verify permission granted is 644
—————————————————————————————— Applying SUID Permission Numerically #
chmod 4755 /bin/ping Removing SUID by Numerically chmod 0755 /bin/ping
Applying SUID Permission to ping binary file Alphabetically # chmod u+s
/bin/ping Removing SUID Permission chmod u-s /bin/ping
—————————————————————————————— # Applying SGID Permission chmod g+s
/database/ chmod 2775 database/ # Remove SGID Alphabetically chmod g-s
/database/ chmod 0775 /database —————————————————————————————— a sticky
bit is now in place and only root, file or directory owners can rename
and delete files # chmod +t /var/share/ # ls -ld /var/share/ drwxrwxrwt.
2 root root 4096 Mar 5 11:21 /var/share/</p>
<p>chmod 0777 somefile (octal) chmod 777 somefile (decimal)</p>
<p>chmod 0710 mydir ; ls -ld mydir chmod 00710 mydir ; ls -ld mydir
—————————————————————————————— # quota settings sudo apt update ; sudo
apt install quota -y quota –version find
/lib/modules/<code>uname -r</code> -type f -name ’<em>quota_v</em>.ko*’
sudo mount -o remount / cat /proc/mounts | grep ’ / sudo quotacheck -ugm
/ sudo quotaon -v / sudo setquota -u member1 200M 240M 0 0 / sudo quota
-vs member1 sudo setquota -t 864000 864000 / sudo repquota -s /
—————————————————————————————— # ldd (Unix) ldd (List Dynamic
Dependencies) ldd /bin/ls # display unused direct dependencies ldd -u
/bin/ping # more information ldd -v /bin/ping
—————————————————————————————— # rename root $ head -2 /etc/passwd
root:x:0:0:root:/root:/bin/nologin rootmon:x:0:0:root:/root:/bin/bash $
sudo passwd rootmon $ su - rootmon # pwd /root</p>
<p>#gain a root shell is by adding a new user to /etc/passwd who has the
UID 0 #any user with UID 0 is effectively root #root2 is the username
#WVLY0mgH0RtUI is the encrypted password we want him to have.
Unencrypted, the password is mrcake, in this case #0:0 means the user id
and group id are both 0 #root is a comment field #/root is the home
directory #/bin/bash is the default shell
root2:WVLY0mgH0RtUI:0:0:root:/root:/bin/bash</p>
<p>#Administrative databases in Unix,getent – get entries from
administrative database passwd – can be used to confirm usernames,
userids, home directories and full names of your users group – all the
information about Unix groups known to your system services – all the
Unix services configured on your system networks – networking
information – what networks your system belongs to protocols –
everything your system knows about network protocols</p>
<p>$ getent hosts # /etc/hosts file $ getent hosts vg-ubuntu-01
double-check which IPs this hostname points to $ getent networks #check
the network and IP address of your system $ getent services 20 #Use
“services” with the port number to find the service name and its
protocol</p>
<p>#List Users(system and normal users) on Linux using the /etc/passwd
File, normal user has a real login shell and a home directory. awk -F:
‘{ print $1}’ /etc/passwd cat /etc/passwd | awk -F: ‘{print $1}’ awk -F:
‘{ print $1}’ /etc/passwd | wc -l # get the # of users cut -d: -f1
/etc/passwd cat /etc/passwd | cut -d: -f1 getent passwd # list users
getent passwd | awk -F “:” ‘{print $1}’ getent passwd | cut -d: -f1
getent passwd # equivalent to cat /etc/passwd getent passwd rahul
#details for a particular user getent passwd 0 #find a username by
UID</p>
<p>$ cut -d”:” -f1 /etc/passwd #list all users</p>
<p>#list normal user names awk -F: ’{if($3 &gt;= 1000 &amp;&amp; $3 &lt;
2**16-2) print $1}’ /etc/passwd awk -F: ‘{if(($3 &gt;= 500)&amp;&amp;($3
&lt;65534)) print $1}’ /etc/passwd awk -F: ’{if(!(( $2 == “!!”)||($2 ==
“*“))) print <span class="math inline">$1}' /etc/shadow
grep -E ":[0-9]{4,6}:[0-9]{4,6}:" /etc/passwd | cut -d: -f1$</span>
getent passwd | awk ‘NR==FNR { if (<span
class="math inline">1 /<sup><em>U</em></sup><em>I</em><em>D</em><sub>(<em>M</em><em>I</em><em>N</em>|<em>M</em><em>A</em><em>X</em>)</sub></span>/)
m[$1] = $2; next } { split (<span class="math inline">$0, a, /:/);
  if (a[3] &gt;= m["UID_MIN"] &amp;&amp; a[3] &lt;= m["UID_MAX"]
&amp;&amp; a[7] !~ /(false|nologin)$</span>/) print a[1] }’
/etc/login.defs - $ getent passwd |<br />
nologin|false)&gt; grep -vE ‘(nologin|false)$’ |<br />
: -v mi&gt; awk -F: -v
min=<code>awk '/^UID_MIN/ {print $2}' /etc/login.defs</code><br />
X/ {p&gt; -v
max=<code>awk '/^UID_MAX/ {print $2}' /etc/login.defs</code><br />
$3 &gt;= &gt; ‘{if(($3 &gt;= min)&amp;&amp;($3 &lt;= max)) print $1}’
|<br />
t -u&gt; sort -u</p>
<p>grep -E ‘<sup>UID_MIN|</sup>UID_MAX’ /etc/login.defs #Each user has a
numeric user ID called UID. If not specified automatically selected from
the /etc/login.defs getent passwd {1000..60000} #list all normal users
depending on UID_MIN/UID_MAX in /etc/login.defs eval getent passwd
{$(awk ‘/^UID_MIN/ {print <span class="math inline">$2}'
/etc/login.defs)..$</span>(awk’/^UID_MAX/ {print <span
class="math inline">$2}' /etc/login.defs)} | cut -d: -f1
# generic,UID_MIN and UID_MIN values may be different,
eval getent passwd {$</span>(awk ‘/^UID_MIN/ {print <span
class="math inline">$2}' /etc/login.defs)..$</span>(awk’/^UID_MAX/
{print $2}’ /etc/login.defs)}</p>
<p>awk -F “:” ‘{print $5}’ /etc/passwd #print the fifth field getent
passwd $UID| awk -F “:” ‘{print $5}’ GECOS fields (which stands for
“General Electric Comprehensive Operating System”)
username:password:userid:groupid:gecos:home-dir:shell GECOS are divided
as: :FullName,RoomAddress,WorkPhone,HomePhone,Others:</p>
<h2
id="sallyx0529sally-joneshomemyhomebinpasswd-might-be-used-on-a-samba-fle-server-or-a-pop-mail-server-to-enable-users-to-change-their-passwords-via-ssh-without-granting-login-shell-access.">sally:x:0:529:Sally
Jones:/home/myhome:/bin/passwd #might be used on, a Samba fle server or
a POP mail server to enable users to change their passwords via SSH
without granting login shell access.</h2>
<h1 id="enable-the-root-account">enable the root account</h1>
<h2 id="sudo-passwd-root">sudo passwd root</h2>
<h1 id="send-an-email-from-command-line">send an email from command
line</h1>
<p>mail -s “Hello world” you@youremailid.com echo “This will go into the
body of the mail.” | mail -s “Hello world” you@youremailid.com df -h |
mail -s “disk space report” calvin@cnh.com
—————————————————————————————— # check a file system for errors? fsck
fsck.ext3 fsck.nfs fsck.ext2 fsck.vfat fsck.reiserfs fsck.msdos</p>
<h2
id="in-order-to-run-fsck-on-the-root-partition-the-root-partition-must-be-mounted-as-readonly">In
order to run fsck on the root partition, the root partition must be
mounted as readonly</h2>
<h1 id="list-of-drives-that-are-mounted-at-boot">list of drives that are
mounted at boot</h1>
<p>/etc/fstab # runs as a daemon and typically has PID 1 # change the
default runlevel upon boot up. /etc/inittab chkconfig –list #list of all
runlevels and services used by them chkconfig vnicen.sh off #Ensure that
the vnicen does not start upon reboot chkconfig –list | grep vnicen
chkconfig –level 2345 sshd on #enable sshd startup syslogd # daemon is
responsible for tracking events on the system # set which window
man-ager you want to use when logging in to X from that account # edit
in your home directory to change which window manager you want to use
~/.xinitrc —————————————————————————————— find the number of processing
units (CPU) available on a system nproc nproc –all echo “Threads/core:
$(nproc –all)”</p>
<p>lscpu #the number of physical CPU cores lscpu | egrep ‘Model
name|Socket|Thread|NUMA|CPU(s)’ lscpu -p</p>
<p>grep ‘model name’ /proc/cpuinfo | wc -l grep ‘cpu cores’
/proc/cpuinfo | uniq echo “CPU threads: $(grep -c processor
/proc/cpuinfo)” cat /proc/cpuinfo grep -c ^processor /proc/cpuinfo cat
/proc/cpuinfo | grep ‘core id’ #get the actual number of cores getconf
_NPROCESSORS_ONLN &amp;&amp; echo “Number of CPU/cores online at
$HOSTNAME: <span class="math inline">$(getconf _NPROCESSORS_ONLN)"
------------------------------------------------------------------------------------------$</span>
seq -s”;” -w 1 12 01;02;03;04;05;06;07;08;09;10;11;12</p>
<h1 id="write-dummy-lines-into-a-file">write dummy lines into a
file</h1>
<p>$ seq -s ’ ’ 23 &gt; file &amp;&amp; cat file # read dummy lines from
a file $ awk ‘(NR % 6 == 1) {print; for(i=1; i&lt;6 &amp;&amp; getline ;
i++) { print }; printf “”}’ RS=’ ’ ORS=’ ’ file 1 2 3 4 5 6 7 8 9 10 11
12 13 14 15 16 17 18 19 20 21 22 23</p>
<h1 id="create-a-dummy-file">Create a dummy file</h1>
<p>echo -e “1” &gt; testfile.txt</p>
<p>$ echo “3997e1” &gt; ids.txt #write $ echo “45697676107” &gt;&gt;
ids.txt #append —————————————————————————————— protection from
inadvertently overwriting files when copying ~/.bashrc alias cp=‘cp -i’
—————————————————————————————— # list tree structure of files and
folders</p>
<p>$ ls -R .: create_folders_files.sh folder_1 folder_2 folder_3</p>
<p>./folder_1: file_1.txt file_2.txt file_3.txt file_4.txt</p>
<p>./folder_2: file_1.txt file_2.txt file_3.txt file_4.txt</p>
<p>./folder_3: file_1.txt file_2.txt file_3.txt file_4.txt</p>
<p>$ find . . ./folder_2 ./folder_2/file_1.txt ./folder_2/file_2.txt
./folder_2/file_3.txt ./folder_2/file_4.txt ./create_folders_files.sh
./folder_1 ./folder_1/file_1.txt ./folder_1/file_2.txt
./folder_1/file_3.txt ./folder_1/file_4.txt ./folder_3
./folder_3/file_1.txt ./folder_3/file_2.txt ./folder_3/file_3.txt
./folder_3/file_4.txt</p>
<p>$ sudo tree -d /var/log/ –du -sch /var/log/ ├── [4.0K] dist-upgrade
├── [4.0K] fsck ├── [4.0K] lxd ├── [4.0K] apt └── [4.0K]
unattended-upgrades $ sudo tree /var/log/ –du -h</p>
<p>$ sudo tree -a /var/log #display hidden files $ tree -daC $ tree -f
#view the full path for each directory and file $ sudo tree -f -L 3 $
sudo tree -f -P cata* #only list files that match cata*, so files such
as Catalina.sh, catalina.bat, etc $ tree -P “<em>.log” $ sudo tree -f -I
</em>log /var/log #-I option,display all the files that do not match the
specified pattern $ sudo tree -d -I <em>log /var/log $ tree -I
”</em>.log” $ sudo tree -f –prune #prune empty directories from the
output $ sudo tree -f -p #-p which prints the file type and permissions
for each file $ sudo tree -f -pug #print the username,the group name $
sudo tree -f -pugs #print the size of each file in bytes along with the
name using the -s option $ sudo tree -f -pugh #human-readable format,
use the -h flag $ sudo tree -f -pug -h -D #display the date of the last
modification time for each sub-directory or file $ tree -d -L 3 # the
depth of directory tree in output tree -vr #sort the files from Z-A $
tree -L 2 tree -J #the output is in JSON format $ sudo tree -o
direc_tree.txt —————————————————————————————— ipcs (InterProcess
Communication System) provides a report on the semaphore, shared memory
&amp; message queue ipcs -u ipcs -m ——————————————————————————————
nslookup github.com nslookup 140.82.118.4 nslookup -query=mx github.com
nslookup -query=ns github.com nslookup -query=any github.com nslookup
-query=soa github.com nslookup -query=soa port=54 github.com nslookup
-debug github.com —————————————————————————————— The command shell
interprets the &amp;&amp; as the logical AND.the second command will be
executed only when the first one has been succcefully executed A double
ampersand &amp;&amp; in Bash means AND and can be used to separate a
list of commands to be run sequentially. Commands separated by a double
ampersand &amp;&amp; are to be run synchronously, with each one running
only if the last did not fail (a fail is interpreted as returning a
non-zero return status).</p>
<p>&amp;&amp; AND – execute both, return true of both succeed ;
sequential execution, return status is that of the last in the list</p>
<p>$ mkdir /workspace ; mkdir /entrypoint mkdir: cannot create directory
‘/workspace’: Permission denied mkdir: cannot create directory
‘/entrypoint’: Permission denied $ mkdir /workspace &amp;&amp; mkdir
/entrypoint mkdir: cannot create directory ‘/workspace’: Permission
denied —————————————————————————————— mkdir -p first/second/third #If
the first and second directories do not exist, mkdir creates these
directories mkdir -m a=rwx first/second/third #set the file modes,
i.e. permissions, etc —————————————————————————————— disable and stop
service $ sudo systemctl disable –now zabbix-server.service enable and
start service $ sudo systemctl enable –now zabbix-server.service #
enable and start the service</p>
<p>chkconfig tgtd on #configure it to start Automatically while system
start-up chkconfig –list tgtd #verify that the run level configured
correctly for the tgtd service chkconfig –list #shows SysV services only
and does not include native systemd services. chkconfig | grep snmpd
systemctl list-units –all systemctl list-unit-files systemctl list-units
–all –state=inactive systemctl list-units –type=service #only active
service units</p>
<p>systemctl cat sshd.service #Displaying a Unit File sudo systemctl
edit nginx.service sudo systemctl edit –full nginx.service sudo
systemctl daemon-reload</p>
<p>systemctl list-unit-files –type=target systemctl list-units
–type=target</p>
<p>systemctl list-dependencies sshd.service #Displaying Dependencies
systemctl show sshd.service #Checking Unit Properties systemctl show
sshd.service -p Conflicts #display a single property,pass the -p flag
with the property name sudo systemctl mask nginx.service #the ability to
mark a unit as completely unstartable, automatically or manually, by
linking it to /dev/null. This is called masking the unit</p>
<table>
<colgroup>
<col style="width: 100%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">ls -laZ ~/.ssh # change the security
context to system_u:object_r:usr_t:s0 chcon -R -v
system_u:object_r:usr_t:s0 ~/.ssh/</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">problem: never edit directly
‘/etc/sudoers’ file $ sudo visudo &gt;&gt;&gt; /etc/sudoers: syntax
error near line 28 &lt;&lt;&lt; sudo: parse error in /etc/sudoers near
line 28 sudo: no valid sudoers sources found, quitting</td>
</tr>
<tr class="even">
<td style="text-align: left;">fix: pkexec visudo #includedir
/etc/sudoers -&gt; #includedir /etc/sudoers.d #change last line</td>
</tr>
<tr class="odd">
<td style="text-align: left;">sudo mount /dev/sda1 /mnt #mount the
installed Ubuntu system’s root filesystem sudo visudo -f
/mnt/etc/sudoers #edit the installed system’s sudoers file pkexec visudo
-f /etc/sudoers.d/filename #edit configuration files</td>
</tr>
</tbody>
</table>
<p>problem: sleep: invalid time interval `2 fix: sudo cat test.sh | sudo
tr -d ’ | sudo tee test2.sh —————————————————————————————— $ diff 1.txt
2.txt # display the differences in the files by comparing the files line
by line $ diff -c 1.txt 2.txt $ diff 1.txt 2.txt -u $ diff 1.txt 2.txt
-i $ diff 1.txt 2.txt –color $ diff 1.txt 2.txt -s <span
class="math inline">$diff -i test_file_1.txt test_file_2.txt #ignoring
the case sensitivity$</span>diff -y -W 60 test_file_1.txt
test_file_2.txt #view the difference,The “-W” indicates the width
between the content of two files <span class="math inline">$diff -q
test_file_1.txt test_file_2.txt #“-q” option with the “diff” command
gives you output in one line$</span>diff -u test_file_1.txt
test_file_2.txt #</p>
<p>#write the difference between two files into a file diff a.txt
b.txt|grep “&gt;”|cut -c 3- &gt; foo.txt</p>
<p>#-q, –brief report only when files differ #-s,
–report-identical-files report when two files are the same diff -sq
/tmp/file1 /tmp/file2</p>
<p>diff chap1.back chap1 #compare two files #If two lines differ only in
the number of spaces and tabs between words, the diff -w command
considers them to be the same. #compare two files compare two files
while ignoring differences in the amount of white space diff -w
prog.c.bak prog.c #create a file containing commands that the ed command
can use to reconstruct one file from another #creates a file named
new.to.old.ed that contains the ed subcommands to change chap2 #back
into the version of the text found in chap2.old diff -e chap2 chap2.old
&gt;new.to.old.ed # in parentheses add 1,<span class="math inline">$p to
the end of the editing commands sent to the ed editor.
#The 1,$</span>p causes the ed command to write the file to standard
output after editing it #then piped to the ed command (| ed), and the
editor reads it as standard input #The - flag causes the ed command not
to display the file size and other extra information #because it would
be mixed with the text of chap2.old. (cat new.to.old.ed ; echo ‘1,$p’) |
ed - chap2 &gt;chap2.old #compare two text files containing UTF-8
characters and show the differences diff -W
filecodeset=UTF-8,pgmcodeset=IBM-1047 myUtf8File01 myUtf8File02 #compare
two text files containing EBCDIC characters and show the differences
diff -B myMisTaggedFile01 myMisTaggedFile02
—————————————————————————————— Local to Remote: rsync [OPTION]… -e ssh
[SRC]… [USER@]HOST:DEST Remote to Local: rsync [OPTION]… -e ssh
[USER@]HOST:SRC… [DEST]</p>
<p>-v, –verbose – Using this option in the rsync command gives the
status about transferred files. -vv – Usually, this option is used to
get information about the skipped files during file transfer. -q, –quiet
– This option simply suppress non-error messages.</p>
<p>rsync -av –rsync-path=“rsync –log-file=/tmp/rlog” source/
destination/ #enable error log for rsync #rsync exits with a non-zero
code when the transfer fails,write details to log files. rsync -avz -e
ssh root@example.com:/ /mybackup/ &gt; /var/log/rsync.log
2&gt;&amp;1</p>
<p>Problem: rsync: failed to set times on “some_dir: Operation not
permitted (1) mkstemp”some_file” failed: Permission denied (13) Fix: if
the user is ‘abc’ then the destination directory should be lrwxrwxrwx 1
abc abc 34 Jul 18 14:05 Destination_directory chown -R abc:abc
Destination_directory</p>
<p>rsync -aEim –delete /path/to/remote/ /path/to/local/ # rsync output
to stdout with the -i flag</p>
<p>#Only files that rsync has fully successfully transferred are
removed. rsync -r -z -c –remove-source-files /home/pi/queue
root@server.mine.com:/home/foobar</p>
<p>rsync -avz source destination #preserve permissions, ownership, and
timestamp</p>
<p>#When the trailing slash “/” is omitted the source directory will be
copied inside the destination directory #transfer the local directory to
the directory on a remote machine $ rsync -avz -e “ssh -o
StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null” –progress
/home/filerunner/dir1 vg-ubuntu-02:/tmp $ ls /tmp/dir1 a.txt</p>
<p>#When the source directory has a trailing slash “/”, rsync will copy
only the contents of the source directory to the destination directory $
rsync -avz -e “ssh -o StrictHostKeyChecking=no -o
UserKnownHostsFile=/dev/null” –progress /home/filerunner/dir1/
vg-ubuntu-02:/tmp $ ls /tmp a.txt</p>
<p>#dry run mode, rsync -azhv -e “ssh -p 2212” –dry-run
/home/bob/test_219</p>
<p>#find out if the files are in sync, without actually doing a sync dry
run mode #-c, –checksum - skip based on checksum, not mod-time &amp;
size #-r, –recursive - recurse into directories #-n, –dry-run - perform
a trial run with no changes made #does not show anything if server2 has
more files then server1 rsync -n -avrc /abc/home/sample1/*
server2:/abc/home/sample2/ #dry-run mode verify rsync -avzrch –progress
–exclude=lost+found/ -e “ssh -i /home/vagrant/privatekey” –delete
user@server:/mnt/files/ /mnt/disk1/ &gt; /tmp/rsync_out 2&gt;&amp;1</p>
<p>#find out if the files are in sync, without actually doing a sync dry
run mode #–delete is needed to show if a file exists on server 2 but not
server 1 rsync -n -avr –size-only –delete /abc/home/sample1/
server2:/abc/home/sample2/</p>
<p>#find out if the files are in sync, without actually doing a sync dry
run mode #Without –dry-run, it will automatically copy files of
different sizes #if the sizes are identical, checksum them and copy if
different #The delete option will remove files from the target if not
present on the source rsync -cr –delete –dry-run source/ target/ &gt;
output_file 2&gt;&amp;1 &amp; #–size-only skip files that match in size,
no checksum rsync -n -avr –size-only –delete /abc/home/sample1/
server2:/abc/home/sample2/</p>
<p>rsync -a -e “ssh -p 3322” /home/linuxize/images/
user@12.12.12.12:/var/www/images/ #if SSH is listening on port 3322</p>
<p>#transfer a single file /opt/file.zip from the local system to the
/var/www/ directory on the remote system with IP 12.12.12.12 #If the
file exists on the remote server it is overwritten rsync -a
/opt/file.zip user@12.12.12.12:/var/www/ #save the file under a
different name rsync -a /opt/file.zip
user@12.12.12.12:/var/www/file2.zip</p>
<p>#transfer data from a remote to a local machine rsync -a
user@12.12.12.12:/var/www/file.zip /opt/</p>
<p>#synchronize the local and remote directory rsync -a
/home/linuxize/images/ user@12.12.12.12:/var/www/images/</p>
<p>#use the –delete option if you want to synchronize the local and
remote directory #delete files in the destination directory if they
don’t exist in the source directory. rsync -a –delete
/home/linuxize/images/ user@12.12.12.12:/var/www/images/</p>
<p>#the “-r” option for “recursive” and the “-a” option for “all”
(otherwise non-regular files will be skipped) #copy the “/etc” folder to
the “/etc_backup” of the remote server #with the “devconnected” username
to server 192.168.178.35/24 rsync -ar /etc
devconnected@192.168.178.35:/etc_backup</p>
<p>#Similarly,copy the content of the “/etc/ directory rather than the
directory itself rsync -ar /etc/*
devconnected@192.168.178.35:/etc_backup/</p>
<h1 id="taggged-with-the-current-date">taggged with the current
date</h1>
<p>rsync -ar /etc/* devconnected@192.168.178.35:/etc_backup/etc_$(date
“+%F”)</p>
<p>#from local to remote server with private key rsync -auvz -e “ssh -i
private-key-file” source destination #Using rsync With SSH and Private
Key rsync -auvz -e “ssh -i
/home/yourUserName/.ssh/yourUserName-rsync-key” junk.txt
yourUserName@calypso.nrel.colostate.edu rsync -avzhe ssh backup.tar.gz
root@192.168.0.141:/backups/ rsync -avzhe ssh –progress /root/rpmpkgs
root@192.168.0.141:/root/rpmpkgs</p>
<p>#from remote to local server rsync -avzh
root@192.168.0.141:/root/rpmpkgs /tmp/myrpms rsync -avze ssh –include
‘R<em>’ –exclude ’</em>’ root@192.168.0.141:/var/lib/rpm/ /root/rpm
#exclude lost+found dir rsync –archive –no-compress –delete-before
–info=progress2 –human-readable –exclude=lost+found/ /mnt/backup/
/mnt/backup-2/</p>
<p>#run rsycn on the background rsync -avze ssh –include ‘R<em>’
–exclude ’</em>’ root@192.168.0.141:/var/lib/rpm/ /root/rpm &gt;
rsync.out 2&gt;&amp;1 &amp; tail -f rsync.out
—————————————————————————————— #copy the “/etc” directory to a backup
server located at 192.168.178.35 in the “/etc_backup” folder scp -r /etc
devconnected@192.168.178.35:/etc_backup/ # taggged with the current date
scp -r /etc devconnected@192.168.178.35:/etc_backup/etc_$(date
“+%F”)</p>
<p>scp your_username@remotehost.edu:foobar.txt
/some/local/directory-&gt; Copy the file “foobar.txt” from a remote host
to the local host scp file.txt
remote_username@10.10.0.2:/remote/directory/newfilename.txt # save the
file under a different name,Omitting the filename from the destination
location copies the file with the original name. scp foobar.txt
your_username@remotehost.edu:/some/remote/directory -&gt; Copy the file
“foobar.txt” from the local host to a remote host scp
your_username@rh1.edu:/some/remote/directory/foobar.txt
your_username@rh2.edu:/some/remote/directory/ -&gt;Copy the file
“foobar.txt” from remote host “rh1.edu” to remote host “rh2.edu” scp -P
2322 file.txt remote_username@10.10.0.2:/remote/directory #the remote
host is listening on a port other than the default 22 scp -r
/local/directory remote_username@10.10.0.2:/remote/directory #copy a
directory from a local to remote system,use the -r flag for
recursive</p>
<p># don’t have to log in to one of the servers to transfer files from
one to another remote machine. #copy the file /files/file.txt from the
remote host host1.com to the directory /files on the remote host
host2.com scp user1@host1.com:/files/file.txt user2@host2.com:/files scp
-3 user1@host1.com:/files/file.txt user2@host2.com:/files #route the
traffic through the local host (machine on which the command is issued),
use the -3 option —————————————————————————————— #cp interpret main as a
directory to place scala,doesn’t exist, cp will throw an error. cp -av
/home/jake/transit/scalaProjects/scalaML/src/main/scala -t
/home/jake/project/__workspace/scalaProjects/scalaML/src/main/</p>
<p>#Copy Directory Content Recursively cp -R bashdir bashdir-bck cp -R
/etc/* /etc_backup cp -R /etc/* /home/* /backup_folder # copy the “/etc”
directory and “/home” directory.</p>
<p>#copies the folder Misc and all its contents (the -r, or “recursive,”
option indicates the contents as well as the folder or file itself) into
the folder /media/clh/4388-D5FE cp -r Misc /media/clh/4388-D5FE # #copy
over only the new files,use the “update” and “verbose” options cp -ruv
Misc /media/clh/4388-D5FE # a file called test1.py, which is the
original, and another called test1.py.<sub>1</sub>, which is the backup
file. cp –force –backup=numbered test1.py test1.py</p>
<p>cp /home/usr/dir/{file1,file2,file3,file4} /home/usr/destination/
#copy multiple files cp -rp /copying/from/{folder1/,folder2/,folder3/}
path/to/folder #p is for copying the folder permission cp
/home/usr/dir/file{1..4} /tmp #if the all the files have the same prefix
but different endings</p>
<table>
<colgroup>
<col style="width: 100%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">#brace expansions</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">#rename multiple files to change the
extensions $ mv <em>.txt </em>.tsv mv: target ‘d.tsv’: Not a
directory</td>
</tr>
<tr class="even">
<td style="text-align: left;">#rename all the files with a .txt
extension to .fg extension in the given directory find . -type f -name
“*.txt” -exec sh -c ‘mv “<span class="math inline">$1"
"$</span>{1%.txt}.fg”’ _ {} ;</td>
</tr>
<tr class="odd">
<td style="text-align: left;">#bash script for file in
/path/to/directory/*.txt; do mv “<span class="math inline">$file"
"$</span>{file%.txt}.fg” done</td>
</tr>
<tr class="even">
<td style="text-align: left;"># one liner version of the bash script
above find /path/to/directory -type f -name “*.txt” -exec bash -c ‘mv
“<span class="math inline">$0" "$</span>{0%.txt}.fg”’ {} ;</td>
</tr>
</tbody>
</table>
<p>cmp file1.txt file2.txt #cmp command reports the byte and line number
if a difference is found cmp –silent file1 file2 &amp;&amp; echo
‘SUCCESS: Files Are Identical’ || echo ‘Files Are Different’ cmp –silent
$old $new || echo “files are different”</p>
<p>#if= defines the source drive and of= defines the file or location
where data saved # dd if=/dev/sda of=/dev/sdb # dd if=/dev/sda
of=/home/username/sdadisk.img #create an .img archive of the /dev/sda
drive and save it to the home directory # dd if=/dev/sda2
of=/home/username/partition2.img bs=4096 #if= takes the image to
restore, and of= takes the target write the image # dd if=sdadisk.img
of=/dev/sdb create a compressed image of a remote drive using SSH and
save the resulting archive to local machine # ssh username@54.98.132.10
“dd if=/dev/sda | gzip -1 -” | dd of=backup.gz dd if=text.ascii
of=text.ebcdic conv=ebcdic #convert an ASCII text file to EBCDIC
#convert the variable-length record ASCII file /etc/passwd to a file of
132-byte fixed-length EBCDIC records dd if=/etc/passwd cbs=132
conv=ebcdic of=/tmp/passwd.ebcdic #convert the 132-byte-per-record
EBCDIC file to variable-length ASCII lines in lowercase dd
if=/tmp/passwd.ebcdic cbs=132 conv=ascii of=/tmp/passwd.ascii #copy
blocks from a tape with 1KB blocks to another tape using 2KB blocks dd
if=/dev/rmt0 ibs=1024 obs=2048 of=/dev/rmt1 ls -l | dd conv=ucase
#displays a long listing of the current directory in uppercase. dd
if=/dev/zero of=/dev/sda1 #Wiping disks with dd,writing zeros # dd
if=/dev/urandom of=/dev/sda1 #Wiping disks with dd,writing random
characters # dd if=/dev/urandom | pv | dd of=/dev/sda1 #Monitoring dd
operations,Pipe Viewer (sudo apt install pv on Ubuntu)</p>
<p>#create a large file of random conten $ dd if=/dev/urandom
of=/tmp/file1 count=1K bs=1MB #copy file1 to file2, and append different
characters to each file $ cp /tmp/file1 /tmp/file2 $ echo 1 &gt;&gt;
/tmp/file1 $ echo 2 &gt;&gt; /tmp/file2 #use the time command to measure
the time taken $ time cmp -s /tmp/file1 /tmp/file2 $ time diff -sq
/tmp/file1 /tmp/file2 $ time sha1sum /tmp/file1 $ time sha1sum
/tmp/file2</p>
<p>#Empty File Content by Redirecting to Null # &gt; access.log # : &gt;
access.log #: is a shell built-in command # true &gt; access.log # cat
/dev/null &gt; access.log # cp /dev/null access.log # dd if=/dev/null
of=access.log # echo “” &gt; access.log # echo &gt; access.log # echo -n
“” &gt; access.log #use the flag -n which tells echo to not output the
trailing newline # truncate -s 0 access.log</p>
<p>dd if=/dev/urandom of=test.file bs=1M count=100 ; time diff -q
test.file test.copy &amp;&amp; echo diff true || echo diff false ;<br />
time cmp -s test.file test.copy &amp;&amp; echo cmp true || echo</p>
<p>vagrant@lampstack-01:~$ echo “file” &gt; file1.txt
vagrant@lampstack-01:~$ cp file1.txt file2.txt vagrant@lampstack-01:~$
cmp file1.txt file2.txt #cmp command reports the byte and line number if
a difference is found vagrant@lampstack-01:~$ sudo cmp file1.txt
file2.txt vagrant@lampstack-01:~$ echo “identical file1” &gt;&gt;
file1.txt vagrant@lampstack-01:~$ cat file1.txt file identical file1
vagrant@lampstack-01:~$ cat file2.txt file vagrant@lampstack-01:~$ cmp
file1.txt file2.txt #cmp command reports the byte and line number if a
difference is found cmp: EOF on file2.txt after byte 5, line 1
vagrant@lampstack-01:~$ diff file1.txt file2.txt 2d1 &lt; identical
file1 ————————- —————————————————————– # approval trick $ yes | sudo yum
install puppet # user has to type ‘y’ for each query $ yes | rm -ri test
————————- —————————————————————– #oracle java download</p>
<p>wget –no-cookies<br />
–no-check-certificate<br />
–header “Cookie: oraclelicense=accept-securebackup-cookie”<br />
“https://download.oracle.com/otn-pub/java/jdk/13.0.1+9/cec27d702aa74d5a8630c65ae61e4305/jdk-13.0.1_linux-x64_bin.tar.gz”<br />
-O jdk-7-linux-x64.tar.gz</p>
<p>curl –silent example.com | sha256sum curl –silent –output -
example.com | sha256sum #the o flag is redundant since the output is
piped to bash (for execution) - not to a file #-L in case the page has
moved curl will redirect the request to the new address #-o output to a
file instead of stdout (usually the screen) curl -LO
http://example.com/</p>
<p>curl -LO -H “Cookie: oraclelicense=accept-securebackup-cookie”<br />
https://download.oracle.com/otn-pub/java/jdk/13.0.1+9/cec27d702aa74d5a8630c65ae61e4305/jdk-13.0.1_linux-x64_bin.tar.gz
——————————————————————————————</p>
<table>
<colgroup>
<col style="width: 100%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">hostnamectl set-hostname vg-checkmk-client
echo “172.28.128.15 vg-checkmk-client.local vg-checkmk-client” |sudo tee
-a /etc/hosts echo “nameserver 8.8.8.8” |sudo tee -a
/etc/resolv.conf</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">#File Creation Times
vagrant@lampstack-01:/tmp/nexus$ df -h Filesystem Size Used Avail Use%
Mounted on udev 205M 0 205M 0% /dev tmpfs 48M 7.8M 41M 17% /run
/dev/mapper/vagrant–vg-root 62G 4.3G 55G 8% / tmpfs 240M 0 240M 0%
/dev/shm tmpfs 5.0M 0 5.0M 0% /run/lock tmpfs 240M 0 240M 0%
/sys/fs/cgroup vagrant 420G 375G 46G 90% /vagrant tmpfs 48M 0 48M 0%
/run/user/1000 vagrant@lampstack-01:/tmp/nexus$ ls -i Dockerfile 3808483
Dockerfile vagrant@lampstack-01:/tmp/nexus$ sudo debugfs -R ‘stat
&lt;3808483&gt;’ /dev/mapper/vagrant–vg-root debugfs 1.44.6 (5-Mar-2019)
vagrant@lampstack-01:/tmp/nexus$ vagrant@lampstack-01:/tmp/nexus$ sudo
debugfs -R ‘stat &lt;3808483&gt;’ /dev/mapper/vagrant–vg-root | grep
crtime debugfs 1.44.6 (5-Mar-2019) crtime: 0x5e4f0f92:b6a11330 – Thu Feb
20 23:00:34 2020</td>
</tr>
</tbody>
</table>
<p>#how to view gz gunzip files</p>
<p>zcat test2.txt.gz #see the content of the compressed file zcat
test.txt.gz test2.txt.gz #see the content of the compressed
files,multiple inputs zcat test2.txt #uncompress files that have the
correct magic number whether they have a .gz suffix or not zcat
test2.txt.gz | more zcat test2.txt.gz | less zmore test2.txt.gz zless
test2.txt.gz zless -f test2.txt #display file contents in output whether
or not the file is compressed</p>
<h1 id="search-string-in-multiple-.gz-file">search string in multiple
.gz file</h1>
<p>zgrep -i -H “pattern match” /somedir/filename<em>.gz zgrep -i -H
“pattern match” /somedir/filename</em>.gz | grep “pattern 2nd” find
/somedir/ -name “log.202011917*.gz” -exec zgrep “somestring” {} ; find
/somedir/ -name ‘log.202011917’ -print0 | xargs -0 zgrep “somestring”
#prints file path inc. folder —————————————————————————————— #Hosts File
Windows 10 - “C:” Linux - “/etc/hosts” Mac OS X - “/private/etc/hosts”
——————————————————————————————<br />
type -a ll #if command is an alias or not type -p dash
——————————————————————————————<br />
—————————————————————————————— echo $? #get the exit status of the
previously executed command,
http://www.tldp.org/LDP/abs/html/exitcodes.html echo $? # Expands to the
exit status (exit code) of the most recently executed foreground
pipeline,return the exit status of last command exits with a status code
0 #success exits with a status code 1 #failure</p>
<p>command &amp;&amp; echo “success: $?” || echo “fail: $?” #test if the
command failed if [ $? -eq 0 ]; then echo “success: $?”; fi</p>
<p>$ echo “hola el mundo” &gt; file.txt $ cat file.txt &amp;&amp; echo
“success: $?” || echo “fail: <span class="math inline">$?"
hola el mundo
success: 0$</span> cat filedoesnotexist.txt &amp;&amp; echo”success: $?”
|| echo “fail: $?” cat: filedoesnotexist.txt: No such file or directory
fail: 1</p>
<p>cat ‘doesnotexist.txt’ 2&gt;/dev/null || exit 0 #suppress exit status
cat file.txt || exit 0</p>
<p>#suppress the error silently $ cat filedoesnotexist.txt &amp;&amp;
echo “success: $?” || echo “fail: <span class="math inline">$?"
cat: filedoesnotexist.txt: No such file or directory
fail: 1$</span> cat filedoesnotexist.txt || true &amp;&amp; echo $? cat:
filedoesnotexist.txt: No such file or directory 0</p>
<p>$ fslint /tmp #lists the duplicate files $ rdfind /tmp #delete the
duplicates,remove the newer files. $ rdfind -dryrun true /tmp #only
report the changes $ rdfind -deleteduplicates true /tmp</p>
<p>$ cksum <em>.html #computes checksums for files $ find . -name
“</em>.html” -exec cksum {} ; #search files by name or type and run the
cksum command.</p>
<p>$ find . -name “not_existing_file” $ echo $?
—————————————————————————————————– bash -x # runs the script <file> with
tracing of each command executed bash -x -c ls -lai #run a command in
BASH, use -c option test -x <file> #tests whether <file> has execute
permissions for the current user ——————————————————————————————<br />
#print variable export BRANCH_NAME=“main” echo “BRANCH_NAME is..: <span
class="math inline">$BRANCH_NAME"
------------------------------------------------------------------------------------------
yum/apt install chrony
systemctl stop chronyd
chronyd -q 'pool pool.ntp.org iburst'
systemctl start chronyd
chronyc tracking #verify
systemctl restart chronyd ; watch chronyc tracking #realtime witnessing
chronyc sources
chronyc sources -v
chronyc
------------------------------------------------------------------------------------------
#concatenate strings
export strservice="libvirtd"
echo "$</span>{strservice} is still running.” echo $(ls) echo “The date
is $(date)” echo <code>pwd</code> echo $((3 + (4**3 /2))) #Direct
calculation in the shell with echo and $(( )
—————————————————————————————— #nfs server exportfs -arv df -h</p>
<p>cat /etc/exports # /mnt/nfs_share client_IP_1
(re,sync,no_subtree_check) echo “<span
class="math inline">$NFS_DIR  192.168.50.7(rw,sync,no_subtree_check)" |
sudo tee -a /etc/exports
echo "$</span>NFS_DIR 192.168.50.8(rw,sync,no_subtree_check)” | sudo tee
-a /etc/exports</p>
<p>#nfs client mount -t nfs NFS_SERVER_IP:NFS_SERVER_DIR NFS_CLIENT_DIR
mount -t nfs 10.20.20.8:/mnt/backups /mnt/backups umount /mnt/backups
mount | grep nfs showmount -e —————————————————————————————— #execute
shell command produced using echo and sed echo “mv
/server/today/logfile1 /nfs/logs/ &amp;&amp; gzip /nfs/logs/logfile1” |
bash # bash -c “<span class="math inline">$(echo "mv
/server/today/logfile1 /nfs/logs/ &amp;&amp; gzip /nfs/logs/logfile1")"
#pass it as an argument to a shell
eval "$</span>(echo”mv /server/today/logfile1 /nfs/logs/ &amp;&amp; gzip
/nfs/logs/logfile1”)” #use the bash built-in eval
—————————————————————————————— $ mycommand=“wc -l department.txt” $ eval
<span
class="math inline"><em>m</em><em>y</em><em>c</em><em>o</em><em>m</em><em>m</em><em>a</em><em>n</em><em>d</em> − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − − −</span>
cat /proc/sys/net/ipv4/ip_local_port_range
—————————————————————————————— #redirection is done by the shell which
doesn’t has write permission sudo echo 1 &gt;
/proc/sys/net/ipv4/ip_forward bash: /proc/sys/net/ipv4/ip_forward:
Permission denied</p>
<p>echo 1 | sudo tee /proc/sys/net/ipv4/ip_forward #resolution-1</p>
<p>$ sudo sh -c ‘echo 1 &gt; /proc/sys/net/ipv4/ip_forward’
#resolution-2</p>
<p>$ sudo -s #resoluton-3 # echo 1 &gt;
/proc/sys/net/ipv4/ip_forward</p>
<p>$ cat testscript.sh #resolution-4 #!/bin/sh echo 1 &gt;
/proc/sys/net/ipv4/ip_forward</p>
<p>sudo echo 1 | sudo tee /proc/sys/net/ipv4/ip_forward &gt; /dev/null
#same $ sudo tee /proc/sys/net/ipv4/ip_forward &gt; /dev/null &lt;&lt;
EOF #same 1 EOF —————————————————————————————— #source tar build, no
version typing tar zfx rrdtool.tar.gz cd rrdtool-*
—————————————————————————————— echo 1 &gt; /proc/sys/kernel/sysrq;echo f
&gt; /proc/sysrq-trigger;echo 0 &gt; /proc/sys/kernel/sysrq #Trigger Out
Of Memory (OOM) killer without reboot —————————————————————————————— ls
-la .mozilla/firefox #user preferences,browser cookies,bookmarks,browser
cache content etc. —————————————————————————————— #troubleshooting
memory problems</p>
<p>#Suddenly killed tasks are often the result of the system running out
of memory, when the so-called Out-of-memory (OOM) killer steps in $ grep
-i -r ‘out of memory’ /var/log/ #search the logs for messages of out of
memory alerts</p>
<p>$ free -m #megabytes $ free -m |head -n 2 |tail -n 1 |awk
‘{free=($4); print free}’ watch -n 5 -d ‘/bin/free -m’</p>
<p>$ top $ top -i -u vagrant #ignore idle processes $ top -n 1 -o RES |
grep kvm</p>
<p>$ uptime #“system load averages” that show the running thread (task)
demand on the system as an average number of running plus waiting
threads. #show three averages, for 1, 5, and 15 minutes #If the averages
are 0.0, system is idle #If the 1 minute average is higher than the 5 or
15 minute averages, then load is increasing #If the 1 minute average is
lower than the 5 or 15 minute averages, then load is decreasing.</p>
<p>$ ps -aylC <span class="math inline">$APACHE |grep "$</span>APACHE”
|awk ’{print <span class="math inline">$8'} |sort -n |tail -n 1$</span>
ps -eL h -o state | egrep “R|D” | wc -l #The instantaneous number of
such tasks #Linux load average,the instantaneous load of a system the
number of tasks (processes and threads) #that are willing to run at a
given time t #either in state R or D, either actually running or blocked
on some resource (CPU, IO, …) waiting for an opportunity to run</p>
<p>$ cat /proc/sys/vm/swappiness #The Linux kernel moves out pages which
are not active or being used at the moment to swap space on the disk.
This process is known as swappiness. #turn off swaping by changing t he
value in /proc/sys/vm/swappiness to 0.The value ranges from 0 to 100 whe
re 100 means aggressive swapping</p>
<p>vmstat –a 1 99 #show memory usage information vmstat -n 1 # If ‘si’
and ‘so’ (stands for swapin and swapout) fields are always 0, then the
system is currently not swapping</p>
<p>$ grep DirectMap /proc/meminfo $ cat /proc/meminfo #Relevant fields
from /proc/meminfo to match them against the output of free -k MemTotal
— Total amount of physical RAM, in kilobytes. MemFree — The amount of
physical RAM, in kilobytes, left unused by the system. Buffers — The
amount of physical RAM, in kilobytes, used for file buffers. Cached —
The amount of physical RAM, in kilobytes, used as cache memory.
SwapCached — The amount of swap, in kilobytes, used as cache memory.
Active — The total amount of buffer or page cache memory, in kilobytes,
that is in active use. This is memory that has been recently used and is
usually not reclaimed for other purposes. Inactive — The total amount of
buffer or page cache memory, in kilobytes, that are free and available.
This is memory that has not been recently used and can be reclaimed for
other purposes. HighTotal and HighFree — The total and free amount of
memory, in kilobytes, that is not directly mapped into kernel space. The
HighTotal value can vary based on the type of kernel used. LowTotal and
LowFree — The total and free amount of memory, in kilobytes, that is
directly mapped into kernel space. The LowTotal value can vary based on
the type of kernel used. SwapTotal — The total amount of swap available,
in kilobytes. SwapFree — The total amount of swap free, in kilobytes.
Dirty — The total amount of memory, in kilobytes, waiting to be written
back to the disk. Writeback — The total amount of memory, in kilobytes,
actively being written back to the disk. Mapped — The total amount of
memory, in kilobytes, which have been used to map devices, files, or
libraries using the mmap command. Slab — The total amount of memory, in
kilobytes, used by the kernel to cache data structures for its own use.
Committed_AS — The total amount of memory, in kilobytes, estimated to
complete the workload. This value represents the worst case scenario
value, and also includes swap memory. PageTables — The total amount of
memory, in kilobytes, dedicated to the lowest page table level.
VMallocTotal — The total amount of memory, in kilobytes, of total
allocated virtual address space. VMallocUsed — The total amount of
memory, in kilobytes, of used virtual address space. VMallocChunk — The
largest contiguous block of memory, in kilobytes, of available virtual
address space. HugePages_Total — The total number of hugepages for the
system. The number is derived by dividing Hugepagesize by the megabytes
set aside for hugepages specified in /proc/sys/vm/hugetlb_pool. This
statistic only appears on the x86, Itanium, and AMD64 architectures.
HugePages_Free — The total number of hugepages available for the system.
This statistic only appears on the x86, Itanium, and AMD64
architectures. Hugepagesize — The size for each hugepages unit in
kilobytes. By default, the value is 4096 KB on uniprocessor kernels for
32 bit architectures. For SMP, hugemem kernels, and AMD64, the default
is 2048 KB. For Itanium architectures, the default is 262144 KB. This
statistic only appears on the x86, Itanium, and AMD64 architectures.</p>
<p>Matching output of free -k to /proc/meminfo free output coresponding
/proc/meminfo fields Mem: total MemTotal Mem: used MemTotal - MemFree
Mem: free MemFree Mem: shared (can be ignored nowadays. It has no
meaning.) N/A Mem: buffers Buffers Mem: cached Cached -/+ buffers/cache:
used MemTotal - (MemFree + Buffers + Cached) -/+ buffers/cache: free
MemFree + Buffers + Cached Swap: total SwapTotal Swap: used SwapTotal -
SwapFree Swap: free SwapFree</p>
<table>
<colgroup>
<col style="width: 100%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">cat newpass.txt | chpasswd #update
passwords in batch mode echo ‘ubuntuser:ubuntupassword’ | sudo
chpasswd</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">ls -1 #list one file per line,vertically
using the -1 switch</td>
</tr>
</tbody>
</table>
<h2
id="sudo-re-run-last-executed-command-as-root-user-sudo-followed-by-a-space-and-two-exclamation-points.">sudo
!! #Re-Run Last Executed Command as Root User, “sudo” followed by a
space and two exclamation points.</h2>
<p>#If set, sudo will only run when the user is logged in to a real tty
#sudo can only be run from a login session and not via other means such
as cron(8) or cgi-bin scripts #enable sudo within scripts</p>
<p>sudo /usr/sbin/visudo</p>
<p>$ cat /etc/sudoers Defaults:username !requiretty #Disable requiretty
to particular user</p>
<p>#sudoers file allows both artbristol and bob to execute
/path/to/program as root from a script #artbristol needs no password
whereas bob must have to enter a password artbristol ALL = (root)
NOPASSWD: /path/to/program bob ALL = (root) /path/to/program
Defaults!/path/to/program !requiretty</p>
<p>#allows artbristol to run /path/to/program –option in a script, but
not /path/to/program with other arguments. Cmnd_Alias MYPROGRAM =
/path/to/program –option<br />
artbristol ALL = (root) /path/to/program artbristol ALL = (root)
NOPASSWD: MYPROGRAM Defaults!MYPROGRAM !requiretty
—————————————————————————————— #This allows the source (the sending
host) to specify the route, loosely or strictly, ignoring the routing
tables of some or all of the routers #source-based routing should be
disabled. /sbin/sysctl -w net.ipv4.conf.all.accept_source_route=0 #drop
packets with the SSR or LSR option set</p>
<p>#Disabling the forwarding of packets should also be done in
conjunction with the above when possible (disabling forwarding may
interfere with virtualization) /sbin/sysctl -w
net.ipv4.conf.all.forwarding=0 /sbin/sysctl -w
net.ipv6.conf.all.forwarding=0 #These commands disable forwarding of all
multicast packets on all interfaces /sbin/sysctl -w
net.ipv4.conf.all.mc_forwarding=0 /sbin/sysctl -w
net.ipv6.conf.all.mc_forwarding=0</p>
<p>#Accepting ICMP redirects has few legitimate uses. Disable the
acceptance and sending of ICMP redirected packets unless specifically
required /sbin/sysctl -w net.ipv4.conf.all.accept_redirects=0
/sbin/sysctl -w net.ipv6.conf.all.accept_redirects=0 #disables
acceptance of secure ICMP redirected packets on all interfaces
/sbin/sysctl -w net.ipv4.conf.all.secure_redirects=0 # disables
acceptance of all IPv4 ICMP redirected packets on all interfaces:
/sbin/sysctl -w net.ipv4.conf.all.send_redirects=0 #automatically
disable sending of ICMP requests whenever you add a new interface
/sbin/sysctl -w net.ipv4.conf.default.send_redirects=0</p>
<p>#make these settings persistent across reboots, modify the
/etc/sysctl.conf file #disable acceptance of all IPv4 ICMP redirected
packets on all interfaces, #open the /etc/sysctl.conf file with an
editor running as the root user and add a line as follow
net.ipv4.conf.all.send_redirects=0 ——————————————————————————————
#Reverse Path Forwarding is used to prevent packets that arrived through
one interface from leaving through a different interface #unless you
know that it is required, it is best enabled as it prevents users
spoofing IP addresses from local subnets and reduces the opportunity for
DDoS attacks. #permanent changes can be made by adding lines to the
/etc/sysctl.conf # make a temporary global change sysctl -w
net.ipv4.conf.default.rp_filter=integer sysctl -w
net.ipv4.conf.all.rp_filter=integer</p>
<table>
<colgroup>
<col style="width: 100%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">#Enabling Packet Forwarding #enable
packets arriving from outside of a system to be forwarded to another
external host #change the line which reads net.ipv4.ip_forward = 0 in
the /etc/sysctl.conf file to the following net.ipv4.ip_forward = 1
/sbin/sysctl -p #load the changes from the /etc/sysctl.conf file
/sbin/sysctl net.ipv4.ip_forward #check if IP forwarding is turned on,If
it returns 1, then IP forwarding is enabled /sbin/sysctl -w
net.ipv4.ip_forward=1 #If it returns 0, turn it on manually</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">#check public IP,private (viewable within
an internal network) or public (can be seen by other machines on the
Internet)</td>
</tr>
<tr class="even">
<td style="text-align: left;">#3rd party web-sites $ wget -qO-
http://ipecho.net/plain | xargs echo $ curl ifconfig.co $ curl
ifconfig.me $ curl icanhazip.com $ curl -4 icanhazip.com $ curl -6
icanhazip.com $ curl ident.me $ curl checkip.dyndns.org $ curl
api.ipify.org $ curl ipinfo.io/ip $ curl checkip.amazonaws.com</td>
</tr>
</tbody>
</table>
<p>#The Internet Assigned Numbers Authority (IANA) has assigned several
address ranges to be used by private networks</p>
<pre><code>Class A: 10.0.0.0 to 10.255.255.255 
Class B: 172.16.0.0 to 172.31.255.255
Class C: 192.168.0.0 to 192.168.255.255

Class A: 10.0.0.0/8 (255.0.0.0) 
Class B: 172.16.0.0/12 (255.240.0.0)
Class C: 192.168.0.0/16 (255.255.0.0)</code></pre>
<table>
<colgroup>
<col style="width: 100%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">#Running GUI applications as root sudo
/usr/bin/etherape</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">chage -l ubuntu #last password change
date</td>
</tr>
</tbody>
</table>
<p>#read first, and if a match is found the connection is allowed and
the search is stopped. #If no allowed match if found, the hosts.deny
file is read /etc/hosts.allow #If a match is found the connection is
refused - otherwise it is allowed #/etc/hosts.deny
—————————————————————————————— # print server’s IP on the wellcome page
echo $(ifconfig eth0 | grep ‘inet addr’ | awk -F: ‘{ print $2 }’ | awk
‘{ print $1 }’) &gt;&gt; /var/www/html/index.html
—————————————————————————————— getfacl -a a.txt #file access control
list of a file or directory. getfacl -t a.txt getfacl -n file #numeric
user and group IDs getfacl -d a.txt #the default access control list of
a file or directory. getfacl -R directory # the ACLs of all files and
directories recursively (sub-directories) getfacl -L -R directory
#follow symbolic links to directories. The default behavior is to follow
symbolic link arguments and skip symbolic links encountered in
subdirectories getfacl -P -R directory #do not follow symbolic links to
directories,skip symbolic link arguments</p>
<p>setfacl -m u:deepak:rw a.txt #grant read and write permission setfacl
-b a.txt #remove all extended ACL entries,remove all entries setfacl -x
u:deepak a.txt #remove user setfacl -x g:linux file #remove group
setfacl -m g:linux:rw -R directory #remove group recursively
(sub-directories) setfacl -k file #remove the default access control
list setfacl –test -x g:linux -R dir1 #The ACLs are not modified in test
mode. It only displays the changes that will take place setfacl -dm
“user:my_user:r–” /path/to/directory #Add a default entry to grant
access to the user my_user on all newly created files within a
directory</p>
<h2
id="getfacl-file1-setfacl-set-file--file2-copy-the-acl-of-one-file-to-another">getfacl
file1 | setfacl –set-file=- file2 #copy the ACL of one file to
another</h2>
<p>for i in <em>linux</em>; do rm $i; done #delete all the files in the
current directory that contains the word “linux” cat linux.txt | grep n
#list the entries that start has the character ‘n’ cat linux.txt | grep
^a #ist the entries that start with the character ‘a’ echo “shutdown
now” | at -m 18:00 #shut down the system at 6 pm today vim -R <filename>
#open a file in read-only mode vim +/<employee id to be searched>
<filename> #search for a specific Employee ID in a file
—————————————————————————————— cd $mydir &amp;&amp; python3 -m
http.server 8888 #Share a file quickly using a web server</p>
<h2
id="podman-run-rm--v-.usrsharenginxhtmlroz--p-3008080--d-nginx-expose-a-web-directory-using-containers">podman
run –rm -v .:/usr/share/nginx/html:ro,Z -p 30080:80 -d nginx # Expose a
web directory using containers</h2>
<p>$ sudo shutdown –halt 22:00 #–halt option stops the operating system
$ sudo shutdown –halt +5 # halt the system after a five-minute delay $
sudo shutdown –halt +5 “Attention. The system is going down in five
minutes.” $ sudo shutdown -c #Cancel a timed shutdown $ sudo shutdown -r
now #restarting the system $ sudo systemctl reboot #restarting the
system ———————————————————————————————————————————————————————————— #how
to delete file with inode find . -inum 1847 -ls find . -inum 1847 -exec
rm {} ;</p>
<p>find . -inum 782263 -exec rm -i {} ;</p>
<p>#how to delete directory/folder with inode find . -inum 393232
-delete ————————————————————————————————————————————————————————————</p>
<section id="footnotes" class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1"><p>^#<a href="#fnref1" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>^;<a href="#fnref2" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>P-R<a href="#fnref3" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>A-Z<a href="#fnref4" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>A-Z<a href="#fnref5" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>:space:<a href="#fnref6" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
